[
    {
        "view_name": "CHARACTER_SETS",
        "database": "INFORMATION_SCHEMA",
        "view_definition": "CREATE VIEW INFORMATION_SCHEMA.CHARACTER_SETS (`character_set_name` String, `CHARACTER_SET_NAME` String) SQL SECURITY INVOKER AS SELECT arrayJoin(['utf8', 'utf8mb4', 'ascii', 'binary']) AS character_set_name, character_set_name AS CHARACTER_SET_NAME"
    },
    {
        "view_name": "COLLATIONS",
        "database": "INFORMATION_SCHEMA",
        "view_definition": "CREATE VIEW INFORMATION_SCHEMA.COLLATIONS (`collation_name` String, `COLLATION_NAME` String) SQL SECURITY INVOKER AS SELECT name AS collation_name, collation_name AS COLLATION_NAME FROM system.collations"
    },
    {
        "view_name": "COLUMNS",
        "database": "INFORMATION_SCHEMA",
        "view_definition": "CREATE VIEW INFORMATION_SCHEMA.COLUMNS (`table_catalog` String, `table_schema` String, `table_name` String, `column_name` String, `ordinal_position` UInt64, `column_default` String, `is_nullable` String, `data_type` String, `character_maximum_length` Nullable(UInt64), `character_octet_length` Nullable(UInt64), `numeric_precision` Nullable(UInt64), `numeric_precision_radix` Nullable(UInt64), `numeric_scale` Nullable(UInt64), `datetime_precision` Nullable(UInt64), `character_set_catalog` Nullable(String), `character_set_schema` Nullable(String), `character_set_name` Nullable(String), `collation_catalog` Nullable(String), `collation_schema` Nullable(String), `collation_name` Nullable(String), `domain_catalog` Nullable(String), `domain_schema` Nullable(String), `domain_name` Nullable(String), `extra` Nullable(String), `column_comment` String, `column_type` String, `TABLE_CATALOG` String, `TABLE_SCHEMA` String, `TABLE_NAME` String, `COLUMN_NAME` String, `ORDINAL_POSITION` UInt64, `COLUMN_DEFAULT` String, `IS_NULLABLE` String, `DATA_TYPE` String, `CHARACTER_MAXIMUM_LENGTH` Nullable(UInt64), `CHARACTER_OCTET_LENGTH` Nullable(UInt64), `NUMERIC_PRECISION` Nullable(UInt64), `NUMERIC_PRECISION_RADIX` Nullable(UInt64), `NUMERIC_SCALE` Nullable(UInt64), `DATETIME_PRECISION` Nullable(UInt64), `CHARACTER_SET_CATALOG` Nullable(String), `CHARACTER_SET_SCHEMA` Nullable(String), `CHARACTER_SET_NAME` Nullable(String), `COLLATION_CATALOG` Nullable(String), `COLLATION_SCHEMA` Nullable(String), `COLLATION_NAME` Nullable(String), `DOMAIN_CATALOG` Nullable(String), `DOMAIN_SCHEMA` Nullable(String), `DOMAIN_NAME` Nullable(String), `EXTRA` Nullable(String), `COLUMN_COMMENT` String, `COLUMN_TYPE` String) SQL SECURITY INVOKER AS SELECT database AS table_catalog, database AS table_schema, `table` AS table_name, name AS column_name, position AS ordinal_position, default_expression AS column_default, type LIKE 'Nullable(%)' AS is_nullable, type AS data_type, character_octet_length AS character_maximum_length, character_octet_length, numeric_precision, numeric_precision_radix, numeric_scale, datetime_precision, NULL AS character_set_catalog, NULL AS character_set_schema, NULL AS character_set_name, NULL AS collation_catalog, NULL AS collation_schema, NULL AS collation_name, NULL AS domain_catalog, NULL AS domain_schema, NULL AS domain_name, multiIf(default_kind = 'DEFAULT', 'DEFAULT_GENERATED', default_kind = 'MATERIALIZED', 'STORED GENERATED', default_kind = 'ALIAS', 'VIRTUAL GENERATED', '') AS extra, comment AS column_comment, type AS column_type, table_catalog AS TABLE_CATALOG, table_schema AS TABLE_SCHEMA, table_name AS TABLE_NAME, column_name AS COLUMN_NAME, ordinal_position AS ORDINAL_POSITION, column_default AS COLUMN_DEFAULT, is_nullable AS IS_NULLABLE, data_type AS DATA_TYPE, character_maximum_length AS CHARACTER_MAXIMUM_LENGTH, character_octet_length AS CHARACTER_OCTET_LENGTH, numeric_precision AS NUMERIC_PRECISION, numeric_precision_radix AS NUMERIC_PRECISION_RADIX, numeric_scale AS NUMERIC_SCALE, datetime_precision AS DATETIME_PRECISION, character_set_catalog AS CHARACTER_SET_CATALOG, character_set_schema AS CHARACTER_SET_SCHEMA, character_set_name AS CHARACTER_SET_NAME, collation_catalog AS COLLATION_CATALOG, collation_schema AS COLLATION_SCHEMA, collation_name AS COLLATION_NAME, domain_catalog AS DOMAIN_CATALOG, domain_schema AS DOMAIN_SCHEMA, domain_name AS DOMAIN_NAME, extra AS EXTRA, column_comment AS COLUMN_COMMENT, column_type AS COLUMN_TYPE FROM system.columns"
    },
    {
        "view_name": "ENGINES",
        "database": "INFORMATION_SCHEMA",
        "view_definition": "CREATE VIEW INFORMATION_SCHEMA.ENGINES (`engine` String, `support` String, `ENGINE` String, `SUPPORT` String) SQL SECURITY INVOKER AS SELECT name AS engine, if(engine = getSetting('default_table_engine'), 'DEFAULT', 'YES') AS support, engine AS ENGINE, support AS SUPPORT FROM system.table_engines"
    },
    {
        "view_name": "KEY_COLUMN_USAGE",
        "database": "INFORMATION_SCHEMA",
        "view_definition": "CREATE VIEW INFORMATION_SCHEMA.KEY_COLUMN_USAGE (`constraint_catalog` String, `constraint_schema` String, `constraint_name` Nullable(String), `table_catalog` String, `table_schema` String, `table_name` String, `column_name` Nullable(String), `ordinal_position` UInt32, `position_in_unique_constraint` Nullable(UInt32), `referenced_table_schema` Nullable(String), `referenced_table_name` Nullable(String), `referenced_column_name` Nullable(String), `CONSTRAINT_CATALOG` Nullable(String), `CONSTRAINT_SCHEMA` Nullable(String), `CONSTRAINT_NAME` Nullable(String), `TABLE_CATALOG` String, `TABLE_SCHEMA` String, `TABLE_NAME` String, `COLUMN_NAME` Nullable(String), `ORDINAL_POSITION` UInt32, `POSITION_IN_UNIQUE_CONSTRAINT` Nullable(UInt32), `REFERENCED_TABLE_SCHEMA` Nullable(String), `REFERENCED_TABLE_NAME` Nullable(String), `REFERENCED_COLUMN_NAME` Nullable(String)) SQL SECURITY INVOKER AS SELECT 'def' AS constraint_catalog, database AS constraint_schema, 'PRIMARY' AS constraint_name, 'def' AS table_catalog, database AS table_schema, `table` AS table_name, name AS column_name, 1 AS ordinal_position, NULL AS position_in_unique_constraint, NULL AS referenced_table_schema, NULL AS referenced_table_name, NULL AS referenced_column_name, constraint_catalog AS CONSTRAINT_CATALOG, constraint_schema AS CONSTRAINT_SCHEMA, constraint_name AS CONSTRAINT_NAME, table_catalog AS TABLE_CATALOG, table_schema AS TABLE_SCHEMA, table_name AS TABLE_NAME, column_name AS COLUMN_NAME, ordinal_position AS ORDINAL_POSITION, position_in_unique_constraint AS POSITION_IN_UNIQUE_CONSTRAINT, referenced_table_schema AS REFERENCED_TABLE_SCHEMA, referenced_table_name AS REFERENCED_TABLE_NAME, referenced_column_name AS REFERENCED_COLUMN_NAME FROM system.columns WHERE is_in_primary_key"
    },
    {
        "view_name": "REFERENTIAL_CONSTRAINTS",
        "database": "INFORMATION_SCHEMA",
        "view_definition": "CREATE VIEW INFORMATION_SCHEMA.REFERENTIAL_CONSTRAINTS (`constraint_catalog` String, `constraint_schema` String, `constraint_name` Nullable(String), `unique_constraint_catalog` String, `unique_constraint_schema` String, `unique_constraint_name` Nullable(String), `match_option` String, `update_rule` String, `delete_rule` String, `table_name` String, `referenced_table_name` String, `CONSTRAINT_CATALOG` String, `CONSTRAINT_SCHEMA` String, `CONSTRAINT_NAME` Nullable(String), `UNIQUE_CONSTRAINT_CATALOG` String, `UNIQUE_CONSTRAINT_SCHEMA` String, `UNIQUE_CONSTRAINT_NAME` Nullable(String), `MATCH_OPTION` String, `UPDATE_RULE` String, `DELETE_RULE` String, `TABLE_NAME` String, `REFERENCED_TABLE_NAME` String) SQL SECURITY INVOKER AS SELECT '' AS constraint_catalog, NULL AS constraint_name, '' AS constraint_schema, '' AS unique_constraint_catalog, NULL AS unique_constraint_name, '' AS unique_constraint_schema, '' AS match_option, '' AS update_rule, '' AS delete_rule, '' AS table_name, '' AS referenced_table_name, constraint_catalog AS CONSTRAINT_CATALOG, constraint_name AS CONSTRAINT_NAME, constraint_schema AS CONSTRAINT_SCHEMA, unique_constraint_catalog AS UNIQUE_CONSTRAINT_CATALOG, unique_constraint_name AS UNIQUE_CONSTRAINT_NAME, unique_constraint_schema AS UNIQUE_CONSTRAINT_SCHEMA, match_option AS MATCH_OPTION, update_rule AS UPDATE_RULE, delete_rule AS DELETE_RULE, table_name AS TABLE_NAME, referenced_table_name AS REFERENCED_TABLE_NAME WHERE false"
    },
    {
        "view_name": "SCHEMATA",
        "database": "INFORMATION_SCHEMA",
        "view_definition": "CREATE VIEW INFORMATION_SCHEMA.SCHEMATA (`catalog_name` String, `schema_name` String, `schema_owner` String, `default_character_set_catalog` Nullable(String), `default_character_set_schema` Nullable(String), `default_character_set_name` Nullable(String), `sql_path` Nullable(String), `CATALOG_NAME` String, `SCHEMA_NAME` String, `SCHEMA_OWNER` String, `DEFAULT_CHARACTER_SET_CATALOG` Nullable(String), `DEFAULT_CHARACTER_SET_SCHEMA` Nullable(String), `DEFAULT_CHARACTER_SET_NAME` Nullable(String), `SQL_PATH` Nullable(String)) SQL SECURITY INVOKER AS SELECT name AS catalog_name, name AS schema_name, 'default' AS schema_owner, NULL AS default_character_set_catalog, NULL AS default_character_set_schema, NULL AS default_character_set_name, NULL AS sql_path, catalog_name AS CATALOG_NAME, schema_name AS SCHEMA_NAME, schema_owner AS SCHEMA_OWNER, default_character_set_catalog AS DEFAULT_CHARACTER_SET_CATALOG, default_character_set_schema AS DEFAULT_CHARACTER_SET_SCHEMA, default_character_set_name AS DEFAULT_CHARACTER_SET_NAME, sql_path AS SQL_PATH FROM system.databases"
    },
    {
        "view_name": "STATISTICS",
        "database": "INFORMATION_SCHEMA",
        "view_definition": "CREATE VIEW INFORMATION_SCHEMA.STATISTICS (`table_catalog` String, `table_schema` String, `table_name` String, `non_unique` Int32, `index_schema` String, `index_name` Nullable(String), `seq_in_index` UInt32, `column_name` Nullable(String), `collation` Nullable(String), `cardinality` Nullable(Int64), `sub_part` Nullable(Int64), `packed` Nullable(String), `nullable` String, `index_type` String, `comment` String, `index_comment` String, `is_visible` String, `expression` Nullable(String), `TABLE_CATALOG` String, `TABLE_SCHEMA` String, `TABLE_NAME` String, `NON_UNIQUE` Int32, `INDEX_SCHEMA` String, `INDEX_NAME` Nullable(String), `SEQ_IN_INDEX` UInt32, `COLUMN_NAME` Nullable(String), `COLLATION` Nullable(String), `CARDINALITY` Nullable(Int64), `SUB_PART` Nullable(Int64), `PACKED` Nullable(String), `NULLABLE` String, `INDEX_TYPE` String, `COMMENT` String, `INDEX_COMMENT` String, `IS_VISIBLE` String, `EXPRESSION` Nullable(String)) SQL SECURITY INVOKER AS SELECT '' AS table_catalog, '' AS table_schema, '' AS table_name, 0 AS non_unique, '' AS index_schema, NULL AS index_name, 0 AS seq_in_index, NULL AS column_name, NULL AS collation, NULL AS cardinality, NULL AS sub_part, NULL AS packed, '' AS nullable, '' AS index_type, '' AS comment, '' AS index_comment, '' AS is_visible, NULL AS expression, table_catalog AS TABLE_CATALOG, table_schema AS TABLE_SCHEMA, table_name AS TABLE_NAME, non_unique AS NON_UNIQUE, index_schema AS INDEX_SCHEMA, index_name AS INDEX_NAME, seq_in_index AS SEQ_IN_INDEX, column_name AS COLUMN_NAME, collation AS COLLATION, cardinality AS CARDINALITY, sub_part AS SUB_PART, packed AS PACKED, nullable AS NULLABLE, index_type AS INDEX_TYPE, comment AS COMMENT, index_comment AS INDEX_COMMENT, is_visible AS IS_VISIBLE, expression AS EXPRESSION WHERE false"
    },
    {
        "view_name": "TABLES",
        "database": "INFORMATION_SCHEMA",
        "view_definition": "CREATE VIEW INFORMATION_SCHEMA.TABLES (`table_catalog` String, `table_schema` String, `table_name` String, `table_type` String, `table_rows` Nullable(UInt64), `data_length` Nullable(UInt64), `index_length` Nullable(UInt64), `table_collation` Nullable(String), `table_comment` Nullable(String), `TABLE_CATALOG` String, `TABLE_SCHEMA` String, `TABLE_NAME` String, `TABLE_TYPE` String, `TABLE_ROWS` Nullable(UInt64), `DATA_LENGTH` Nullable(UInt64), `TABLE_COLLATION` Nullable(String), `TABLE_COMMENT` Nullable(String)) SQL SECURITY INVOKER AS SELECT database AS table_catalog, database AS table_schema, name AS table_name, multiIf(is_temporary, 'LOCAL TEMPORARY', engine LIKE '%View', 'VIEW', engine LIKE 'System%', 'SYSTEM VIEW', has_own_data = 0, 'FOREIGN TABLE', 'BASE TABLE') AS table_type, total_rows AS table_rows, total_bytes AS data_length, sum(((p.primary_key_size + p.marks_bytes) + p.secondary_indices_compressed_bytes) + p.secondary_indices_marks_bytes) AS index_length, 'utf8mb4_0900_ai_ci' AS table_collation, comment AS table_comment, table_catalog AS TABLE_CATALOG, table_schema AS TABLE_SCHEMA, table_name AS TABLE_NAME, table_type AS TABLE_TYPE, table_rows AS TABLE_ROWS, data_length AS DATA_LENGTH, table_collation AS TABLE_COLLATION, table_comment AS TABLE_COMMENT FROM system.tables AS t LEFT JOIN system.parts AS p ON (t.database = p.database) AND (t.name = p.`table`) GROUP BY t.database, t.name, t.is_temporary, t.engine, t.has_own_data, t.total_rows, t.total_bytes, t.comment"
    },
    {
        "view_name": "VIEWS",
        "database": "INFORMATION_SCHEMA",
        "view_definition": "CREATE VIEW INFORMATION_SCHEMA.VIEWS (`table_catalog` String, `table_schema` String, `table_name` String, `view_definition` String, `check_option` String, `is_updatable` Enum8('NO' = 0, 'YES' = 1), `is_insertable_into` Enum8('NO' = 0, 'YES' = 1), `is_trigger_updatable` Enum8('NO' = 0, 'YES' = 1), `is_trigger_deletable` Enum8('NO' = 0, 'YES' = 1), `is_trigger_insertable_into` Enum8('NO' = 0, 'YES' = 1), `TABLE_CATALOG` String, `TABLE_SCHEMA` String, `TABLE_NAME` String, `VIEW_DEFINITION` String, `CHECK_OPTION` String, `IS_UPDATABLE` Enum8('NO' = 0, 'YES' = 1), `IS_INSERTABLE_INTO` Enum8('NO' = 0, 'YES' = 1), `IS_TRIGGER_UPDATABLE` Enum8('NO' = 0, 'YES' = 1), `IS_TRIGGER_DELETABLE` Enum8('NO' = 0, 'YES' = 1), `IS_TRIGGER_INSERTABLE_INTO` Enum8('NO' = 0, 'YES' = 1)) SQL SECURITY INVOKER AS SELECT database AS table_catalog, database AS table_schema, name AS table_name, as_select AS view_definition, 'NONE' AS check_option, 0 AS is_updatable, engine = 'MaterializedView' AS is_insertable_into, 0 AS is_trigger_updatable, 0 AS is_trigger_deletable, 0 AS is_trigger_insertable_into, table_catalog AS TABLE_CATALOG, table_schema AS TABLE_SCHEMA, table_name AS TABLE_NAME, view_definition AS VIEW_DEFINITION, check_option AS CHECK_OPTION, is_updatable AS IS_UPDATABLE, is_insertable_into AS IS_INSERTABLE_INTO, is_trigger_updatable AS IS_TRIGGER_UPDATABLE, is_trigger_deletable AS IS_TRIGGER_DELETABLE, is_trigger_insertable_into AS IS_TRIGGER_INSERTABLE_INTO FROM system.tables WHERE engine LIKE '%View'"
    },
    {
        "view_name": "character_sets",
        "database": "INFORMATION_SCHEMA",
        "view_definition": "CREATE VIEW INFORMATION_SCHEMA.character_sets (`character_set_name` String, `CHARACTER_SET_NAME` String) SQL SECURITY INVOKER AS SELECT arrayJoin(['utf8', 'utf8mb4', 'ascii', 'binary']) AS character_set_name, character_set_name AS CHARACTER_SET_NAME"
    },
    {
        "view_name": "collations",
        "database": "INFORMATION_SCHEMA",
        "view_definition": "CREATE VIEW INFORMATION_SCHEMA.collations (`collation_name` String, `COLLATION_NAME` String) SQL SECURITY INVOKER AS SELECT name AS collation_name, collation_name AS COLLATION_NAME FROM system.collations"
    },
    {
        "view_name": "columns",
        "database": "INFORMATION_SCHEMA",
        "view_definition": "CREATE VIEW INFORMATION_SCHEMA.columns (`table_catalog` String, `table_schema` String, `table_name` String, `column_name` String, `ordinal_position` UInt64, `column_default` String, `is_nullable` String, `data_type` String, `character_maximum_length` Nullable(UInt64), `character_octet_length` Nullable(UInt64), `numeric_precision` Nullable(UInt64), `numeric_precision_radix` Nullable(UInt64), `numeric_scale` Nullable(UInt64), `datetime_precision` Nullable(UInt64), `character_set_catalog` Nullable(String), `character_set_schema` Nullable(String), `character_set_name` Nullable(String), `collation_catalog` Nullable(String), `collation_schema` Nullable(String), `collation_name` Nullable(String), `domain_catalog` Nullable(String), `domain_schema` Nullable(String), `domain_name` Nullable(String), `extra` Nullable(String), `column_comment` String, `column_type` String, `TABLE_CATALOG` String, `TABLE_SCHEMA` String, `TABLE_NAME` String, `COLUMN_NAME` String, `ORDINAL_POSITION` UInt64, `COLUMN_DEFAULT` String, `IS_NULLABLE` String, `DATA_TYPE` String, `CHARACTER_MAXIMUM_LENGTH` Nullable(UInt64), `CHARACTER_OCTET_LENGTH` Nullable(UInt64), `NUMERIC_PRECISION` Nullable(UInt64), `NUMERIC_PRECISION_RADIX` Nullable(UInt64), `NUMERIC_SCALE` Nullable(UInt64), `DATETIME_PRECISION` Nullable(UInt64), `CHARACTER_SET_CATALOG` Nullable(String), `CHARACTER_SET_SCHEMA` Nullable(String), `CHARACTER_SET_NAME` Nullable(String), `COLLATION_CATALOG` Nullable(String), `COLLATION_SCHEMA` Nullable(String), `COLLATION_NAME` Nullable(String), `DOMAIN_CATALOG` Nullable(String), `DOMAIN_SCHEMA` Nullable(String), `DOMAIN_NAME` Nullable(String), `EXTRA` Nullable(String), `COLUMN_COMMENT` String, `COLUMN_TYPE` String) SQL SECURITY INVOKER AS SELECT database AS table_catalog, database AS table_schema, `table` AS table_name, name AS column_name, position AS ordinal_position, default_expression AS column_default, type LIKE 'Nullable(%)' AS is_nullable, type AS data_type, character_octet_length AS character_maximum_length, character_octet_length, numeric_precision, numeric_precision_radix, numeric_scale, datetime_precision, NULL AS character_set_catalog, NULL AS character_set_schema, NULL AS character_set_name, NULL AS collation_catalog, NULL AS collation_schema, NULL AS collation_name, NULL AS domain_catalog, NULL AS domain_schema, NULL AS domain_name, multiIf(default_kind = 'DEFAULT', 'DEFAULT_GENERATED', default_kind = 'MATERIALIZED', 'STORED GENERATED', default_kind = 'ALIAS', 'VIRTUAL GENERATED', '') AS extra, comment AS column_comment, type AS column_type, table_catalog AS TABLE_CATALOG, table_schema AS TABLE_SCHEMA, table_name AS TABLE_NAME, column_name AS COLUMN_NAME, ordinal_position AS ORDINAL_POSITION, column_default AS COLUMN_DEFAULT, is_nullable AS IS_NULLABLE, data_type AS DATA_TYPE, character_maximum_length AS CHARACTER_MAXIMUM_LENGTH, character_octet_length AS CHARACTER_OCTET_LENGTH, numeric_precision AS NUMERIC_PRECISION, numeric_precision_radix AS NUMERIC_PRECISION_RADIX, numeric_scale AS NUMERIC_SCALE, datetime_precision AS DATETIME_PRECISION, character_set_catalog AS CHARACTER_SET_CATALOG, character_set_schema AS CHARACTER_SET_SCHEMA, character_set_name AS CHARACTER_SET_NAME, collation_catalog AS COLLATION_CATALOG, collation_schema AS COLLATION_SCHEMA, collation_name AS COLLATION_NAME, domain_catalog AS DOMAIN_CATALOG, domain_schema AS DOMAIN_SCHEMA, domain_name AS DOMAIN_NAME, extra AS EXTRA, column_comment AS COLUMN_COMMENT, column_type AS COLUMN_TYPE FROM system.columns"
    },
    {
        "view_name": "engines",
        "database": "INFORMATION_SCHEMA",
        "view_definition": "CREATE VIEW INFORMATION_SCHEMA.engines (`engine` String, `support` String, `ENGINE` String, `SUPPORT` String) SQL SECURITY INVOKER AS SELECT name AS engine, if(engine = getSetting('default_table_engine'), 'DEFAULT', 'YES') AS support, engine AS ENGINE, support AS SUPPORT FROM system.table_engines"
    },
    {
        "view_name": "key_column_usage",
        "database": "INFORMATION_SCHEMA",
        "view_definition": "CREATE VIEW INFORMATION_SCHEMA.key_column_usage (`constraint_catalog` String, `constraint_schema` String, `constraint_name` Nullable(String), `table_catalog` String, `table_schema` String, `table_name` String, `column_name` Nullable(String), `ordinal_position` UInt32, `position_in_unique_constraint` Nullable(UInt32), `referenced_table_schema` Nullable(String), `referenced_table_name` Nullable(String), `referenced_column_name` Nullable(String), `CONSTRAINT_CATALOG` Nullable(String), `CONSTRAINT_SCHEMA` Nullable(String), `CONSTRAINT_NAME` Nullable(String), `TABLE_CATALOG` String, `TABLE_SCHEMA` String, `TABLE_NAME` String, `COLUMN_NAME` Nullable(String), `ORDINAL_POSITION` UInt32, `POSITION_IN_UNIQUE_CONSTRAINT` Nullable(UInt32), `REFERENCED_TABLE_SCHEMA` Nullable(String), `REFERENCED_TABLE_NAME` Nullable(String), `REFERENCED_COLUMN_NAME` Nullable(String)) SQL SECURITY INVOKER AS SELECT 'def' AS constraint_catalog, database AS constraint_schema, 'PRIMARY' AS constraint_name, 'def' AS table_catalog, database AS table_schema, `table` AS table_name, name AS column_name, 1 AS ordinal_position, NULL AS position_in_unique_constraint, NULL AS referenced_table_schema, NULL AS referenced_table_name, NULL AS referenced_column_name, constraint_catalog AS CONSTRAINT_CATALOG, constraint_schema AS CONSTRAINT_SCHEMA, constraint_name AS CONSTRAINT_NAME, table_catalog AS TABLE_CATALOG, table_schema AS TABLE_SCHEMA, table_name AS TABLE_NAME, column_name AS COLUMN_NAME, ordinal_position AS ORDINAL_POSITION, position_in_unique_constraint AS POSITION_IN_UNIQUE_CONSTRAINT, referenced_table_schema AS REFERENCED_TABLE_SCHEMA, referenced_table_name AS REFERENCED_TABLE_NAME, referenced_column_name AS REFERENCED_COLUMN_NAME FROM system.columns WHERE is_in_primary_key"
    },
    {
        "view_name": "referential_constraints",
        "database": "INFORMATION_SCHEMA",
        "view_definition": "CREATE VIEW INFORMATION_SCHEMA.referential_constraints (`constraint_catalog` String, `constraint_schema` String, `constraint_name` Nullable(String), `unique_constraint_catalog` String, `unique_constraint_schema` String, `unique_constraint_name` Nullable(String), `match_option` String, `update_rule` String, `delete_rule` String, `table_name` String, `referenced_table_name` String, `CONSTRAINT_CATALOG` String, `CONSTRAINT_SCHEMA` String, `CONSTRAINT_NAME` Nullable(String), `UNIQUE_CONSTRAINT_CATALOG` String, `UNIQUE_CONSTRAINT_SCHEMA` String, `UNIQUE_CONSTRAINT_NAME` Nullable(String), `MATCH_OPTION` String, `UPDATE_RULE` String, `DELETE_RULE` String, `TABLE_NAME` String, `REFERENCED_TABLE_NAME` String) SQL SECURITY INVOKER AS SELECT '' AS constraint_catalog, NULL AS constraint_name, '' AS constraint_schema, '' AS unique_constraint_catalog, NULL AS unique_constraint_name, '' AS unique_constraint_schema, '' AS match_option, '' AS update_rule, '' AS delete_rule, '' AS table_name, '' AS referenced_table_name, constraint_catalog AS CONSTRAINT_CATALOG, constraint_name AS CONSTRAINT_NAME, constraint_schema AS CONSTRAINT_SCHEMA, unique_constraint_catalog AS UNIQUE_CONSTRAINT_CATALOG, unique_constraint_name AS UNIQUE_CONSTRAINT_NAME, unique_constraint_schema AS UNIQUE_CONSTRAINT_SCHEMA, match_option AS MATCH_OPTION, update_rule AS UPDATE_RULE, delete_rule AS DELETE_RULE, table_name AS TABLE_NAME, referenced_table_name AS REFERENCED_TABLE_NAME WHERE false"
    },
    {
        "view_name": "schemata",
        "database": "INFORMATION_SCHEMA",
        "view_definition": "CREATE VIEW INFORMATION_SCHEMA.schemata (`catalog_name` String, `schema_name` String, `schema_owner` String, `default_character_set_catalog` Nullable(String), `default_character_set_schema` Nullable(String), `default_character_set_name` Nullable(String), `sql_path` Nullable(String), `CATALOG_NAME` String, `SCHEMA_NAME` String, `SCHEMA_OWNER` String, `DEFAULT_CHARACTER_SET_CATALOG` Nullable(String), `DEFAULT_CHARACTER_SET_SCHEMA` Nullable(String), `DEFAULT_CHARACTER_SET_NAME` Nullable(String), `SQL_PATH` Nullable(String)) SQL SECURITY INVOKER AS SELECT name AS catalog_name, name AS schema_name, 'default' AS schema_owner, NULL AS default_character_set_catalog, NULL AS default_character_set_schema, NULL AS default_character_set_name, NULL AS sql_path, catalog_name AS CATALOG_NAME, schema_name AS SCHEMA_NAME, schema_owner AS SCHEMA_OWNER, default_character_set_catalog AS DEFAULT_CHARACTER_SET_CATALOG, default_character_set_schema AS DEFAULT_CHARACTER_SET_SCHEMA, default_character_set_name AS DEFAULT_CHARACTER_SET_NAME, sql_path AS SQL_PATH FROM system.databases"
    },
    {
        "view_name": "statistics",
        "database": "INFORMATION_SCHEMA",
        "view_definition": "CREATE VIEW INFORMATION_SCHEMA.statistics (`table_catalog` String, `table_schema` String, `table_name` String, `non_unique` Int32, `index_schema` String, `index_name` Nullable(String), `seq_in_index` UInt32, `column_name` Nullable(String), `collation` Nullable(String), `cardinality` Nullable(Int64), `sub_part` Nullable(Int64), `packed` Nullable(String), `nullable` String, `index_type` String, `comment` String, `index_comment` String, `is_visible` String, `expression` Nullable(String), `TABLE_CATALOG` String, `TABLE_SCHEMA` String, `TABLE_NAME` String, `NON_UNIQUE` Int32, `INDEX_SCHEMA` String, `INDEX_NAME` Nullable(String), `SEQ_IN_INDEX` UInt32, `COLUMN_NAME` Nullable(String), `COLLATION` Nullable(String), `CARDINALITY` Nullable(Int64), `SUB_PART` Nullable(Int64), `PACKED` Nullable(String), `NULLABLE` String, `INDEX_TYPE` String, `COMMENT` String, `INDEX_COMMENT` String, `IS_VISIBLE` String, `EXPRESSION` Nullable(String)) SQL SECURITY INVOKER AS SELECT '' AS table_catalog, '' AS table_schema, '' AS table_name, 0 AS non_unique, '' AS index_schema, NULL AS index_name, 0 AS seq_in_index, NULL AS column_name, NULL AS collation, NULL AS cardinality, NULL AS sub_part, NULL AS packed, '' AS nullable, '' AS index_type, '' AS comment, '' AS index_comment, '' AS is_visible, NULL AS expression, table_catalog AS TABLE_CATALOG, table_schema AS TABLE_SCHEMA, table_name AS TABLE_NAME, non_unique AS NON_UNIQUE, index_schema AS INDEX_SCHEMA, index_name AS INDEX_NAME, seq_in_index AS SEQ_IN_INDEX, column_name AS COLUMN_NAME, collation AS COLLATION, cardinality AS CARDINALITY, sub_part AS SUB_PART, packed AS PACKED, nullable AS NULLABLE, index_type AS INDEX_TYPE, comment AS COMMENT, index_comment AS INDEX_COMMENT, is_visible AS IS_VISIBLE, expression AS EXPRESSION WHERE false"
    },
    {
        "view_name": "tables",
        "database": "INFORMATION_SCHEMA",
        "view_definition": "CREATE VIEW INFORMATION_SCHEMA.tables (`table_catalog` String, `table_schema` String, `table_name` String, `table_type` String, `table_rows` Nullable(UInt64), `data_length` Nullable(UInt64), `index_length` Nullable(UInt64), `table_collation` Nullable(String), `table_comment` Nullable(String), `TABLE_CATALOG` String, `TABLE_SCHEMA` String, `TABLE_NAME` String, `TABLE_TYPE` String, `TABLE_ROWS` Nullable(UInt64), `DATA_LENGTH` Nullable(UInt64), `TABLE_COLLATION` Nullable(String), `TABLE_COMMENT` Nullable(String)) SQL SECURITY INVOKER AS SELECT database AS table_catalog, database AS table_schema, name AS table_name, multiIf(is_temporary, 'LOCAL TEMPORARY', engine LIKE '%View', 'VIEW', engine LIKE 'System%', 'SYSTEM VIEW', has_own_data = 0, 'FOREIGN TABLE', 'BASE TABLE') AS table_type, total_rows AS table_rows, total_bytes AS data_length, sum(((p.primary_key_size + p.marks_bytes) + p.secondary_indices_compressed_bytes) + p.secondary_indices_marks_bytes) AS index_length, 'utf8mb4_0900_ai_ci' AS table_collation, comment AS table_comment, table_catalog AS TABLE_CATALOG, table_schema AS TABLE_SCHEMA, table_name AS TABLE_NAME, table_type AS TABLE_TYPE, table_rows AS TABLE_ROWS, data_length AS DATA_LENGTH, table_collation AS TABLE_COLLATION, table_comment AS TABLE_COMMENT FROM system.tables AS t LEFT JOIN system.parts AS p ON (t.database = p.database) AND (t.name = p.`table`) GROUP BY t.database, t.name, t.is_temporary, t.engine, t.has_own_data, t.total_rows, t.total_bytes, t.comment"
    },
    {
        "view_name": "views",
        "database": "INFORMATION_SCHEMA",
        "view_definition": "CREATE VIEW INFORMATION_SCHEMA.views (`table_catalog` String, `table_schema` String, `table_name` String, `view_definition` String, `check_option` String, `is_updatable` Enum8('NO' = 0, 'YES' = 1), `is_insertable_into` Enum8('NO' = 0, 'YES' = 1), `is_trigger_updatable` Enum8('NO' = 0, 'YES' = 1), `is_trigger_deletable` Enum8('NO' = 0, 'YES' = 1), `is_trigger_insertable_into` Enum8('NO' = 0, 'YES' = 1), `TABLE_CATALOG` String, `TABLE_SCHEMA` String, `TABLE_NAME` String, `VIEW_DEFINITION` String, `CHECK_OPTION` String, `IS_UPDATABLE` Enum8('NO' = 0, 'YES' = 1), `IS_INSERTABLE_INTO` Enum8('NO' = 0, 'YES' = 1), `IS_TRIGGER_UPDATABLE` Enum8('NO' = 0, 'YES' = 1), `IS_TRIGGER_DELETABLE` Enum8('NO' = 0, 'YES' = 1), `IS_TRIGGER_INSERTABLE_INTO` Enum8('NO' = 0, 'YES' = 1)) SQL SECURITY INVOKER AS SELECT database AS table_catalog, database AS table_schema, name AS table_name, as_select AS view_definition, 'NONE' AS check_option, 0 AS is_updatable, engine = 'MaterializedView' AS is_insertable_into, 0 AS is_trigger_updatable, 0 AS is_trigger_deletable, 0 AS is_trigger_insertable_into, table_catalog AS TABLE_CATALOG, table_schema AS TABLE_SCHEMA, table_name AS TABLE_NAME, view_definition AS VIEW_DEFINITION, check_option AS CHECK_OPTION, is_updatable AS IS_UPDATABLE, is_insertable_into AS IS_INSERTABLE_INTO, is_trigger_updatable AS IS_TRIGGER_UPDATABLE, is_trigger_deletable AS IS_TRIGGER_DELETABLE, is_trigger_insertable_into AS IS_TRIGGER_INSERTABLE_INTO FROM system.tables WHERE engine LIKE '%View'"
    },
    {
        "view_name": "activity_pair_thresholds_analyzer_IncidentManagement",
        "database": "default",
        "view_definition": "CREATE VIEW default.activity_pair_thresholds_analyzer_IncidentManagement (`Transition` String, `Occurrences` UInt64, `Avg (h)` Float64, `Std Dev (h)` Float64, `Min (h)` Float64, `P25 (h)` Float64, `Median (h)` Float64, `P75 (h)` Float64, `Max (h)` Float64) AS WITH ordered_events AS (SELECT case_id, activity, timestamp, row_number() OVER (PARTITION BY case_id ORDER BY parseDateTimeBestEffort(timestamp) ASC) AS rn FROM default.IncidentManagement), event_pairs AS (SELECT a.case_id, a.activity AS to_activity, a.timestamp AS to_timestamp, b.activity AS from_activity, b.timestamp AS from_timestamp FROM ordered_events AS a INNER JOIN ordered_events AS b ON (a.case_id = b.case_id) AND (a.rn = (b.rn + 1))), transitions AS (SELECT concat(from_activity, ' > ', to_activity) AS transition, round((toUnixTimestamp(parseDateTimeBestEffort(to_timestamp)) - toUnixTimestamp(parseDateTimeBestEffort(from_timestamp))) / 3600., 2) AS duration_hours FROM event_pairs WHERE (duration_hours > 0) AND (duration_hours < 1000)) SELECT transition AS Transition, count(*) AS Occurrences, round(avg(duration_hours), 2) AS `Avg (h)`, round(stddevPop(duration_hours), 2) AS `Std Dev (h)`, round(min(duration_hours), 2) AS `Min (h)`, round(quantile(0.25)(duration_hours), 2) AS `P25 (h)`, round(quantile(0.5)(duration_hours), 2) AS `Median (h)`, round(quantile(0.75)(duration_hours), 2) AS `P75 (h)`, round(max(duration_hours), 2) AS `Max (h)` FROM transitions GROUP BY transition HAVING count(*) >= 5 ORDER BY `Std Dev (h)` DESC"
    },
    {
        "view_name": "activity_pair_thresholds_analyzer_ap_event_log",
        "database": "default",
        "view_definition": "CREATE VIEW default.activity_pair_thresholds_analyzer_ap_event_log (`Transition` String, `Occurrences` UInt64, `Avg (h)` Float64, `Std Dev (h)` Float64, `Min (h)` Float64, `P25 (h)` Float64, `Median (h)` Float64, `P75 (h)` Float64, `Max (h)` Float64) AS WITH ordered_events AS (SELECT case_id, activity, timestamp, row_number() OVER (PARTITION BY case_id ORDER BY parseDateTimeBestEffort(timestamp) ASC) AS rn FROM default.ap_event_log), event_pairs AS (SELECT a.case_id, a.activity AS to_activity, a.timestamp AS to_timestamp, b.activity AS from_activity, b.timestamp AS from_timestamp FROM ordered_events AS a INNER JOIN ordered_events AS b ON (a.case_id = b.case_id) AND (a.rn = (b.rn + 1))), transitions AS (SELECT concat(from_activity, ' > ', to_activity) AS transition, round((toUnixTimestamp(parseDateTimeBestEffort(to_timestamp)) - toUnixTimestamp(parseDateTimeBestEffort(from_timestamp))) / 3600., 2) AS duration_hours FROM event_pairs WHERE (duration_hours > 0) AND (duration_hours < 1000)) SELECT transition AS Transition, count(*) AS Occurrences, round(avg(duration_hours), 2) AS `Avg (h)`, round(stddevPop(duration_hours), 2) AS `Std Dev (h)`, round(min(duration_hours), 2) AS `Min (h)`, round(quantile(0.25)(duration_hours), 2) AS `P25 (h)`, round(quantile(0.5)(duration_hours), 2) AS `Median (h)`, round(quantile(0.75)(duration_hours), 2) AS `P75 (h)`, round(max(duration_hours), 2) AS `Max (h)` FROM transitions GROUP BY transition HAVING count(*) >= 5 ORDER BY `Std Dev (h)` DESC"
    },
    {
        "view_name": "activity_pair_thresholds_analyzer_ar_event_log",
        "database": "default",
        "view_definition": "CREATE VIEW default.activity_pair_thresholds_analyzer_ar_event_log (`Transition` String, `Occurrences` UInt64, `Avg (h)` Float64, `Std Dev (h)` Float64, `Min (h)` Float64, `P25 (h)` Float64, `Median (h)` Float64, `P75 (h)` Float64, `Max (h)` Float64) AS WITH ordered_events AS (SELECT case_id, activity, timestamp, row_number() OVER (PARTITION BY case_id ORDER BY parseDateTimeBestEffort(timestamp) ASC) AS rn FROM default.ar_event_log), event_pairs AS (SELECT a.case_id, a.activity AS to_activity, a.timestamp AS to_timestamp, b.activity AS from_activity, b.timestamp AS from_timestamp FROM ordered_events AS a INNER JOIN ordered_events AS b ON (a.case_id = b.case_id) AND (a.rn = (b.rn + 1))), transitions AS (SELECT concat(from_activity, ' > ', to_activity) AS transition, round((toUnixTimestamp(parseDateTimeBestEffort(to_timestamp)) - toUnixTimestamp(parseDateTimeBestEffort(from_timestamp))) / 3600., 2) AS duration_hours FROM event_pairs WHERE (duration_hours > 0) AND (duration_hours < 1000)) SELECT transition AS Transition, count(*) AS Occurrences, round(avg(duration_hours), 2) AS `Avg (h)`, round(stddevPop(duration_hours), 2) AS `Std Dev (h)`, round(min(duration_hours), 2) AS `Min (h)`, round(quantile(0.25)(duration_hours), 2) AS `P25 (h)`, round(quantile(0.5)(duration_hours), 2) AS `Median (h)`, round(quantile(0.75)(duration_hours), 2) AS `P75 (h)`, round(max(duration_hours), 2) AS `Max (h)` FROM transitions GROUP BY transition HAVING count(*) >= 5 ORDER BY `Std Dev (h)` DESC"
    },
    {
        "view_name": "activity_pair_thresholds_analyzer_car_insurance_claims",
        "database": "default",
        "view_definition": "CREATE VIEW default.activity_pair_thresholds_analyzer_car_insurance_claims (`Transition` String, `Occurrences` UInt64, `Avg (h)` Float64, `Std Dev (h)` Float64, `Min (h)` Float64, `P25 (h)` Float64, `Median (h)` Float64, `P75 (h)` Float64, `Max (h)` Float64) AS WITH ordered_events AS (SELECT case_id, activity, timestamp, row_number() OVER (PARTITION BY case_id ORDER BY parseDateTimeBestEffort(timestamp) ASC) AS rn FROM default.car_insurance_claims), event_pairs AS (SELECT a.case_id, a.activity AS to_activity, a.timestamp AS to_timestamp, b.activity AS from_activity, b.timestamp AS from_timestamp FROM ordered_events AS a INNER JOIN ordered_events AS b ON (a.case_id = b.case_id) AND (a.rn = (b.rn + 1))), transitions AS (SELECT concat(from_activity, ' > ', to_activity) AS transition, round((toUnixTimestamp(parseDateTimeBestEffort(to_timestamp)) - toUnixTimestamp(parseDateTimeBestEffort(from_timestamp))) / 3600., 2) AS duration_hours FROM event_pairs WHERE (duration_hours > 0) AND (duration_hours < 1000)) SELECT transition AS Transition, count(*) AS Occurrences, round(avg(duration_hours), 2) AS `Avg (h)`, round(stddevPop(duration_hours), 2) AS `Std Dev (h)`, round(min(duration_hours), 2) AS `Min (h)`, round(quantile(0.25)(duration_hours), 2) AS `P25 (h)`, round(quantile(0.5)(duration_hours), 2) AS `Median (h)`, round(quantile(0.75)(duration_hours), 2) AS `P75 (h)`, round(max(duration_hours), 2) AS `Max (h)` FROM transitions GROUP BY transition HAVING count(*) >= 5 ORDER BY `Std Dev (h)` DESC"
    },
    {
        "view_name": "activity_pair_thresholds_analyzer_hire_to_retire_event_log",
        "database": "default",
        "view_definition": "CREATE VIEW default.activity_pair_thresholds_analyzer_hire_to_retire_event_log (`Transition` String, `Occurrences` UInt64, `Avg (h)` Float64, `Std Dev (h)` Float64, `Min (h)` Float64, `P25 (h)` Float64, `Median (h)` Float64, `P75 (h)` Float64, `Max (h)` Float64) AS WITH ordered_events AS (SELECT case_id, activity, timestamp, row_number() OVER (PARTITION BY case_id ORDER BY parseDateTimeBestEffort(timestamp) ASC) AS rn FROM default.hire_to_retire_event_log), event_pairs AS (SELECT a.case_id, a.activity AS to_activity, a.timestamp AS to_timestamp, b.activity AS from_activity, b.timestamp AS from_timestamp FROM ordered_events AS a INNER JOIN ordered_events AS b ON (a.case_id = b.case_id) AND (a.rn = (b.rn + 1))), transitions AS (SELECT concat(from_activity, ' > ', to_activity) AS transition, round((toUnixTimestamp(parseDateTimeBestEffort(to_timestamp)) - toUnixTimestamp(parseDateTimeBestEffort(from_timestamp))) / 3600., 2) AS duration_hours FROM event_pairs WHERE (duration_hours > 0) AND (duration_hours < 1000)) SELECT transition AS Transition, count(*) AS Occurrences, round(avg(duration_hours), 2) AS `Avg (h)`, round(stddevPop(duration_hours), 2) AS `Std Dev (h)`, round(min(duration_hours), 2) AS `Min (h)`, round(quantile(0.25)(duration_hours), 2) AS `P25 (h)`, round(quantile(0.5)(duration_hours), 2) AS `Median (h)`, round(quantile(0.75)(duration_hours), 2) AS `P75 (h)`, round(max(duration_hours), 2) AS `Max (h)` FROM transitions GROUP BY transition HAVING count(*) >= 5 ORDER BY `Std Dev (h)` DESC"
    },
    {
        "view_name": "activity_pair_thresholds_analyzer_logistics_event_log",
        "database": "default",
        "view_definition": "CREATE VIEW default.activity_pair_thresholds_analyzer_logistics_event_log (`Transition` String, `Occurrences` UInt64, `Avg (h)` Float64, `Std Dev (h)` Float64, `Min (h)` Float64, `P25 (h)` Float64, `Median (h)` Float64, `P75 (h)` Float64, `Max (h)` Float64) AS WITH ordered_events AS (SELECT case_id, activity, timestamp, row_number() OVER (PARTITION BY case_id ORDER BY parseDateTimeBestEffort(timestamp) ASC) AS rn FROM default.logistics_event_log), event_pairs AS (SELECT a.case_id, a.activity AS to_activity, a.timestamp AS to_timestamp, b.activity AS from_activity, b.timestamp AS from_timestamp FROM ordered_events AS a INNER JOIN ordered_events AS b ON (a.case_id = b.case_id) AND (a.rn = (b.rn + 1))), transitions AS (SELECT concat(from_activity, ' > ', to_activity) AS transition, round((toUnixTimestamp(parseDateTimeBestEffort(to_timestamp)) - toUnixTimestamp(parseDateTimeBestEffort(from_timestamp))) / 3600., 2) AS duration_hours FROM event_pairs WHERE (duration_hours > 0) AND (duration_hours < 1000)) SELECT transition AS Transition, count(*) AS Occurrences, round(avg(duration_hours), 2) AS `Avg (h)`, round(stddevPop(duration_hours), 2) AS `Std Dev (h)`, round(min(duration_hours), 2) AS `Min (h)`, round(quantile(0.25)(duration_hours), 2) AS `P25 (h)`, round(quantile(0.5)(duration_hours), 2) AS `Median (h)`, round(quantile(0.75)(duration_hours), 2) AS `P75 (h)`, round(max(duration_hours), 2) AS `Max (h)` FROM transitions GROUP BY transition HAVING count(*) >= 5 ORDER BY `Std Dev (h)` DESC"
    },
    {
        "view_name": "activity_pair_thresholds_analyzer_mortgage_events",
        "database": "default",
        "view_definition": "CREATE VIEW default.activity_pair_thresholds_analyzer_mortgage_events (`Transition` String, `Occurrences` UInt64, `Avg (h)` Float64, `Std Dev (h)` Float64, `Min (h)` Float64, `P25 (h)` Float64, `Median (h)` Float64, `P75 (h)` Float64, `Max (h)` Float64) AS WITH ordered_events AS (SELECT case_id, activity, timestamp, row_number() OVER (PARTITION BY case_id ORDER BY parseDateTimeBestEffort(timestamp) ASC) AS rn FROM default.mortgage_events), event_pairs AS (SELECT a.case_id, a.activity AS to_activity, a.timestamp AS to_timestamp, b.activity AS from_activity, b.timestamp AS from_timestamp FROM ordered_events AS a INNER JOIN ordered_events AS b ON (a.case_id = b.case_id) AND (a.rn = (b.rn + 1))), transitions AS (SELECT concat(from_activity, ' > ', to_activity) AS transition, round((toUnixTimestamp(parseDateTimeBestEffort(to_timestamp)) - toUnixTimestamp(parseDateTimeBestEffort(from_timestamp))) / 3600., 2) AS duration_hours FROM event_pairs WHERE (duration_hours > 0) AND (duration_hours < 1000)) SELECT transition AS Transition, count(*) AS Occurrences, round(avg(duration_hours), 2) AS `Avg (h)`, round(stddevPop(duration_hours), 2) AS `Std Dev (h)`, round(min(duration_hours), 2) AS `Min (h)`, round(quantile(0.25)(duration_hours), 2) AS `P25 (h)`, round(quantile(0.5)(duration_hours), 2) AS `Median (h)`, round(quantile(0.75)(duration_hours), 2) AS `P75 (h)`, round(max(duration_hours), 2) AS `Max (h)` FROM transitions GROUP BY transition HAVING count(*) >= 5 ORDER BY `Std Dev (h)` DESC"
    },
    {
        "view_name": "activity_pair_thresholds_analyzer_o2c_event_log",
        "database": "default",
        "view_definition": "CREATE VIEW default.activity_pair_thresholds_analyzer_o2c_event_log (`Transition` String, `Occurrences` UInt64, `Avg (h)` Float64, `Std Dev (h)` Float64, `Min (h)` Float64, `P25 (h)` Float64, `Median (h)` Float64, `P75 (h)` Float64, `Max (h)` Float64) AS WITH ordered_events AS (SELECT case_id, activity, timestamp, row_number() OVER (PARTITION BY case_id ORDER BY parseDateTimeBestEffort(timestamp) ASC) AS rn FROM default.o2c_event_log), event_pairs AS (SELECT a.case_id, a.activity AS to_activity, a.timestamp AS to_timestamp, b.activity AS from_activity, b.timestamp AS from_timestamp FROM ordered_events AS a INNER JOIN ordered_events AS b ON (a.case_id = b.case_id) AND (a.rn = (b.rn + 1))), transitions AS (SELECT concat(from_activity, ' > ', to_activity) AS transition, round((toUnixTimestamp(parseDateTimeBestEffort(to_timestamp)) - toUnixTimestamp(parseDateTimeBestEffort(from_timestamp))) / 3600., 2) AS duration_hours FROM event_pairs WHERE (duration_hours > 0) AND (duration_hours < 1000)) SELECT transition AS Transition, count(*) AS Occurrences, round(avg(duration_hours), 2) AS `Avg (h)`, round(stddevPop(duration_hours), 2) AS `Std Dev (h)`, round(min(duration_hours), 2) AS `Min (h)`, round(quantile(0.25)(duration_hours), 2) AS `P25 (h)`, round(quantile(0.5)(duration_hours), 2) AS `Median (h)`, round(quantile(0.75)(duration_hours), 2) AS `P75 (h)`, round(max(duration_hours), 2) AS `Max (h)` FROM transitions GROUP BY transition HAVING count(*) >= 5 ORDER BY `Std Dev (h)` DESC"
    },
    {
        "view_name": "activity_pair_thresholds_analyzer_p2p_event_log",
        "database": "default",
        "view_definition": "CREATE VIEW default.activity_pair_thresholds_analyzer_p2p_event_log (`Transition` String, `Occurrences` UInt64, `Avg (h)` Float64, `Std Dev (h)` Float64, `Min (h)` Float64, `P25 (h)` Float64, `Median (h)` Float64, `P75 (h)` Float64, `Max (h)` Float64) AS WITH ordered_events AS (SELECT case_id, activity, timestamp, row_number() OVER (PARTITION BY case_id ORDER BY parseDateTimeBestEffort(timestamp) ASC) AS rn FROM default.p2p_event_log), event_pairs AS (SELECT a.case_id, a.activity AS to_activity, a.timestamp AS to_timestamp, b.activity AS from_activity, b.timestamp AS from_timestamp FROM ordered_events AS a INNER JOIN ordered_events AS b ON (a.case_id = b.case_id) AND (a.rn = (b.rn + 1))), transitions AS (SELECT concat(from_activity, ' > ', to_activity) AS transition, round((toUnixTimestamp(parseDateTimeBestEffort(to_timestamp)) - toUnixTimestamp(parseDateTimeBestEffort(from_timestamp))) / 3600., 2) AS duration_hours FROM event_pairs WHERE (duration_hours > 0) AND (duration_hours < 1000)) SELECT transition AS Transition, count(*) AS Occurrences, round(avg(duration_hours), 2) AS `Avg (h)`, round(stddevPop(duration_hours), 2) AS `Std Dev (h)`, round(min(duration_hours), 2) AS `Min (h)`, round(quantile(0.25)(duration_hours), 2) AS `P25 (h)`, round(quantile(0.5)(duration_hours), 2) AS `Median (h)`, round(quantile(0.75)(duration_hours), 2) AS `P75 (h)`, round(max(duration_hours), 2) AS `Max (h)` FROM transitions GROUP BY transition HAVING count(*) >= 5 ORDER BY `Std Dev (h)` DESC"
    },
    {
        "view_name": "case_complexity_analyzer_IncidentManagement",
        "database": "default",
        "view_definition": "CREATE VIEW default.case_complexity_analyzer_IncidentManagement (`Case ID` String, `Pattern ID` UInt64, `Total Events` UInt64, `Activity Variety` UInt64, `Resource Variety` UInt64, `Duration Hours` Float64, `Z Score` Float64, `Outlier` String) AS WITH case_with_patterns AS (SELECT case_id, groupArray(activity) AS activity_sequence, count(activity) AS total_events, COUNTDistinct(activity) AS activity_variety, COUNTDistinct(resource) AS resource_variety, (max(parseDateTimeBestEffort(timestamp)) - min(parseDateTimeBestEffort(timestamp))) / 3600. AS duration_hours FROM default.IncidentManagement GROUP BY case_id), pattern_stats AS (SELECT activity_sequence, row_number() OVER (ORDER BY COUNT() DESC) AS pattern_id, avg(total_events) AS mean_events, stddevPop(total_events) AS std_events, avg(activity_variety) AS mean_activity_variety, stddevPop(activity_variety) AS std_activity_variety, avg(resource_variety) AS mean_resource_variety, stddevPop(resource_variety) AS std_resource_variety, avg(duration_hours) AS mean_duration, stddevPop(duration_hours) AS std_duration FROM case_with_patterns GROUP BY activity_sequence), all_case_scores AS (SELECT cwp.case_id, ps.pattern_id, cwp.total_events, cwp.activity_variety, cwp.resource_variety, cwp.duration_hours, round((((if(ps.std_events = 0, 0, (cwp.total_events - ps.mean_events) / ps.std_events) + if(ps.std_activity_variety = 0, 0, (cwp.activity_variety - ps.mean_activity_variety) / ps.std_activity_variety)) + if(ps.std_resource_variety = 0, 0, (cwp.resource_variety - ps.mean_resource_variety) / ps.std_resource_variety)) + if(ps.std_duration = 0, 0, (cwp.duration_hours - ps.mean_duration) / ps.std_duration)) / 4, 2) AS `Z Score` FROM case_with_patterns AS cwp INNER JOIN pattern_stats AS ps ON cwp.activity_sequence = ps.activity_sequence) SELECT case_id AS `Case ID`, pattern_id AS `Pattern ID`, total_events AS `Total Events`, activity_variety AS `Activity Variety`, resource_variety AS `Resource Variety`, round(duration_hours, 2) AS `Duration Hours`, `Z Score`, 'Yes' AS Outlier FROM all_case_scores WHERE (`Z Score` <= -1.5) OR (`Z Score` >= 1.5) ORDER BY `Z Score` DESC"
    },
    {
        "view_name": "case_complexity_analyzer_ap_event_log",
        "database": "default",
        "view_definition": "CREATE VIEW default.case_complexity_analyzer_ap_event_log (`Case ID` String, `Pattern ID` UInt64, `Total Events` UInt64, `Activity Variety` UInt64, `Resource Variety` UInt64, `Duration Hours` Float64, `Z Score` Float64, `Outlier` String) AS WITH case_with_patterns AS (SELECT case_id, groupArray(activity) AS activity_sequence, count(activity) AS total_events, COUNTDistinct(activity) AS activity_variety, COUNTDistinct(resource) AS resource_variety, (max(parseDateTimeBestEffort(timestamp)) - min(parseDateTimeBestEffort(timestamp))) / 3600. AS duration_hours FROM default.ap_event_log GROUP BY case_id), pattern_stats AS (SELECT activity_sequence, row_number() OVER (ORDER BY COUNT() DESC) AS pattern_id, avg(total_events) AS mean_events, stddevPop(total_events) AS std_events, avg(activity_variety) AS mean_activity_variety, stddevPop(activity_variety) AS std_activity_variety, avg(resource_variety) AS mean_resource_variety, stddevPop(resource_variety) AS std_resource_variety, avg(duration_hours) AS mean_duration, stddevPop(duration_hours) AS std_duration FROM case_with_patterns GROUP BY activity_sequence), all_case_scores AS (SELECT cwp.case_id, ps.pattern_id, cwp.total_events, cwp.activity_variety, cwp.resource_variety, cwp.duration_hours, round((((if(ps.std_events = 0, 0, (cwp.total_events - ps.mean_events) / ps.std_events) + if(ps.std_activity_variety = 0, 0, (cwp.activity_variety - ps.mean_activity_variety) / ps.std_activity_variety)) + if(ps.std_resource_variety = 0, 0, (cwp.resource_variety - ps.mean_resource_variety) / ps.std_resource_variety)) + if(ps.std_duration = 0, 0, (cwp.duration_hours - ps.mean_duration) / ps.std_duration)) / 4, 2) AS `Z Score` FROM case_with_patterns AS cwp INNER JOIN pattern_stats AS ps ON cwp.activity_sequence = ps.activity_sequence) SELECT case_id AS `Case ID`, pattern_id AS `Pattern ID`, total_events AS `Total Events`, activity_variety AS `Activity Variety`, resource_variety AS `Resource Variety`, round(duration_hours, 2) AS `Duration Hours`, `Z Score`, 'Yes' AS Outlier FROM all_case_scores WHERE (`Z Score` <= -1.5) OR (`Z Score` >= 1.5) ORDER BY `Z Score` DESC"
    },
    {
        "view_name": "case_complexity_analyzer_ar_event_log",
        "database": "default",
        "view_definition": "CREATE VIEW default.case_complexity_analyzer_ar_event_log (`Case ID` String, `Pattern ID` UInt64, `Total Events` UInt64, `Activity Variety` UInt64, `Resource Variety` UInt64, `Duration Hours` Float64, `Z Score` Float64, `Outlier` String) AS WITH case_with_patterns AS (SELECT case_id, groupArray(activity) AS activity_sequence, count(activity) AS total_events, COUNTDistinct(activity) AS activity_variety, COUNTDistinct(resource) AS resource_variety, (max(parseDateTimeBestEffort(timestamp)) - min(parseDateTimeBestEffort(timestamp))) / 3600. AS duration_hours FROM default.ar_event_log GROUP BY case_id), pattern_stats AS (SELECT activity_sequence, row_number() OVER (ORDER BY COUNT() DESC) AS pattern_id, avg(total_events) AS mean_events, stddevPop(total_events) AS std_events, avg(activity_variety) AS mean_activity_variety, stddevPop(activity_variety) AS std_activity_variety, avg(resource_variety) AS mean_resource_variety, stddevPop(resource_variety) AS std_resource_variety, avg(duration_hours) AS mean_duration, stddevPop(duration_hours) AS std_duration FROM case_with_patterns GROUP BY activity_sequence), all_case_scores AS (SELECT cwp.case_id, ps.pattern_id, cwp.total_events, cwp.activity_variety, cwp.resource_variety, cwp.duration_hours, round((((if(ps.std_events = 0, 0, (cwp.total_events - ps.mean_events) / ps.std_events) + if(ps.std_activity_variety = 0, 0, (cwp.activity_variety - ps.mean_activity_variety) / ps.std_activity_variety)) + if(ps.std_resource_variety = 0, 0, (cwp.resource_variety - ps.mean_resource_variety) / ps.std_resource_variety)) + if(ps.std_duration = 0, 0, (cwp.duration_hours - ps.mean_duration) / ps.std_duration)) / 4, 2) AS `Z Score` FROM case_with_patterns AS cwp INNER JOIN pattern_stats AS ps ON cwp.activity_sequence = ps.activity_sequence) SELECT case_id AS `Case ID`, pattern_id AS `Pattern ID`, total_events AS `Total Events`, activity_variety AS `Activity Variety`, resource_variety AS `Resource Variety`, round(duration_hours, 2) AS `Duration Hours`, `Z Score`, 'Yes' AS Outlier FROM all_case_scores WHERE (`Z Score` <= -1.5) OR (`Z Score` >= 1.5) ORDER BY `Z Score` DESC"
    },
    {
        "view_name": "case_complexity_analyzer_car_insurance_claims",
        "database": "default",
        "view_definition": "CREATE VIEW default.case_complexity_analyzer_car_insurance_claims (`Case ID` String, `Pattern ID` UInt64, `Total Events` UInt64, `Activity Variety` UInt64, `Resource Variety` UInt64, `Duration Hours` Float64, `Z Score` Float64, `Outlier` String) AS WITH case_with_patterns AS (SELECT case_id, groupArray(activity) AS activity_sequence, count(activity) AS total_events, COUNTDistinct(activity) AS activity_variety, COUNTDistinct(resource) AS resource_variety, (max(parseDateTimeBestEffort(timestamp)) - min(parseDateTimeBestEffort(timestamp))) / 3600. AS duration_hours FROM default.car_insurance_claims GROUP BY case_id), pattern_stats AS (SELECT activity_sequence, row_number() OVER (ORDER BY COUNT() DESC) AS pattern_id, avg(total_events) AS mean_events, stddevPop(total_events) AS std_events, avg(activity_variety) AS mean_activity_variety, stddevPop(activity_variety) AS std_activity_variety, avg(resource_variety) AS mean_resource_variety, stddevPop(resource_variety) AS std_resource_variety, avg(duration_hours) AS mean_duration, stddevPop(duration_hours) AS std_duration FROM case_with_patterns GROUP BY activity_sequence), all_case_scores AS (SELECT cwp.case_id, ps.pattern_id, cwp.total_events, cwp.activity_variety, cwp.resource_variety, cwp.duration_hours, round((((if(ps.std_events = 0, 0, (cwp.total_events - ps.mean_events) / ps.std_events) + if(ps.std_activity_variety = 0, 0, (cwp.activity_variety - ps.mean_activity_variety) / ps.std_activity_variety)) + if(ps.std_resource_variety = 0, 0, (cwp.resource_variety - ps.mean_resource_variety) / ps.std_resource_variety)) + if(ps.std_duration = 0, 0, (cwp.duration_hours - ps.mean_duration) / ps.std_duration)) / 4, 2) AS `Z Score` FROM case_with_patterns AS cwp INNER JOIN pattern_stats AS ps ON cwp.activity_sequence = ps.activity_sequence) SELECT case_id AS `Case ID`, pattern_id AS `Pattern ID`, total_events AS `Total Events`, activity_variety AS `Activity Variety`, resource_variety AS `Resource Variety`, round(duration_hours, 2) AS `Duration Hours`, `Z Score`, 'Yes' AS Outlier FROM all_case_scores WHERE (`Z Score` <= -1.5) OR (`Z Score` >= 1.5) ORDER BY `Z Score` DESC"
    },
    {
        "view_name": "case_complexity_analyzer_hire_to_retire_event_log",
        "database": "default",
        "view_definition": "CREATE VIEW default.case_complexity_analyzer_hire_to_retire_event_log (`Case ID` String, `Pattern ID` UInt64, `Total Events` UInt64, `Activity Variety` UInt64, `Resource Variety` UInt64, `Duration Hours` Float64, `Z Score` Float64, `Outlier` String) AS WITH case_with_patterns AS (SELECT case_id, groupArray(activity) AS activity_sequence, count(activity) AS total_events, COUNTDistinct(activity) AS activity_variety, COUNTDistinct(resource) AS resource_variety, (max(parseDateTimeBestEffort(timestamp)) - min(parseDateTimeBestEffort(timestamp))) / 3600. AS duration_hours FROM default.hire_to_retire_event_log GROUP BY case_id), pattern_stats AS (SELECT activity_sequence, row_number() OVER (ORDER BY COUNT() DESC) AS pattern_id, avg(total_events) AS mean_events, stddevPop(total_events) AS std_events, avg(activity_variety) AS mean_activity_variety, stddevPop(activity_variety) AS std_activity_variety, avg(resource_variety) AS mean_resource_variety, stddevPop(resource_variety) AS std_resource_variety, avg(duration_hours) AS mean_duration, stddevPop(duration_hours) AS std_duration FROM case_with_patterns GROUP BY activity_sequence), all_case_scores AS (SELECT cwp.case_id, ps.pattern_id, cwp.total_events, cwp.activity_variety, cwp.resource_variety, cwp.duration_hours, round((((if(ps.std_events = 0, 0, (cwp.total_events - ps.mean_events) / ps.std_events) + if(ps.std_activity_variety = 0, 0, (cwp.activity_variety - ps.mean_activity_variety) / ps.std_activity_variety)) + if(ps.std_resource_variety = 0, 0, (cwp.resource_variety - ps.mean_resource_variety) / ps.std_resource_variety)) + if(ps.std_duration = 0, 0, (cwp.duration_hours - ps.mean_duration) / ps.std_duration)) / 4, 2) AS `Z Score` FROM case_with_patterns AS cwp INNER JOIN pattern_stats AS ps ON cwp.activity_sequence = ps.activity_sequence) SELECT case_id AS `Case ID`, pattern_id AS `Pattern ID`, total_events AS `Total Events`, activity_variety AS `Activity Variety`, resource_variety AS `Resource Variety`, round(duration_hours, 2) AS `Duration Hours`, `Z Score`, 'Yes' AS Outlier FROM all_case_scores WHERE (`Z Score` <= -1.5) OR (`Z Score` >= 1.5) ORDER BY `Z Score` DESC"
    },
    {
        "view_name": "case_complexity_analyzer_logistics_event_log",
        "database": "default",
        "view_definition": "CREATE VIEW default.case_complexity_analyzer_logistics_event_log (`Case ID` String, `Pattern ID` UInt64, `Total Events` UInt64, `Activity Variety` UInt64, `Resource Variety` UInt64, `Duration Hours` Float64, `Z Score` Float64, `Outlier` String) AS WITH case_with_patterns AS (SELECT case_id, groupArray(activity) AS activity_sequence, count(activity) AS total_events, COUNTDistinct(activity) AS activity_variety, COUNTDistinct(resource) AS resource_variety, (max(parseDateTimeBestEffort(timestamp)) - min(parseDateTimeBestEffort(timestamp))) / 3600. AS duration_hours FROM default.logistics_event_log GROUP BY case_id), pattern_stats AS (SELECT activity_sequence, row_number() OVER (ORDER BY COUNT() DESC) AS pattern_id, avg(total_events) AS mean_events, stddevPop(total_events) AS std_events, avg(activity_variety) AS mean_activity_variety, stddevPop(activity_variety) AS std_activity_variety, avg(resource_variety) AS mean_resource_variety, stddevPop(resource_variety) AS std_resource_variety, avg(duration_hours) AS mean_duration, stddevPop(duration_hours) AS std_duration FROM case_with_patterns GROUP BY activity_sequence), all_case_scores AS (SELECT cwp.case_id, ps.pattern_id, cwp.total_events, cwp.activity_variety, cwp.resource_variety, cwp.duration_hours, round((((if(ps.std_events = 0, 0, (cwp.total_events - ps.mean_events) / ps.std_events) + if(ps.std_activity_variety = 0, 0, (cwp.activity_variety - ps.mean_activity_variety) / ps.std_activity_variety)) + if(ps.std_resource_variety = 0, 0, (cwp.resource_variety - ps.mean_resource_variety) / ps.std_resource_variety)) + if(ps.std_duration = 0, 0, (cwp.duration_hours - ps.mean_duration) / ps.std_duration)) / 4, 2) AS `Z Score` FROM case_with_patterns AS cwp INNER JOIN pattern_stats AS ps ON cwp.activity_sequence = ps.activity_sequence) SELECT case_id AS `Case ID`, pattern_id AS `Pattern ID`, total_events AS `Total Events`, activity_variety AS `Activity Variety`, resource_variety AS `Resource Variety`, round(duration_hours, 2) AS `Duration Hours`, `Z Score`, 'Yes' AS Outlier FROM all_case_scores WHERE (`Z Score` <= -1.5) OR (`Z Score` >= 1.5) ORDER BY `Z Score` DESC"
    },
    {
        "view_name": "case_complexity_analyzer_mortgage_events",
        "database": "default",
        "view_definition": "CREATE VIEW default.case_complexity_analyzer_mortgage_events (`Case ID` String, `Pattern ID` UInt64, `Total Events` UInt64, `Activity Variety` UInt64, `Resource Variety` UInt64, `Duration Hours` Float64, `Z Score` Float64, `Outlier` String) AS WITH case_with_patterns AS (SELECT case_id, groupArray(activity) AS activity_sequence, count(activity) AS total_events, COUNTDistinct(activity) AS activity_variety, COUNTDistinct(resource) AS resource_variety, (max(parseDateTimeBestEffort(timestamp)) - min(parseDateTimeBestEffort(timestamp))) / 3600. AS duration_hours FROM default.mortgage_events GROUP BY case_id), pattern_stats AS (SELECT activity_sequence, row_number() OVER (ORDER BY COUNT() DESC) AS pattern_id, avg(total_events) AS mean_events, stddevPop(total_events) AS std_events, avg(activity_variety) AS mean_activity_variety, stddevPop(activity_variety) AS std_activity_variety, avg(resource_variety) AS mean_resource_variety, stddevPop(resource_variety) AS std_resource_variety, avg(duration_hours) AS mean_duration, stddevPop(duration_hours) AS std_duration FROM case_with_patterns GROUP BY activity_sequence), all_case_scores AS (SELECT cwp.case_id, ps.pattern_id, cwp.total_events, cwp.activity_variety, cwp.resource_variety, cwp.duration_hours, round((((if(ps.std_events = 0, 0, (cwp.total_events - ps.mean_events) / ps.std_events) + if(ps.std_activity_variety = 0, 0, (cwp.activity_variety - ps.mean_activity_variety) / ps.std_activity_variety)) + if(ps.std_resource_variety = 0, 0, (cwp.resource_variety - ps.mean_resource_variety) / ps.std_resource_variety)) + if(ps.std_duration = 0, 0, (cwp.duration_hours - ps.mean_duration) / ps.std_duration)) / 4, 2) AS `Z Score` FROM case_with_patterns AS cwp INNER JOIN pattern_stats AS ps ON cwp.activity_sequence = ps.activity_sequence) SELECT case_id AS `Case ID`, pattern_id AS `Pattern ID`, total_events AS `Total Events`, activity_variety AS `Activity Variety`, resource_variety AS `Resource Variety`, round(duration_hours, 2) AS `Duration Hours`, `Z Score`, 'Yes' AS Outlier FROM all_case_scores WHERE (`Z Score` <= -1.5) OR (`Z Score` >= 1.5) ORDER BY `Z Score` DESC"
    },
    {
        "view_name": "case_complexity_analyzer_o2c_event_log",
        "database": "default",
        "view_definition": "CREATE VIEW default.case_complexity_analyzer_o2c_event_log (`Case ID` String, `Pattern ID` UInt64, `Total Events` UInt64, `Activity Variety` UInt64, `Resource Variety` UInt64, `Duration Hours` Float64, `Z Score` Float64, `Outlier` String) AS WITH case_with_patterns AS (SELECT case_id, groupArray(activity) AS activity_sequence, count(activity) AS total_events, COUNTDistinct(activity) AS activity_variety, COUNTDistinct(resource) AS resource_variety, (max(parseDateTimeBestEffort(timestamp)) - min(parseDateTimeBestEffort(timestamp))) / 3600. AS duration_hours FROM default.o2c_event_log GROUP BY case_id), pattern_stats AS (SELECT activity_sequence, row_number() OVER (ORDER BY COUNT() DESC) AS pattern_id, avg(total_events) AS mean_events, stddevPop(total_events) AS std_events, avg(activity_variety) AS mean_activity_variety, stddevPop(activity_variety) AS std_activity_variety, avg(resource_variety) AS mean_resource_variety, stddevPop(resource_variety) AS std_resource_variety, avg(duration_hours) AS mean_duration, stddevPop(duration_hours) AS std_duration FROM case_with_patterns GROUP BY activity_sequence), all_case_scores AS (SELECT cwp.case_id, ps.pattern_id, cwp.total_events, cwp.activity_variety, cwp.resource_variety, cwp.duration_hours, round((((if(ps.std_events = 0, 0, (cwp.total_events - ps.mean_events) / ps.std_events) + if(ps.std_activity_variety = 0, 0, (cwp.activity_variety - ps.mean_activity_variety) / ps.std_activity_variety)) + if(ps.std_resource_variety = 0, 0, (cwp.resource_variety - ps.mean_resource_variety) / ps.std_resource_variety)) + if(ps.std_duration = 0, 0, (cwp.duration_hours - ps.mean_duration) / ps.std_duration)) / 4, 2) AS `Z Score` FROM case_with_patterns AS cwp INNER JOIN pattern_stats AS ps ON cwp.activity_sequence = ps.activity_sequence) SELECT case_id AS `Case ID`, pattern_id AS `Pattern ID`, total_events AS `Total Events`, activity_variety AS `Activity Variety`, resource_variety AS `Resource Variety`, round(duration_hours, 2) AS `Duration Hours`, `Z Score`, 'Yes' AS Outlier FROM all_case_scores WHERE (`Z Score` <= -1.5) OR (`Z Score` >= 1.5) ORDER BY `Z Score` DESC"
    },
    {
        "view_name": "case_complexity_analyzer_p2p_event_log",
        "database": "default",
        "view_definition": "CREATE VIEW default.case_complexity_analyzer_p2p_event_log (`Case ID` String, `Pattern ID` UInt64, `Total Events` UInt64, `Activity Variety` UInt64, `Resource Variety` UInt64, `Duration Hours` Float64, `Z Score` Float64, `Outlier` String) AS WITH case_with_patterns AS (SELECT case_id, groupArray(activity) AS activity_sequence, count(activity) AS total_events, COUNTDistinct(activity) AS activity_variety, COUNTDistinct(resource) AS resource_variety, (max(parseDateTimeBestEffort(timestamp)) - min(parseDateTimeBestEffort(timestamp))) / 3600. AS duration_hours FROM default.p2p_event_log GROUP BY case_id), pattern_stats AS (SELECT activity_sequence, row_number() OVER (ORDER BY COUNT() DESC) AS pattern_id, avg(total_events) AS mean_events, stddevPop(total_events) AS std_events, avg(activity_variety) AS mean_activity_variety, stddevPop(activity_variety) AS std_activity_variety, avg(resource_variety) AS mean_resource_variety, stddevPop(resource_variety) AS std_resource_variety, avg(duration_hours) AS mean_duration, stddevPop(duration_hours) AS std_duration FROM case_with_patterns GROUP BY activity_sequence), all_case_scores AS (SELECT cwp.case_id, ps.pattern_id, cwp.total_events, cwp.activity_variety, cwp.resource_variety, cwp.duration_hours, round((((if(ps.std_events = 0, 0, (cwp.total_events - ps.mean_events) / ps.std_events) + if(ps.std_activity_variety = 0, 0, (cwp.activity_variety - ps.mean_activity_variety) / ps.std_activity_variety)) + if(ps.std_resource_variety = 0, 0, (cwp.resource_variety - ps.mean_resource_variety) / ps.std_resource_variety)) + if(ps.std_duration = 0, 0, (cwp.duration_hours - ps.mean_duration) / ps.std_duration)) / 4, 2) AS `Z Score` FROM case_with_patterns AS cwp INNER JOIN pattern_stats AS ps ON cwp.activity_sequence = ps.activity_sequence) SELECT case_id AS `Case ID`, pattern_id AS `Pattern ID`, total_events AS `Total Events`, activity_variety AS `Activity Variety`, resource_variety AS `Resource Variety`, round(duration_hours, 2) AS `Duration Hours`, `Z Score`, 'Yes' AS Outlier FROM all_case_scores WHERE (`Z Score` <= -1.5) OR (`Z Score` >= 1.5) ORDER BY `Z Score` DESC"
    },
    {
        "view_name": "incomplete_cases_analyzer_IncidentManagement",
        "database": "default",
        "view_definition": "CREATE VIEW default.incomplete_cases_analyzer_IncidentManagement (`Case ID` String, `All Activities` Array(String), `Is Incomplete` UInt8) AS WITH incomplete_data AS (SELECT case_id, groupArray(activity) AS all_activities FROM default.IncidentManagement GROUP BY case_id) SELECT case_id AS `Case ID`, all_activities AS `All Activities`, multiIf(hasAny(arrayMap(x -> lower(x), all_activities), ['application approved', 'application rejected']), 0, 1) AS `Is Incomplete` FROM incomplete_data WHERE `Is Incomplete` = 1 ORDER BY case_id ASC"
    },
    {
        "view_name": "incomplete_cases_analyzer_ap_event_log",
        "database": "default",
        "view_definition": "CREATE VIEW default.incomplete_cases_analyzer_ap_event_log (`Case ID` String, `All Activities` Array(String), `Is Incomplete` UInt8) AS WITH incomplete_data AS (SELECT case_id, groupArray(activity) AS all_activities FROM default.ap_event_log GROUP BY case_id) SELECT case_id AS `Case ID`, all_activities AS `All Activities`, multiIf(hasAny(arrayMap(x -> lower(x), all_activities), ['application approved', 'application rejected']), 0, 1) AS `Is Incomplete` FROM incomplete_data WHERE `Is Incomplete` = 1 ORDER BY case_id ASC"
    },
    {
        "view_name": "incomplete_cases_analyzer_ar_event_log",
        "database": "default",
        "view_definition": "CREATE VIEW default.incomplete_cases_analyzer_ar_event_log (`Case ID` String, `All Activities` Array(String), `Is Incomplete` UInt8) AS WITH incomplete_data AS (SELECT case_id, groupArray(activity) AS all_activities FROM default.ar_event_log GROUP BY case_id) SELECT case_id AS `Case ID`, all_activities AS `All Activities`, multiIf(hasAny(arrayMap(x -> lower(x), all_activities), ['application approved', 'application rejected']), 0, 1) AS `Is Incomplete` FROM incomplete_data WHERE `Is Incomplete` = 1 ORDER BY case_id ASC"
    },
    {
        "view_name": "incomplete_cases_analyzer_car_insurance_claims",
        "database": "default",
        "view_definition": "CREATE VIEW default.incomplete_cases_analyzer_car_insurance_claims (`Case ID` String, `All Activities` Array(String), `Is Incomplete` UInt8) AS WITH incomplete_data AS (SELECT case_id, groupArray(activity) AS all_activities FROM default.car_insurance_claims GROUP BY case_id) SELECT case_id AS `Case ID`, all_activities AS `All Activities`, multiIf(hasAny(arrayMap(x -> lower(x), all_activities), ['application approved', 'application rejected']), 0, 1) AS `Is Incomplete` FROM incomplete_data WHERE `Is Incomplete` = 1 ORDER BY case_id ASC"
    },
    {
        "view_name": "incomplete_cases_analyzer_hire_to_retire_event_log",
        "database": "default",
        "view_definition": "CREATE VIEW default.incomplete_cases_analyzer_hire_to_retire_event_log (`Case ID` String, `All Activities` Array(String), `Is Incomplete` UInt8) AS WITH incomplete_data AS (SELECT case_id, groupArray(activity) AS all_activities FROM default.hire_to_retire_event_log GROUP BY case_id) SELECT case_id AS `Case ID`, all_activities AS `All Activities`, multiIf(hasAny(arrayMap(x -> lower(x), all_activities), ['application approved', 'application rejected']), 0, 1) AS `Is Incomplete` FROM incomplete_data WHERE `Is Incomplete` = 1 ORDER BY case_id ASC"
    },
    {
        "view_name": "incomplete_cases_analyzer_logistics_event_log",
        "database": "default",
        "view_definition": "CREATE VIEW default.incomplete_cases_analyzer_logistics_event_log (`Case ID` String, `All Activities` Array(String), `Is Incomplete` UInt8) AS WITH incomplete_data AS (SELECT case_id, groupArray(activity) AS all_activities FROM default.logistics_event_log GROUP BY case_id) SELECT case_id AS `Case ID`, all_activities AS `All Activities`, multiIf(hasAny(arrayMap(x -> lower(x), all_activities), ['application approved', 'application rejected']), 0, 1) AS `Is Incomplete` FROM incomplete_data WHERE `Is Incomplete` = 1 ORDER BY case_id ASC"
    },
    {
        "view_name": "incomplete_cases_analyzer_mortgage_events",
        "database": "default",
        "view_definition": "CREATE VIEW default.incomplete_cases_analyzer_mortgage_events (`Case ID` String, `All Activities` Array(String), `Is Incomplete` UInt8) AS WITH incomplete_data AS (SELECT case_id, groupArray(activity) AS all_activities FROM default.mortgage_events GROUP BY case_id) SELECT case_id AS `Case ID`, all_activities AS `All Activities`, multiIf(hasAny(arrayMap(x -> lower(x), all_activities), ['application approved', 'application rejected']), 0, 1) AS `Is Incomplete` FROM incomplete_data WHERE `Is Incomplete` = 1 ORDER BY case_id ASC"
    },
    {
        "view_name": "incomplete_cases_analyzer_o2c_event_log",
        "database": "default",
        "view_definition": "CREATE VIEW default.incomplete_cases_analyzer_o2c_event_log (`Case ID` String, `All Activities` Array(String), `Is Incomplete` UInt8) AS WITH incomplete_data AS (SELECT case_id, groupArray(activity) AS all_activities FROM default.o2c_event_log GROUP BY case_id) SELECT case_id AS `Case ID`, all_activities AS `All Activities`, multiIf(hasAny(arrayMap(x -> lower(x), all_activities), ['application approved', 'application rejected']), 0, 1) AS `Is Incomplete` FROM incomplete_data WHERE `Is Incomplete` = 1 ORDER BY case_id ASC"
    },
    {
        "view_name": "incomplete_cases_analyzer_p2p_event_log",
        "database": "default",
        "view_definition": "CREATE VIEW default.incomplete_cases_analyzer_p2p_event_log (`Case ID` String, `All Activities` Array(String), `Is Incomplete` UInt8) AS WITH incomplete_data AS (SELECT case_id, groupArray(activity) AS all_activities FROM default.p2p_event_log GROUP BY case_id) SELECT case_id AS `Case ID`, all_activities AS `All Activities`, multiIf(hasAny(arrayMap(x -> lower(x), all_activities), ['application approved', 'application rejected']), 0, 1) AS `Is Incomplete` FROM incomplete_data WHERE `Is Incomplete` = 1 ORDER BY case_id ASC"
    },
    {
        "view_name": "long_running_cases_analyzer_IncidentManagement",
        "database": "default",
        "view_definition": "CREATE VIEW default.long_running_cases_analyzer_IncidentManagement (`case_id` String, `activity_sequence` Array(String), `timestamps` Array(String)) AS SELECT case_id, groupArray(activity) AS activity_sequence, groupArray(timestamp) AS timestamps FROM (SELECT case_id, activity, timestamp FROM default.IncidentManagement ORDER BY case_id ASC, timestamp ASC) GROUP BY case_id"
    },
    {
        "view_name": "long_running_cases_analyzer_ap_event_log",
        "database": "default",
        "view_definition": "CREATE VIEW default.long_running_cases_analyzer_ap_event_log (`case_id` String, `activity_sequence` Array(String), `timestamps` Array(String)) AS SELECT case_id, groupArray(activity) AS activity_sequence, groupArray(timestamp) AS timestamps FROM (SELECT case_id, activity, timestamp FROM default.ap_event_log ORDER BY case_id ASC, timestamp ASC) GROUP BY case_id"
    },
    {
        "view_name": "long_running_cases_analyzer_ar_event_log",
        "database": "default",
        "view_definition": "CREATE VIEW default.long_running_cases_analyzer_ar_event_log (`case_id` String, `activity_sequence` Array(String), `timestamps` Array(String)) AS SELECT case_id, groupArray(activity) AS activity_sequence, groupArray(timestamp) AS timestamps FROM (SELECT case_id, activity, timestamp FROM default.ar_event_log ORDER BY case_id ASC, timestamp ASC) GROUP BY case_id"
    },
    {
        "view_name": "long_running_cases_analyzer_car_insurance_claims",
        "database": "default",
        "view_definition": "CREATE VIEW default.long_running_cases_analyzer_car_insurance_claims (`case_id` String, `activity_sequence` Array(String), `timestamps` Array(String)) AS SELECT case_id, groupArray(activity) AS activity_sequence, groupArray(timestamp) AS timestamps FROM (SELECT case_id, activity, timestamp FROM default.car_insurance_claims ORDER BY case_id ASC, timestamp ASC) GROUP BY case_id"
    },
    {
        "view_name": "long_running_cases_analyzer_hire_to_retire_event_log",
        "database": "default",
        "view_definition": "CREATE VIEW default.long_running_cases_analyzer_hire_to_retire_event_log (`case_id` String, `activity_sequence` Array(String), `timestamps` Array(String)) AS SELECT case_id, groupArray(activity) AS activity_sequence, groupArray(timestamp) AS timestamps FROM (SELECT case_id, activity, timestamp FROM default.hire_to_retire_event_log ORDER BY case_id ASC, timestamp ASC) GROUP BY case_id"
    },
    {
        "view_name": "long_running_cases_analyzer_logistics_event_log",
        "database": "default",
        "view_definition": "CREATE VIEW default.long_running_cases_analyzer_logistics_event_log (`case_id` String, `activity_sequence` Array(String), `timestamps` Array(String)) AS SELECT case_id, groupArray(activity) AS activity_sequence, groupArray(timestamp) AS timestamps FROM (SELECT case_id, activity, timestamp FROM default.logistics_event_log ORDER BY case_id ASC, timestamp ASC) GROUP BY case_id"
    },
    {
        "view_name": "long_running_cases_analyzer_mortgage_events",
        "database": "default",
        "view_definition": "CREATE VIEW default.long_running_cases_analyzer_mortgage_events (`case_id` String, `activity_sequence` Array(String), `timestamps` Array(String)) AS SELECT case_id, groupArray(activity) AS activity_sequence, groupArray(timestamp) AS timestamps FROM (SELECT case_id, activity, timestamp FROM default.mortgage_events ORDER BY case_id ASC, timestamp ASC) GROUP BY case_id"
    },
    {
        "view_name": "long_running_cases_analyzer_o2c_event_log",
        "database": "default",
        "view_definition": "CREATE VIEW default.long_running_cases_analyzer_o2c_event_log (`case_id` String, `activity_sequence` Array(String), `timestamps` Array(String)) AS SELECT case_id, groupArray(activity) AS activity_sequence, groupArray(timestamp) AS timestamps FROM (SELECT case_id, activity, timestamp FROM default.o2c_event_log ORDER BY case_id ASC, timestamp ASC) GROUP BY case_id"
    },
    {
        "view_name": "long_running_cases_analyzer_p2p_event_log",
        "database": "default",
        "view_definition": "CREATE VIEW default.long_running_cases_analyzer_p2p_event_log (`case_id` String, `activity_sequence` Array(String), `timestamps` Array(String)) AS SELECT case_id, groupArray(activity) AS activity_sequence, groupArray(timestamp) AS timestamps FROM (SELECT case_id, activity, timestamp FROM default.p2p_event_log ORDER BY case_id ASC, timestamp ASC) GROUP BY case_id"
    },
    {
        "view_name": "resource_performance_analyzer_IncidentManagement",
        "database": "default",
        "view_definition": "CREATE VIEW default.resource_performance_analyzer_IncidentManagement (`Resource` String, `Total Events` UInt32, `Avg Step Dur (h)` Float64, `Workload IQR Outlier` String, `Step Dur IQR Outlier` String, `Combined Outlier` String, `Unique Cases` UInt32, `Activity Variety` UInt32, `Volume Z` Float64, `Time Gap Z` Float64) AS WITH resource_batch AS (SELECT resource, groupArray(case_id) AS all_case_ids, groupArray(toString(timestamp)) AS all_timestamps, groupArray(activity) AS all_activities, check_resource_performance(resource, all_case_ids, all_timestamps, all_activities) AS result_tuple FROM default.IncidentManagement GROUP BY resource), resource_stats AS (SELECT resource, result_tuple.2 AS avg_step_duration, result_tuple.3 AS unique_cases, result_tuple.4 AS total_events, result_tuple.5 AS activity_variety, result_tuple.6 AS volume_z_score, result_tuple.7 AS time_gap_z_score, result_tuple.8 AS workload_iqr_outlier, result_tuple.9 AS step_dur_iqr_outlier, result_tuple.10 AS combined_outlier FROM resource_batch) SELECT resource AS Resource, total_events AS `Total Events`, round(avg_step_duration, 2) AS `Avg Step Dur (h)`, workload_iqr_outlier AS `Workload IQR Outlier`, step_dur_iqr_outlier AS `Step Dur IQR Outlier`, combined_outlier AS `Combined Outlier`, unique_cases AS `Unique Cases`, activity_variety AS `Activity Variety`, round(volume_z_score, 2) AS `Volume Z`, round(time_gap_z_score, 2) AS `Time Gap Z` FROM resource_stats ORDER BY total_events DESC"
    },
    {
        "view_name": "resource_performance_analyzer_ap_event_log",
        "database": "default",
        "view_definition": "CREATE VIEW default.resource_performance_analyzer_ap_event_log (`Resource` String, `Total Events` UInt32, `Avg Step Dur (h)` Float64, `Workload IQR Outlier` String, `Step Dur IQR Outlier` String, `Combined Outlier` String, `Unique Cases` UInt32, `Activity Variety` UInt32, `Volume Z` Float64, `Time Gap Z` Float64) AS WITH resource_batch AS (SELECT resource, groupArray(case_id) AS all_case_ids, groupArray(toString(timestamp)) AS all_timestamps, groupArray(activity) AS all_activities, check_resource_performance(resource, all_case_ids, all_timestamps, all_activities) AS result_tuple FROM default.ap_event_log GROUP BY resource), resource_stats AS (SELECT resource, result_tuple.2 AS avg_step_duration, result_tuple.3 AS unique_cases, result_tuple.4 AS total_events, result_tuple.5 AS activity_variety, result_tuple.6 AS volume_z_score, result_tuple.7 AS time_gap_z_score, result_tuple.8 AS workload_iqr_outlier, result_tuple.9 AS step_dur_iqr_outlier, result_tuple.10 AS combined_outlier FROM resource_batch) SELECT resource AS Resource, total_events AS `Total Events`, round(avg_step_duration, 2) AS `Avg Step Dur (h)`, workload_iqr_outlier AS `Workload IQR Outlier`, step_dur_iqr_outlier AS `Step Dur IQR Outlier`, combined_outlier AS `Combined Outlier`, unique_cases AS `Unique Cases`, activity_variety AS `Activity Variety`, round(volume_z_score, 2) AS `Volume Z`, round(time_gap_z_score, 2) AS `Time Gap Z` FROM resource_stats ORDER BY total_events DESC"
    },
    {
        "view_name": "resource_performance_analyzer_ar_event_log",
        "database": "default",
        "view_definition": "CREATE VIEW default.resource_performance_analyzer_ar_event_log (`Resource` String, `Total Events` UInt32, `Avg Step Dur (h)` Float64, `Workload IQR Outlier` String, `Step Dur IQR Outlier` String, `Combined Outlier` String, `Unique Cases` UInt32, `Activity Variety` UInt32, `Volume Z` Float64, `Time Gap Z` Float64) AS WITH resource_batch AS (SELECT resource, groupArray(case_id) AS all_case_ids, groupArray(toString(timestamp)) AS all_timestamps, groupArray(activity) AS all_activities, check_resource_performance(resource, all_case_ids, all_timestamps, all_activities) AS result_tuple FROM default.ar_event_log GROUP BY resource), resource_stats AS (SELECT resource, result_tuple.2 AS avg_step_duration, result_tuple.3 AS unique_cases, result_tuple.4 AS total_events, result_tuple.5 AS activity_variety, result_tuple.6 AS volume_z_score, result_tuple.7 AS time_gap_z_score, result_tuple.8 AS workload_iqr_outlier, result_tuple.9 AS step_dur_iqr_outlier, result_tuple.10 AS combined_outlier FROM resource_batch) SELECT resource AS Resource, total_events AS `Total Events`, round(avg_step_duration, 2) AS `Avg Step Dur (h)`, workload_iqr_outlier AS `Workload IQR Outlier`, step_dur_iqr_outlier AS `Step Dur IQR Outlier`, combined_outlier AS `Combined Outlier`, unique_cases AS `Unique Cases`, activity_variety AS `Activity Variety`, round(volume_z_score, 2) AS `Volume Z`, round(time_gap_z_score, 2) AS `Time Gap Z` FROM resource_stats ORDER BY total_events DESC"
    },
    {
        "view_name": "resource_performance_analyzer_car_insurance_claims",
        "database": "default",
        "view_definition": "CREATE VIEW default.resource_performance_analyzer_car_insurance_claims (`Resource` String, `Total Events` UInt32, `Avg Step Dur (h)` Float64, `Workload IQR Outlier` String, `Step Dur IQR Outlier` String, `Combined Outlier` String, `Unique Cases` UInt32, `Activity Variety` UInt32, `Volume Z` Float64, `Time Gap Z` Float64) AS WITH resource_batch AS (SELECT resource, groupArray(case_id) AS all_case_ids, groupArray(toString(timestamp)) AS all_timestamps, groupArray(activity) AS all_activities, check_resource_performance(resource, all_case_ids, all_timestamps, all_activities) AS result_tuple FROM default.car_insurance_claims GROUP BY resource), resource_stats AS (SELECT resource, result_tuple.2 AS avg_step_duration, result_tuple.3 AS unique_cases, result_tuple.4 AS total_events, result_tuple.5 AS activity_variety, result_tuple.6 AS volume_z_score, result_tuple.7 AS time_gap_z_score, result_tuple.8 AS workload_iqr_outlier, result_tuple.9 AS step_dur_iqr_outlier, result_tuple.10 AS combined_outlier FROM resource_batch) SELECT resource AS Resource, total_events AS `Total Events`, round(avg_step_duration, 2) AS `Avg Step Dur (h)`, workload_iqr_outlier AS `Workload IQR Outlier`, step_dur_iqr_outlier AS `Step Dur IQR Outlier`, combined_outlier AS `Combined Outlier`, unique_cases AS `Unique Cases`, activity_variety AS `Activity Variety`, round(volume_z_score, 2) AS `Volume Z`, round(time_gap_z_score, 2) AS `Time Gap Z` FROM resource_stats ORDER BY total_events DESC"
    },
    {
        "view_name": "resource_performance_analyzer_hire_to_retire_event_log",
        "database": "default",
        "view_definition": "CREATE VIEW default.resource_performance_analyzer_hire_to_retire_event_log (`Resource` String, `Total Events` UInt32, `Avg Step Dur (h)` Float64, `Workload IQR Outlier` String, `Step Dur IQR Outlier` String, `Combined Outlier` String, `Unique Cases` UInt32, `Activity Variety` UInt32, `Volume Z` Float64, `Time Gap Z` Float64) AS WITH resource_batch AS (SELECT resource, groupArray(case_id) AS all_case_ids, groupArray(toString(timestamp)) AS all_timestamps, groupArray(activity) AS all_activities, check_resource_performance(resource, all_case_ids, all_timestamps, all_activities) AS result_tuple FROM default.hire_to_retire_event_log GROUP BY resource), resource_stats AS (SELECT resource, result_tuple.2 AS avg_step_duration, result_tuple.3 AS unique_cases, result_tuple.4 AS total_events, result_tuple.5 AS activity_variety, result_tuple.6 AS volume_z_score, result_tuple.7 AS time_gap_z_score, result_tuple.8 AS workload_iqr_outlier, result_tuple.9 AS step_dur_iqr_outlier, result_tuple.10 AS combined_outlier FROM resource_batch) SELECT resource AS Resource, total_events AS `Total Events`, round(avg_step_duration, 2) AS `Avg Step Dur (h)`, workload_iqr_outlier AS `Workload IQR Outlier`, step_dur_iqr_outlier AS `Step Dur IQR Outlier`, combined_outlier AS `Combined Outlier`, unique_cases AS `Unique Cases`, activity_variety AS `Activity Variety`, round(volume_z_score, 2) AS `Volume Z`, round(time_gap_z_score, 2) AS `Time Gap Z` FROM resource_stats ORDER BY total_events DESC"
    },
    {
        "view_name": "resource_performance_analyzer_logistics_event_log",
        "database": "default",
        "view_definition": "CREATE VIEW default.resource_performance_analyzer_logistics_event_log (`Resource` String, `Total Events` UInt32, `Avg Step Dur (h)` Float64, `Workload IQR Outlier` String, `Step Dur IQR Outlier` String, `Combined Outlier` String, `Unique Cases` UInt32, `Activity Variety` UInt32, `Volume Z` Float64, `Time Gap Z` Float64) AS WITH resource_batch AS (SELECT resource, groupArray(case_id) AS all_case_ids, groupArray(toString(timestamp)) AS all_timestamps, groupArray(activity) AS all_activities, check_resource_performance(resource, all_case_ids, all_timestamps, all_activities) AS result_tuple FROM default.logistics_event_log GROUP BY resource), resource_stats AS (SELECT resource, result_tuple.2 AS avg_step_duration, result_tuple.3 AS unique_cases, result_tuple.4 AS total_events, result_tuple.5 AS activity_variety, result_tuple.6 AS volume_z_score, result_tuple.7 AS time_gap_z_score, result_tuple.8 AS workload_iqr_outlier, result_tuple.9 AS step_dur_iqr_outlier, result_tuple.10 AS combined_outlier FROM resource_batch) SELECT resource AS Resource, total_events AS `Total Events`, round(avg_step_duration, 2) AS `Avg Step Dur (h)`, workload_iqr_outlier AS `Workload IQR Outlier`, step_dur_iqr_outlier AS `Step Dur IQR Outlier`, combined_outlier AS `Combined Outlier`, unique_cases AS `Unique Cases`, activity_variety AS `Activity Variety`, round(volume_z_score, 2) AS `Volume Z`, round(time_gap_z_score, 2) AS `Time Gap Z` FROM resource_stats ORDER BY total_events DESC"
    },
    {
        "view_name": "resource_performance_analyzer_mortgage_events",
        "database": "default",
        "view_definition": "CREATE VIEW default.resource_performance_analyzer_mortgage_events (`Resource` String, `Total Events` UInt32, `Avg Step Dur (h)` Float64, `Workload IQR Outlier` String, `Step Dur IQR Outlier` String, `Combined Outlier` String, `Unique Cases` UInt32, `Activity Variety` UInt32, `Volume Z` Float64, `Time Gap Z` Float64) AS WITH resource_batch AS (SELECT resource, groupArray(case_id) AS all_case_ids, groupArray(toString(timestamp)) AS all_timestamps, groupArray(activity) AS all_activities, check_resource_performance(resource, all_case_ids, all_timestamps, all_activities) AS result_tuple FROM default.mortgage_events GROUP BY resource), resource_stats AS (SELECT resource, result_tuple.2 AS avg_step_duration, result_tuple.3 AS unique_cases, result_tuple.4 AS total_events, result_tuple.5 AS activity_variety, result_tuple.6 AS volume_z_score, result_tuple.7 AS time_gap_z_score, result_tuple.8 AS workload_iqr_outlier, result_tuple.9 AS step_dur_iqr_outlier, result_tuple.10 AS combined_outlier FROM resource_batch) SELECT resource AS Resource, total_events AS `Total Events`, round(avg_step_duration, 2) AS `Avg Step Dur (h)`, workload_iqr_outlier AS `Workload IQR Outlier`, step_dur_iqr_outlier AS `Step Dur IQR Outlier`, combined_outlier AS `Combined Outlier`, unique_cases AS `Unique Cases`, activity_variety AS `Activity Variety`, round(volume_z_score, 2) AS `Volume Z`, round(time_gap_z_score, 2) AS `Time Gap Z` FROM resource_stats ORDER BY total_events DESC"
    },
    {
        "view_name": "resource_performance_analyzer_o2c_event_log",
        "database": "default",
        "view_definition": "CREATE VIEW default.resource_performance_analyzer_o2c_event_log (`Resource` String, `Total Events` UInt32, `Avg Step Dur (h)` Float64, `Workload IQR Outlier` String, `Step Dur IQR Outlier` String, `Combined Outlier` String, `Unique Cases` UInt32, `Activity Variety` UInt32, `Volume Z` Float64, `Time Gap Z` Float64) AS WITH resource_batch AS (SELECT resource, groupArray(case_id) AS all_case_ids, groupArray(toString(timestamp)) AS all_timestamps, groupArray(activity) AS all_activities, check_resource_performance(resource, all_case_ids, all_timestamps, all_activities) AS result_tuple FROM default.o2c_event_log GROUP BY resource), resource_stats AS (SELECT resource, result_tuple.2 AS avg_step_duration, result_tuple.3 AS unique_cases, result_tuple.4 AS total_events, result_tuple.5 AS activity_variety, result_tuple.6 AS volume_z_score, result_tuple.7 AS time_gap_z_score, result_tuple.8 AS workload_iqr_outlier, result_tuple.9 AS step_dur_iqr_outlier, result_tuple.10 AS combined_outlier FROM resource_batch) SELECT resource AS Resource, total_events AS `Total Events`, round(avg_step_duration, 2) AS `Avg Step Dur (h)`, workload_iqr_outlier AS `Workload IQR Outlier`, step_dur_iqr_outlier AS `Step Dur IQR Outlier`, combined_outlier AS `Combined Outlier`, unique_cases AS `Unique Cases`, activity_variety AS `Activity Variety`, round(volume_z_score, 2) AS `Volume Z`, round(time_gap_z_score, 2) AS `Time Gap Z` FROM resource_stats ORDER BY total_events DESC"
    },
    {
        "view_name": "resource_performance_analyzer_p2p_event_log",
        "database": "default",
        "view_definition": "CREATE VIEW default.resource_performance_analyzer_p2p_event_log (`Resource` String, `Total Events` UInt32, `Avg Step Dur (h)` Float64, `Workload IQR Outlier` String, `Step Dur IQR Outlier` String, `Combined Outlier` String, `Unique Cases` UInt32, `Activity Variety` UInt32, `Volume Z` Float64, `Time Gap Z` Float64) AS WITH resource_batch AS (SELECT resource, groupArray(case_id) AS all_case_ids, groupArray(toString(timestamp)) AS all_timestamps, groupArray(activity) AS all_activities, check_resource_performance(resource, all_case_ids, all_timestamps, all_activities) AS result_tuple FROM default.p2p_event_log GROUP BY resource), resource_stats AS (SELECT resource, result_tuple.2 AS avg_step_duration, result_tuple.3 AS unique_cases, result_tuple.4 AS total_events, result_tuple.5 AS activity_variety, result_tuple.6 AS volume_z_score, result_tuple.7 AS time_gap_z_score, result_tuple.8 AS workload_iqr_outlier, result_tuple.9 AS step_dur_iqr_outlier, result_tuple.10 AS combined_outlier FROM resource_batch) SELECT resource AS Resource, total_events AS `Total Events`, round(avg_step_duration, 2) AS `Avg Step Dur (h)`, workload_iqr_outlier AS `Workload IQR Outlier`, step_dur_iqr_outlier AS `Step Dur IQR Outlier`, combined_outlier AS `Combined Outlier`, unique_cases AS `Unique Cases`, activity_variety AS `Activity Variety`, round(volume_z_score, 2) AS `Volume Z`, round(time_gap_z_score, 2) AS `Time Gap Z` FROM resource_stats ORDER BY total_events DESC"
    },
    {
        "view_name": "resource_switches_analyzer_IncidentManagement",
        "database": "default",
        "view_definition": "CREATE VIEW default.resource_switches_analyzer_IncidentManagement (`Case ID` String, `Total Switches` UInt32, `Switch Band` String, `First Switch` String) AS WITH resource_analysis AS (SELECT case_id, groupArray(resource) AS ordered_resources, check_resource_switches(case_id, groupArray(resource)) AS udf_result FROM default.IncidentManagement GROUP BY case_id), switch_classified AS (SELECT case_id, ordered_resources, udf_result.1 AS case_id_from_script, udf_result.2 AS total_switches, multiIf((udf_result.2) = 0, '0 switches', ((udf_result.2) >= 1) AND ((udf_result.2) <= 3), '1-3 switches', ((udf_result.2) >= 4) AND ((udf_result.2) <= 6), '4-6 switches', ((udf_result.2) >= 7) AND ((udf_result.2) <= 9), '7-9 switches', ((udf_result.2) >= 10) AND ((udf_result.2) <= 12), '10-12 switches', (udf_result.2) >= 13, '13+ switches', 'Unknown') AS switch_band, ordered_resources[1] AS first_switch FROM resource_analysis WHERE (udf_result.2) >= 0) SELECT case_id AS `Case ID`, total_switches AS `Total Switches`, switch_band AS `Switch Band`, first_switch AS `First Switch` FROM switch_classified ORDER BY total_switches DESC, case_id ASC"
    },
    {
        "view_name": "resource_switches_analyzer_ap_event_log",
        "database": "default",
        "view_definition": "CREATE VIEW default.resource_switches_analyzer_ap_event_log (`Case ID` String, `Total Switches` UInt32, `Switch Band` String, `First Switch` String) AS WITH resource_analysis AS (SELECT case_id, groupArray(resource) AS ordered_resources, check_resource_switches(case_id, groupArray(resource)) AS udf_result FROM default.ap_event_log GROUP BY case_id), switch_classified AS (SELECT case_id, ordered_resources, udf_result.1 AS case_id_from_script, udf_result.2 AS total_switches, multiIf((udf_result.2) = 0, '0 switches', ((udf_result.2) >= 1) AND ((udf_result.2) <= 3), '1-3 switches', ((udf_result.2) >= 4) AND ((udf_result.2) <= 6), '4-6 switches', ((udf_result.2) >= 7) AND ((udf_result.2) <= 9), '7-9 switches', ((udf_result.2) >= 10) AND ((udf_result.2) <= 12), '10-12 switches', (udf_result.2) >= 13, '13+ switches', 'Unknown') AS switch_band, ordered_resources[1] AS first_switch FROM resource_analysis WHERE (udf_result.2) >= 0) SELECT case_id AS `Case ID`, total_switches AS `Total Switches`, switch_band AS `Switch Band`, first_switch AS `First Switch` FROM switch_classified ORDER BY total_switches DESC, case_id ASC"
    },
    {
        "view_name": "resource_switches_analyzer_ar_event_log",
        "database": "default",
        "view_definition": "CREATE VIEW default.resource_switches_analyzer_ar_event_log (`Case ID` String, `Total Switches` UInt32, `Switch Band` String, `First Switch` String) AS WITH resource_analysis AS (SELECT case_id, groupArray(resource) AS ordered_resources, check_resource_switches(case_id, groupArray(resource)) AS udf_result FROM default.ar_event_log GROUP BY case_id), switch_classified AS (SELECT case_id, ordered_resources, udf_result.1 AS case_id_from_script, udf_result.2 AS total_switches, multiIf((udf_result.2) = 0, '0 switches', ((udf_result.2) >= 1) AND ((udf_result.2) <= 3), '1-3 switches', ((udf_result.2) >= 4) AND ((udf_result.2) <= 6), '4-6 switches', ((udf_result.2) >= 7) AND ((udf_result.2) <= 9), '7-9 switches', ((udf_result.2) >= 10) AND ((udf_result.2) <= 12), '10-12 switches', (udf_result.2) >= 13, '13+ switches', 'Unknown') AS switch_band, ordered_resources[1] AS first_switch FROM resource_analysis WHERE (udf_result.2) >= 0) SELECT case_id AS `Case ID`, total_switches AS `Total Switches`, switch_band AS `Switch Band`, first_switch AS `First Switch` FROM switch_classified ORDER BY total_switches DESC, case_id ASC"
    },
    {
        "view_name": "resource_switches_analyzer_car_insurance_claims",
        "database": "default",
        "view_definition": "CREATE VIEW default.resource_switches_analyzer_car_insurance_claims (`Case ID` String, `Total Switches` UInt32, `Switch Band` String, `First Switch` String) AS WITH resource_analysis AS (SELECT case_id, groupArray(resource) AS ordered_resources, check_resource_switches(case_id, groupArray(resource)) AS udf_result FROM default.car_insurance_claims GROUP BY case_id), switch_classified AS (SELECT case_id, ordered_resources, udf_result.1 AS case_id_from_script, udf_result.2 AS total_switches, multiIf((udf_result.2) = 0, '0 switches', ((udf_result.2) >= 1) AND ((udf_result.2) <= 3), '1-3 switches', ((udf_result.2) >= 4) AND ((udf_result.2) <= 6), '4-6 switches', ((udf_result.2) >= 7) AND ((udf_result.2) <= 9), '7-9 switches', ((udf_result.2) >= 10) AND ((udf_result.2) <= 12), '10-12 switches', (udf_result.2) >= 13, '13+ switches', 'Unknown') AS switch_band, ordered_resources[1] AS first_switch FROM resource_analysis WHERE (udf_result.2) >= 0) SELECT case_id AS `Case ID`, total_switches AS `Total Switches`, switch_band AS `Switch Band`, first_switch AS `First Switch` FROM switch_classified ORDER BY total_switches DESC, case_id ASC"
    },
    {
        "view_name": "resource_switches_analyzer_hire_to_retire_event_log",
        "database": "default",
        "view_definition": "CREATE VIEW default.resource_switches_analyzer_hire_to_retire_event_log (`Case ID` String, `Total Switches` UInt32, `Switch Band` String, `First Switch` String) AS WITH resource_analysis AS (SELECT case_id, groupArray(resource) AS ordered_resources, check_resource_switches(case_id, groupArray(resource)) AS udf_result FROM default.hire_to_retire_event_log GROUP BY case_id), switch_classified AS (SELECT case_id, ordered_resources, udf_result.1 AS case_id_from_script, udf_result.2 AS total_switches, multiIf((udf_result.2) = 0, '0 switches', ((udf_result.2) >= 1) AND ((udf_result.2) <= 3), '1-3 switches', ((udf_result.2) >= 4) AND ((udf_result.2) <= 6), '4-6 switches', ((udf_result.2) >= 7) AND ((udf_result.2) <= 9), '7-9 switches', ((udf_result.2) >= 10) AND ((udf_result.2) <= 12), '10-12 switches', (udf_result.2) >= 13, '13+ switches', 'Unknown') AS switch_band, ordered_resources[1] AS first_switch FROM resource_analysis WHERE (udf_result.2) >= 0) SELECT case_id AS `Case ID`, total_switches AS `Total Switches`, switch_band AS `Switch Band`, first_switch AS `First Switch` FROM switch_classified ORDER BY total_switches DESC, case_id ASC"
    },
    {
        "view_name": "resource_switches_analyzer_logistics_event_log",
        "database": "default",
        "view_definition": "CREATE VIEW default.resource_switches_analyzer_logistics_event_log (`Case ID` String, `Total Switches` UInt32, `Switch Band` String, `First Switch` String) AS WITH resource_analysis AS (SELECT case_id, groupArray(resource) AS ordered_resources, check_resource_switches(case_id, groupArray(resource)) AS udf_result FROM default.logistics_event_log GROUP BY case_id), switch_classified AS (SELECT case_id, ordered_resources, udf_result.1 AS case_id_from_script, udf_result.2 AS total_switches, multiIf((udf_result.2) = 0, '0 switches', ((udf_result.2) >= 1) AND ((udf_result.2) <= 3), '1-3 switches', ((udf_result.2) >= 4) AND ((udf_result.2) <= 6), '4-6 switches', ((udf_result.2) >= 7) AND ((udf_result.2) <= 9), '7-9 switches', ((udf_result.2) >= 10) AND ((udf_result.2) <= 12), '10-12 switches', (udf_result.2) >= 13, '13+ switches', 'Unknown') AS switch_band, ordered_resources[1] AS first_switch FROM resource_analysis WHERE (udf_result.2) >= 0) SELECT case_id AS `Case ID`, total_switches AS `Total Switches`, switch_band AS `Switch Band`, first_switch AS `First Switch` FROM switch_classified ORDER BY total_switches DESC, case_id ASC"
    },
    {
        "view_name": "resource_switches_analyzer_mortgage_events",
        "database": "default",
        "view_definition": "CREATE VIEW default.resource_switches_analyzer_mortgage_events (`Case ID` String, `Total Switches` UInt32, `Switch Band` String, `First Switch` String) AS WITH resource_analysis AS (SELECT case_id, groupArray(resource) AS ordered_resources, check_resource_switches(case_id, groupArray(resource)) AS udf_result FROM default.mortgage_events GROUP BY case_id), switch_classified AS (SELECT case_id, ordered_resources, udf_result.1 AS case_id_from_script, udf_result.2 AS total_switches, multiIf((udf_result.2) = 0, '0 switches', ((udf_result.2) >= 1) AND ((udf_result.2) <= 3), '1-3 switches', ((udf_result.2) >= 4) AND ((udf_result.2) <= 6), '4-6 switches', ((udf_result.2) >= 7) AND ((udf_result.2) <= 9), '7-9 switches', ((udf_result.2) >= 10) AND ((udf_result.2) <= 12), '10-12 switches', (udf_result.2) >= 13, '13+ switches', 'Unknown') AS switch_band, ordered_resources[1] AS first_switch FROM resource_analysis WHERE (udf_result.2) >= 0) SELECT case_id AS `Case ID`, total_switches AS `Total Switches`, switch_band AS `Switch Band`, first_switch AS `First Switch` FROM switch_classified ORDER BY total_switches DESC, case_id ASC"
    },
    {
        "view_name": "resource_switches_analyzer_o2c_event_log",
        "database": "default",
        "view_definition": "CREATE VIEW default.resource_switches_analyzer_o2c_event_log (`Case ID` String, `Total Switches` UInt32, `Switch Band` String, `First Switch` String) AS WITH resource_analysis AS (SELECT case_id, groupArray(resource) AS ordered_resources, check_resource_switches(case_id, groupArray(resource)) AS udf_result FROM default.o2c_event_log GROUP BY case_id), switch_classified AS (SELECT case_id, ordered_resources, udf_result.1 AS case_id_from_script, udf_result.2 AS total_switches, multiIf((udf_result.2) = 0, '0 switches', ((udf_result.2) >= 1) AND ((udf_result.2) <= 3), '1-3 switches', ((udf_result.2) >= 4) AND ((udf_result.2) <= 6), '4-6 switches', ((udf_result.2) >= 7) AND ((udf_result.2) <= 9), '7-9 switches', ((udf_result.2) >= 10) AND ((udf_result.2) <= 12), '10-12 switches', (udf_result.2) >= 13, '13+ switches', 'Unknown') AS switch_band, ordered_resources[1] AS first_switch FROM resource_analysis WHERE (udf_result.2) >= 0) SELECT case_id AS `Case ID`, total_switches AS `Total Switches`, switch_band AS `Switch Band`, first_switch AS `First Switch` FROM switch_classified ORDER BY total_switches DESC, case_id ASC"
    },
    {
        "view_name": "resource_switches_analyzer_p2p_event_log",
        "database": "default",
        "view_definition": "CREATE VIEW default.resource_switches_analyzer_p2p_event_log (`Case ID` String, `Total Switches` UInt32, `Switch Band` String, `First Switch` String) AS WITH resource_analysis AS (SELECT case_id, groupArray(resource) AS ordered_resources, check_resource_switches(case_id, groupArray(resource)) AS udf_result FROM default.p2p_event_log GROUP BY case_id), switch_classified AS (SELECT case_id, ordered_resources, udf_result.1 AS case_id_from_script, udf_result.2 AS total_switches, multiIf((udf_result.2) = 0, '0 switches', ((udf_result.2) >= 1) AND ((udf_result.2) <= 3), '1-3 switches', ((udf_result.2) >= 4) AND ((udf_result.2) <= 6), '4-6 switches', ((udf_result.2) >= 7) AND ((udf_result.2) <= 9), '7-9 switches', ((udf_result.2) >= 10) AND ((udf_result.2) <= 12), '10-12 switches', (udf_result.2) >= 13, '13+ switches', 'Unknown') AS switch_band, ordered_resources[1] AS first_switch FROM resource_analysis WHERE (udf_result.2) >= 0) SELECT case_id AS `Case ID`, total_switches AS `Total Switches`, switch_band AS `Switch Band`, first_switch AS `First Switch` FROM switch_classified ORDER BY total_switches DESC, case_id ASC"
    },
    {
        "view_name": "reworked_activities_analyzer_IncidentManagement",
        "database": "default",
        "view_definition": "CREATE VIEW default.reworked_activities_analyzer_IncidentManagement (`Reworked Activity` String, `Cases with Rework` UInt64, `Total Excess Occurrences` Int64) AS WITH activity_counts AS (SELECT case_id, activity, count(*) AS actual_count, groupArray(activity) AS all_activities FROM default.IncidentManagement GROUP BY case_id, activity), rework_analysis AS (SELECT case_id, activity, actual_count, check_operational_overhead(case_id, all_activities) AS udf_result FROM activity_counts), rework_details AS (SELECT case_id, activity, actual_count - 1 AS excess FROM rework_analysis WHERE (actual_count > 1) AND (udf_result.has_operational_overhead = 1)) SELECT activity AS `Reworked Activity`, countDistinct(case_id) AS `Cases with Rework`, sum(excess) AS `Total Excess Occurrences` FROM rework_details GROUP BY activity ORDER BY `Total Excess Occurrences` DESC, `Cases with Rework` DESC"
    },
    {
        "view_name": "reworked_activities_analyzer_ap_event_log",
        "database": "default",
        "view_definition": "CREATE VIEW default.reworked_activities_analyzer_ap_event_log (`Reworked Activity` String, `Cases with Rework` UInt64, `Total Excess Occurrences` Int64) AS WITH activity_counts AS (SELECT case_id, activity, count(*) AS actual_count, groupArray(activity) AS all_activities FROM default.ap_event_log GROUP BY case_id, activity), rework_analysis AS (SELECT case_id, activity, actual_count, check_operational_overhead(case_id, all_activities) AS udf_result FROM activity_counts), rework_details AS (SELECT case_id, activity, actual_count - 1 AS excess FROM rework_analysis WHERE (actual_count > 1) AND (udf_result.has_operational_overhead = 1)) SELECT activity AS `Reworked Activity`, countDistinct(case_id) AS `Cases with Rework`, sum(excess) AS `Total Excess Occurrences` FROM rework_details GROUP BY activity ORDER BY `Total Excess Occurrences` DESC, `Cases with Rework` DESC"
    },
    {
        "view_name": "reworked_activities_analyzer_ar_event_log",
        "database": "default",
        "view_definition": "CREATE VIEW default.reworked_activities_analyzer_ar_event_log (`Reworked Activity` String, `Cases with Rework` UInt64, `Total Excess Occurrences` Int64) AS WITH activity_counts AS (SELECT case_id, activity, count(*) AS actual_count, groupArray(activity) AS all_activities FROM default.ar_event_log GROUP BY case_id, activity), rework_analysis AS (SELECT case_id, activity, actual_count, check_operational_overhead(case_id, all_activities) AS udf_result FROM activity_counts), rework_details AS (SELECT case_id, activity, actual_count - 1 AS excess FROM rework_analysis WHERE (actual_count > 1) AND (udf_result.has_operational_overhead = 1)) SELECT activity AS `Reworked Activity`, countDistinct(case_id) AS `Cases with Rework`, sum(excess) AS `Total Excess Occurrences` FROM rework_details GROUP BY activity ORDER BY `Total Excess Occurrences` DESC, `Cases with Rework` DESC"
    },
    {
        "view_name": "reworked_activities_analyzer_car_insurance_claims",
        "database": "default",
        "view_definition": "CREATE VIEW default.reworked_activities_analyzer_car_insurance_claims (`Reworked Activity` String, `Cases with Rework` UInt64, `Total Excess Occurrences` Int64) AS WITH activity_counts AS (SELECT case_id, activity, count(*) AS actual_count, groupArray(activity) AS all_activities FROM default.car_insurance_claims GROUP BY case_id, activity), rework_analysis AS (SELECT case_id, activity, actual_count, check_operational_overhead(case_id, all_activities) AS udf_result FROM activity_counts), rework_details AS (SELECT case_id, activity, actual_count - 1 AS excess FROM rework_analysis WHERE (actual_count > 1) AND (udf_result.has_operational_overhead = 1)) SELECT activity AS `Reworked Activity`, countDistinct(case_id) AS `Cases with Rework`, sum(excess) AS `Total Excess Occurrences` FROM rework_details GROUP BY activity ORDER BY `Total Excess Occurrences` DESC, `Cases with Rework` DESC"
    },
    {
        "view_name": "reworked_activities_analyzer_hire_to_retire_event_log",
        "database": "default",
        "view_definition": "CREATE VIEW default.reworked_activities_analyzer_hire_to_retire_event_log (`Reworked Activity` String, `Cases with Rework` UInt64, `Total Excess Occurrences` Int64) AS WITH activity_counts AS (SELECT case_id, activity, count(*) AS actual_count, groupArray(activity) AS all_activities FROM default.hire_to_retire_event_log GROUP BY case_id, activity), rework_analysis AS (SELECT case_id, activity, actual_count, check_operational_overhead(case_id, all_activities) AS udf_result FROM activity_counts), rework_details AS (SELECT case_id, activity, actual_count - 1 AS excess FROM rework_analysis WHERE (actual_count > 1) AND (udf_result.has_operational_overhead = 1)) SELECT activity AS `Reworked Activity`, countDistinct(case_id) AS `Cases with Rework`, sum(excess) AS `Total Excess Occurrences` FROM rework_details GROUP BY activity ORDER BY `Total Excess Occurrences` DESC, `Cases with Rework` DESC"
    },
    {
        "view_name": "reworked_activities_analyzer_logistics_event_log",
        "database": "default",
        "view_definition": "CREATE VIEW default.reworked_activities_analyzer_logistics_event_log (`Reworked Activity` String, `Cases with Rework` UInt64, `Total Excess Occurrences` Int64) AS WITH activity_counts AS (SELECT case_id, activity, count(*) AS actual_count, groupArray(activity) AS all_activities FROM default.logistics_event_log GROUP BY case_id, activity), rework_analysis AS (SELECT case_id, activity, actual_count, check_operational_overhead(case_id, all_activities) AS udf_result FROM activity_counts), rework_details AS (SELECT case_id, activity, actual_count - 1 AS excess FROM rework_analysis WHERE (actual_count > 1) AND (udf_result.has_operational_overhead = 1)) SELECT activity AS `Reworked Activity`, countDistinct(case_id) AS `Cases with Rework`, sum(excess) AS `Total Excess Occurrences` FROM rework_details GROUP BY activity ORDER BY `Total Excess Occurrences` DESC, `Cases with Rework` DESC"
    },
    {
        "view_name": "reworked_activities_analyzer_mortgage_events",
        "database": "default",
        "view_definition": "CREATE VIEW default.reworked_activities_analyzer_mortgage_events (`Reworked Activity` String, `Cases with Rework` UInt64, `Total Excess Occurrences` Int64) AS WITH activity_counts AS (SELECT case_id, activity, count(*) AS actual_count, groupArray(activity) AS all_activities FROM default.mortgage_events GROUP BY case_id, activity), rework_analysis AS (SELECT case_id, activity, actual_count, check_operational_overhead(case_id, all_activities) AS udf_result FROM activity_counts), rework_details AS (SELECT case_id, activity, actual_count - 1 AS excess FROM rework_analysis WHERE (actual_count > 1) AND (udf_result.has_operational_overhead = 1)) SELECT activity AS `Reworked Activity`, countDistinct(case_id) AS `Cases with Rework`, sum(excess) AS `Total Excess Occurrences` FROM rework_details GROUP BY activity ORDER BY `Total Excess Occurrences` DESC, `Cases with Rework` DESC"
    },
    {
        "view_name": "reworked_activities_analyzer_o2c_event_log",
        "database": "default",
        "view_definition": "CREATE VIEW default.reworked_activities_analyzer_o2c_event_log (`Reworked Activity` String, `Cases with Rework` UInt64, `Total Excess Occurrences` Int64) AS WITH activity_counts AS (SELECT case_id, activity, count(*) AS actual_count, groupArray(activity) AS all_activities FROM default.o2c_event_log GROUP BY case_id, activity), rework_analysis AS (SELECT case_id, activity, actual_count, check_operational_overhead(case_id, all_activities) AS udf_result FROM activity_counts), rework_details AS (SELECT case_id, activity, actual_count - 1 AS excess FROM rework_analysis WHERE (actual_count > 1) AND (udf_result.has_operational_overhead = 1)) SELECT activity AS `Reworked Activity`, countDistinct(case_id) AS `Cases with Rework`, sum(excess) AS `Total Excess Occurrences` FROM rework_details GROUP BY activity ORDER BY `Total Excess Occurrences` DESC, `Cases with Rework` DESC"
    },
    {
        "view_name": "reworked_activities_analyzer_p2p_event_log",
        "database": "default",
        "view_definition": "CREATE VIEW default.reworked_activities_analyzer_p2p_event_log (`Reworked Activity` String, `Cases with Rework` UInt64, `Total Excess Occurrences` Int64) AS WITH activity_counts AS (SELECT case_id, activity, count(*) AS actual_count, groupArray(activity) AS all_activities FROM default.p2p_event_log GROUP BY case_id, activity), rework_analysis AS (SELECT case_id, activity, actual_count, check_operational_overhead(case_id, all_activities) AS udf_result FROM activity_counts), rework_details AS (SELECT case_id, activity, actual_count - 1 AS excess FROM rework_analysis WHERE (actual_count > 1) AND (udf_result.has_operational_overhead = 1)) SELECT activity AS `Reworked Activity`, countDistinct(case_id) AS `Cases with Rework`, sum(excess) AS `Total Excess Occurrences` FROM rework_details GROUP BY activity ORDER BY `Total Excess Occurrences` DESC, `Cases with Rework` DESC"
    },
    {
        "view_name": "sop_deviation_analyzer_IncidentManagement",
        "database": "default",
        "view_definition": "CREATE VIEW default.sop_deviation_analyzer_IncidentManagement (`pattern_sl_no` UInt64, `pattern_count` UInt64, `percentage` Nullable(Float64), `sop_deviation_sequence_preview` Array(String)) AS WITH (SELECT countDistinct(case_id) FROM default.IncidentManagement) AS total_count SELECT row_number() OVER (ORDER BY count() DESC) AS pattern_sl_no, count() AS pattern_count, round((count() * 100.) / total_count, 2) AS percentage, grouped_activities AS sop_deviation_sequence_preview FROM (SELECT case_id, groupArray(activity) AS grouped_activities FROM (SELECT case_id, activity FROM default.IncidentManagement ORDER BY case_id ASC, parseDateTimeBestEffort(timestamp) ASC) GROUP BY case_id) AS grouped_cases GROUP BY grouped_activities ORDER BY pattern_count DESC"
    },
    {
        "view_name": "sop_deviation_analyzer_ap_event_log",
        "database": "default",
        "view_definition": "CREATE VIEW default.sop_deviation_analyzer_ap_event_log (`pattern_sl_no` UInt64, `pattern_count` UInt64, `percentage` Nullable(Float64), `sop_deviation_sequence_preview` Array(String)) AS WITH (SELECT countDistinct(case_id) FROM default.ap_event_log) AS total_count SELECT row_number() OVER (ORDER BY count() DESC) AS pattern_sl_no, count() AS pattern_count, round((count() * 100.) / total_count, 2) AS percentage, grouped_activities AS sop_deviation_sequence_preview FROM (SELECT case_id, groupArray(activity) AS grouped_activities FROM (SELECT case_id, activity FROM default.ap_event_log ORDER BY case_id ASC, parseDateTimeBestEffort(timestamp) ASC) GROUP BY case_id) AS grouped_cases GROUP BY grouped_activities ORDER BY pattern_count DESC"
    },
    {
        "view_name": "sop_deviation_analyzer_ar_event_log",
        "database": "default",
        "view_definition": "CREATE VIEW default.sop_deviation_analyzer_ar_event_log (`pattern_sl_no` UInt64, `pattern_count` UInt64, `percentage` Nullable(Float64), `sop_deviation_sequence_preview` Array(String)) AS WITH (SELECT countDistinct(case_id) FROM default.ar_event_log) AS total_count SELECT row_number() OVER (ORDER BY count() DESC) AS pattern_sl_no, count() AS pattern_count, round((count() * 100.) / total_count, 2) AS percentage, grouped_activities AS sop_deviation_sequence_preview FROM (SELECT case_id, groupArray(activity) AS grouped_activities FROM (SELECT case_id, activity FROM default.ar_event_log ORDER BY case_id ASC, parseDateTimeBestEffort(timestamp) ASC) GROUP BY case_id) AS grouped_cases GROUP BY grouped_activities ORDER BY pattern_count DESC"
    },
    {
        "view_name": "sop_deviation_analyzer_car_insurance_claims",
        "database": "default",
        "view_definition": "CREATE VIEW default.sop_deviation_analyzer_car_insurance_claims (`pattern_sl_no` UInt64, `pattern_count` UInt64, `percentage` Nullable(Float64), `sop_deviation_sequence_preview` Array(String)) AS WITH (SELECT countDistinct(case_id) FROM default.car_insurance_claims) AS total_count SELECT row_number() OVER (ORDER BY count() DESC) AS pattern_sl_no, count() AS pattern_count, round((count() * 100.) / total_count, 2) AS percentage, grouped_activities AS sop_deviation_sequence_preview FROM (SELECT case_id, groupArray(activity) AS grouped_activities FROM (SELECT case_id, activity FROM default.car_insurance_claims ORDER BY case_id ASC, parseDateTimeBestEffort(timestamp) ASC) GROUP BY case_id) AS grouped_cases GROUP BY grouped_activities ORDER BY pattern_count DESC"
    },
    {
        "view_name": "sop_deviation_analyzer_hire_to_retire_event_log",
        "database": "default",
        "view_definition": "CREATE VIEW default.sop_deviation_analyzer_hire_to_retire_event_log (`pattern_sl_no` UInt64, `pattern_count` UInt64, `percentage` Nullable(Float64), `sop_deviation_sequence_preview` Array(String)) AS WITH (SELECT countDistinct(case_id) FROM default.hire_to_retire_event_log) AS total_count SELECT row_number() OVER (ORDER BY count() DESC) AS pattern_sl_no, count() AS pattern_count, round((count() * 100.) / total_count, 2) AS percentage, grouped_activities AS sop_deviation_sequence_preview FROM (SELECT case_id, groupArray(activity) AS grouped_activities FROM (SELECT case_id, activity FROM default.hire_to_retire_event_log ORDER BY case_id ASC, parseDateTimeBestEffort(timestamp) ASC) GROUP BY case_id) AS grouped_cases GROUP BY grouped_activities ORDER BY pattern_count DESC"
    },
    {
        "view_name": "sop_deviation_analyzer_logistics_event_log",
        "database": "default",
        "view_definition": "CREATE VIEW default.sop_deviation_analyzer_logistics_event_log (`pattern_sl_no` UInt64, `pattern_count` UInt64, `percentage` Nullable(Float64), `sop_deviation_sequence_preview` Array(String)) AS WITH (SELECT countDistinct(case_id) FROM default.logistics_event_log) AS total_count SELECT row_number() OVER (ORDER BY count() DESC) AS pattern_sl_no, count() AS pattern_count, round((count() * 100.) / total_count, 2) AS percentage, grouped_activities AS sop_deviation_sequence_preview FROM (SELECT case_id, groupArray(activity) AS grouped_activities FROM (SELECT case_id, activity FROM default.logistics_event_log ORDER BY case_id ASC, parseDateTimeBestEffort(timestamp) ASC) GROUP BY case_id) AS grouped_cases GROUP BY grouped_activities ORDER BY pattern_count DESC"
    },
    {
        "view_name": "sop_deviation_analyzer_mortgage_events",
        "database": "default",
        "view_definition": "CREATE VIEW default.sop_deviation_analyzer_mortgage_events (`pattern_sl_no` UInt64, `pattern_count` UInt64, `percentage` Nullable(Float64), `sop_deviation_sequence_preview` Array(String)) AS WITH (SELECT countDistinct(case_id) FROM default.mortgage_events) AS total_count SELECT row_number() OVER (ORDER BY count() DESC) AS pattern_sl_no, count() AS pattern_count, round((count() * 100.) / total_count, 2) AS percentage, grouped_activities AS sop_deviation_sequence_preview FROM (SELECT case_id, groupArray(activity) AS grouped_activities FROM (SELECT case_id, activity FROM default.mortgage_events ORDER BY case_id ASC, parseDateTimeBestEffort(timestamp) ASC) GROUP BY case_id) AS grouped_cases GROUP BY grouped_activities ORDER BY pattern_count DESC"
    },
    {
        "view_name": "sop_deviation_analyzer_o2c_event_log",
        "database": "default",
        "view_definition": "CREATE VIEW default.sop_deviation_analyzer_o2c_event_log (`pattern_sl_no` UInt64, `pattern_count` UInt64, `percentage` Nullable(Float64), `sop_deviation_sequence_preview` Array(String)) AS WITH (SELECT countDistinct(case_id) FROM default.o2c_event_log) AS total_count SELECT row_number() OVER (ORDER BY count() DESC) AS pattern_sl_no, count() AS pattern_count, round((count() * 100.) / total_count, 2) AS percentage, grouped_activities AS sop_deviation_sequence_preview FROM (SELECT case_id, groupArray(activity) AS grouped_activities FROM (SELECT case_id, activity FROM default.o2c_event_log ORDER BY case_id ASC, parseDateTimeBestEffort(timestamp) ASC) GROUP BY case_id) AS grouped_cases GROUP BY grouped_activities ORDER BY pattern_count DESC"
    },
    {
        "view_name": "sop_deviation_analyzer_p2p_event_log",
        "database": "default",
        "view_definition": "CREATE VIEW default.sop_deviation_analyzer_p2p_event_log (`pattern_sl_no` UInt64, `pattern_count` UInt64, `percentage` Nullable(Float64), `sop_deviation_sequence_preview` Array(String)) AS WITH (SELECT countDistinct(case_id) FROM default.p2p_event_log) AS total_count SELECT row_number() OVER (ORDER BY count() DESC) AS pattern_sl_no, count() AS pattern_count, round((count() * 100.) / total_count, 2) AS percentage, grouped_activities AS sop_deviation_sequence_preview FROM (SELECT case_id, groupArray(activity) AS grouped_activities FROM (SELECT case_id, activity FROM default.p2p_event_log ORDER BY case_id ASC, parseDateTimeBestEffort(timestamp) ASC) GROUP BY case_id) AS grouped_cases GROUP BY grouped_activities ORDER BY pattern_count DESC"
    },
    {
        "view_name": "sop_statistics_analyzer_IncidentManagement",
        "database": "default",
        "view_definition": "CREATE VIEW default.sop_statistics_analyzer_IncidentManagement (`pattern_rank` UInt64, `pattern_case_count` UInt64, `pattern_sequence` Array(String), `avg_total_events` Float64, `avg_activity_variety` Float64, `avg_resource_variety` Float64, `avg_duration_hours` Float64, `pattern_complexity_score` Float64, `Business Interpretation` String) AS WITH case_with_metrics AS (SELECT case_id, groupArray(activity) AS activity_sequence, count(activity) AS total_events, COUNTDistinct(activity) AS activity_variety, COUNTDistinct(resource) AS resource_variety, (max(parseDateTimeBestEffort(timestamp)) - min(parseDateTimeBestEffort(timestamp))) / 3600. AS duration_hours FROM default.IncidentManagement GROUP BY case_id), pattern_level_stats AS (SELECT activity_sequence, count() AS pattern_case_count, avg(total_events) AS avg_total_events, avg(activity_variety) AS avg_activity_variety, avg(resource_variety) AS avg_resource_variety, avg(duration_hours) AS avg_duration_hours FROM case_with_metrics GROUP BY activity_sequence), overall_stats_for_scoring AS (SELECT avg(avg_duration_hours) AS mean_of_avg_duration, stddevPop(avg_duration_hours) AS stddev_of_avg_duration, avg(avg_resource_variety) AS mean_of_avg_resource_variety, stddevPop(avg_resource_variety) AS stddev_of_avg_resource_variety FROM pattern_level_stats), patterns_with_scores AS (SELECT row_number() OVER (ORDER BY pls.pattern_case_count DESC) AS pattern_rank, pls.pattern_case_count, pls.activity_sequence AS pattern_sequence, round(pls.avg_total_events, 2) AS avg_total_events, round(pls.avg_activity_variety, 2) AS avg_activity_variety, round(pls.avg_resource_variety, 2) AS avg_resource_variety, round(pls.avg_duration_hours, 2) AS avg_duration_hours, round((if(oss.stddev_of_avg_duration = 0, 0, (pls.avg_duration_hours - oss.mean_of_avg_duration) / oss.stddev_of_avg_duration) + if(oss.stddev_of_avg_resource_variety = 0, 0, (pls.avg_resource_variety - oss.mean_of_avg_resource_variety) / oss.stddev_of_avg_resource_variety)) / 2, 2) AS pattern_complexity_score FROM pattern_level_stats AS pls, overall_stats_for_scoring AS oss) SELECT *, multiIf(pattern_complexity_score > 1., 'Problem Pattern', pattern_complexity_score < -1., 'Best Practice Pattern', 'Standard Pattern') AS `Business Interpretation` FROM patterns_with_scores ORDER BY pattern_rank ASC"
    },
    {
        "view_name": "sop_statistics_analyzer_ap_event_log",
        "database": "default",
        "view_definition": "CREATE VIEW default.sop_statistics_analyzer_ap_event_log (`pattern_rank` UInt64, `pattern_case_count` UInt64, `pattern_sequence` Array(String), `avg_total_events` Float64, `avg_activity_variety` Float64, `avg_resource_variety` Float64, `avg_duration_hours` Float64, `pattern_complexity_score` Float64, `Business Interpretation` String) AS WITH case_with_metrics AS (SELECT case_id, groupArray(activity) AS activity_sequence, count(activity) AS total_events, COUNTDistinct(activity) AS activity_variety, COUNTDistinct(resource) AS resource_variety, (max(parseDateTimeBestEffort(timestamp)) - min(parseDateTimeBestEffort(timestamp))) / 3600. AS duration_hours FROM default.ap_event_log GROUP BY case_id), pattern_level_stats AS (SELECT activity_sequence, count() AS pattern_case_count, avg(total_events) AS avg_total_events, avg(activity_variety) AS avg_activity_variety, avg(resource_variety) AS avg_resource_variety, avg(duration_hours) AS avg_duration_hours FROM case_with_metrics GROUP BY activity_sequence), overall_stats_for_scoring AS (SELECT avg(avg_duration_hours) AS mean_of_avg_duration, stddevPop(avg_duration_hours) AS stddev_of_avg_duration, avg(avg_resource_variety) AS mean_of_avg_resource_variety, stddevPop(avg_resource_variety) AS stddev_of_avg_resource_variety FROM pattern_level_stats), patterns_with_scores AS (SELECT row_number() OVER (ORDER BY pls.pattern_case_count DESC) AS pattern_rank, pls.pattern_case_count, pls.activity_sequence AS pattern_sequence, round(pls.avg_total_events, 2) AS avg_total_events, round(pls.avg_activity_variety, 2) AS avg_activity_variety, round(pls.avg_resource_variety, 2) AS avg_resource_variety, round(pls.avg_duration_hours, 2) AS avg_duration_hours, round((if(oss.stddev_of_avg_duration = 0, 0, (pls.avg_duration_hours - oss.mean_of_avg_duration) / oss.stddev_of_avg_duration) + if(oss.stddev_of_avg_resource_variety = 0, 0, (pls.avg_resource_variety - oss.mean_of_avg_resource_variety) / oss.stddev_of_avg_resource_variety)) / 2, 2) AS pattern_complexity_score FROM pattern_level_stats AS pls, overall_stats_for_scoring AS oss) SELECT *, multiIf(pattern_complexity_score > 1., 'Problem Pattern', pattern_complexity_score < -1., 'Best Practice Pattern', 'Standard Pattern') AS `Business Interpretation` FROM patterns_with_scores ORDER BY pattern_rank ASC"
    },
    {
        "view_name": "sop_statistics_analyzer_ar_event_log",
        "database": "default",
        "view_definition": "CREATE VIEW default.sop_statistics_analyzer_ar_event_log (`pattern_rank` UInt64, `pattern_case_count` UInt64, `pattern_sequence` Array(String), `avg_total_events` Float64, `avg_activity_variety` Float64, `avg_resource_variety` Float64, `avg_duration_hours` Float64, `pattern_complexity_score` Float64, `Business Interpretation` String) AS WITH case_with_metrics AS (SELECT case_id, groupArray(activity) AS activity_sequence, count(activity) AS total_events, COUNTDistinct(activity) AS activity_variety, COUNTDistinct(resource) AS resource_variety, (max(parseDateTimeBestEffort(timestamp)) - min(parseDateTimeBestEffort(timestamp))) / 3600. AS duration_hours FROM default.ar_event_log GROUP BY case_id), pattern_level_stats AS (SELECT activity_sequence, count() AS pattern_case_count, avg(total_events) AS avg_total_events, avg(activity_variety) AS avg_activity_variety, avg(resource_variety) AS avg_resource_variety, avg(duration_hours) AS avg_duration_hours FROM case_with_metrics GROUP BY activity_sequence), overall_stats_for_scoring AS (SELECT avg(avg_duration_hours) AS mean_of_avg_duration, stddevPop(avg_duration_hours) AS stddev_of_avg_duration, avg(avg_resource_variety) AS mean_of_avg_resource_variety, stddevPop(avg_resource_variety) AS stddev_of_avg_resource_variety FROM pattern_level_stats), patterns_with_scores AS (SELECT row_number() OVER (ORDER BY pls.pattern_case_count DESC) AS pattern_rank, pls.pattern_case_count, pls.activity_sequence AS pattern_sequence, round(pls.avg_total_events, 2) AS avg_total_events, round(pls.avg_activity_variety, 2) AS avg_activity_variety, round(pls.avg_resource_variety, 2) AS avg_resource_variety, round(pls.avg_duration_hours, 2) AS avg_duration_hours, round((if(oss.stddev_of_avg_duration = 0, 0, (pls.avg_duration_hours - oss.mean_of_avg_duration) / oss.stddev_of_avg_duration) + if(oss.stddev_of_avg_resource_variety = 0, 0, (pls.avg_resource_variety - oss.mean_of_avg_resource_variety) / oss.stddev_of_avg_resource_variety)) / 2, 2) AS pattern_complexity_score FROM pattern_level_stats AS pls, overall_stats_for_scoring AS oss) SELECT *, multiIf(pattern_complexity_score > 1., 'Problem Pattern', pattern_complexity_score < -1., 'Best Practice Pattern', 'Standard Pattern') AS `Business Interpretation` FROM patterns_with_scores ORDER BY pattern_rank ASC"
    },
    {
        "view_name": "sop_statistics_analyzer_car_insurance_claims",
        "database": "default",
        "view_definition": "CREATE VIEW default.sop_statistics_analyzer_car_insurance_claims (`pattern_rank` UInt64, `pattern_case_count` UInt64, `pattern_sequence` Array(String), `avg_total_events` Float64, `avg_activity_variety` Float64, `avg_resource_variety` Float64, `avg_duration_hours` Float64, `pattern_complexity_score` Float64, `Business Interpretation` String) AS WITH case_with_metrics AS (SELECT case_id, groupArray(activity) AS activity_sequence, count(activity) AS total_events, COUNTDistinct(activity) AS activity_variety, COUNTDistinct(resource) AS resource_variety, (max(parseDateTimeBestEffort(timestamp)) - min(parseDateTimeBestEffort(timestamp))) / 3600. AS duration_hours FROM default.car_insurance_claims GROUP BY case_id), pattern_level_stats AS (SELECT activity_sequence, count() AS pattern_case_count, avg(total_events) AS avg_total_events, avg(activity_variety) AS avg_activity_variety, avg(resource_variety) AS avg_resource_variety, avg(duration_hours) AS avg_duration_hours FROM case_with_metrics GROUP BY activity_sequence), overall_stats_for_scoring AS (SELECT avg(avg_duration_hours) AS mean_of_avg_duration, stddevPop(avg_duration_hours) AS stddev_of_avg_duration, avg(avg_resource_variety) AS mean_of_avg_resource_variety, stddevPop(avg_resource_variety) AS stddev_of_avg_resource_variety FROM pattern_level_stats), patterns_with_scores AS (SELECT row_number() OVER (ORDER BY pls.pattern_case_count DESC) AS pattern_rank, pls.pattern_case_count, pls.activity_sequence AS pattern_sequence, round(pls.avg_total_events, 2) AS avg_total_events, round(pls.avg_activity_variety, 2) AS avg_activity_variety, round(pls.avg_resource_variety, 2) AS avg_resource_variety, round(pls.avg_duration_hours, 2) AS avg_duration_hours, round((if(oss.stddev_of_avg_duration = 0, 0, (pls.avg_duration_hours - oss.mean_of_avg_duration) / oss.stddev_of_avg_duration) + if(oss.stddev_of_avg_resource_variety = 0, 0, (pls.avg_resource_variety - oss.mean_of_avg_resource_variety) / oss.stddev_of_avg_resource_variety)) / 2, 2) AS pattern_complexity_score FROM pattern_level_stats AS pls, overall_stats_for_scoring AS oss) SELECT *, multiIf(pattern_complexity_score > 1., 'Problem Pattern', pattern_complexity_score < -1., 'Best Practice Pattern', 'Standard Pattern') AS `Business Interpretation` FROM patterns_with_scores ORDER BY pattern_rank ASC"
    },
    {
        "view_name": "sop_statistics_analyzer_hire_to_retire_event_log",
        "database": "default",
        "view_definition": "CREATE VIEW default.sop_statistics_analyzer_hire_to_retire_event_log (`pattern_rank` UInt64, `pattern_case_count` UInt64, `pattern_sequence` Array(String), `avg_total_events` Float64, `avg_activity_variety` Float64, `avg_resource_variety` Float64, `avg_duration_hours` Float64, `pattern_complexity_score` Float64, `Business Interpretation` String) AS WITH case_with_metrics AS (SELECT case_id, groupArray(activity) AS activity_sequence, count(activity) AS total_events, COUNTDistinct(activity) AS activity_variety, COUNTDistinct(resource) AS resource_variety, (max(parseDateTimeBestEffort(timestamp)) - min(parseDateTimeBestEffort(timestamp))) / 3600. AS duration_hours FROM default.hire_to_retire_event_log GROUP BY case_id), pattern_level_stats AS (SELECT activity_sequence, count() AS pattern_case_count, avg(total_events) AS avg_total_events, avg(activity_variety) AS avg_activity_variety, avg(resource_variety) AS avg_resource_variety, avg(duration_hours) AS avg_duration_hours FROM case_with_metrics GROUP BY activity_sequence), overall_stats_for_scoring AS (SELECT avg(avg_duration_hours) AS mean_of_avg_duration, stddevPop(avg_duration_hours) AS stddev_of_avg_duration, avg(avg_resource_variety) AS mean_of_avg_resource_variety, stddevPop(avg_resource_variety) AS stddev_of_avg_resource_variety FROM pattern_level_stats), patterns_with_scores AS (SELECT row_number() OVER (ORDER BY pls.pattern_case_count DESC) AS pattern_rank, pls.pattern_case_count, pls.activity_sequence AS pattern_sequence, round(pls.avg_total_events, 2) AS avg_total_events, round(pls.avg_activity_variety, 2) AS avg_activity_variety, round(pls.avg_resource_variety, 2) AS avg_resource_variety, round(pls.avg_duration_hours, 2) AS avg_duration_hours, round((if(oss.stddev_of_avg_duration = 0, 0, (pls.avg_duration_hours - oss.mean_of_avg_duration) / oss.stddev_of_avg_duration) + if(oss.stddev_of_avg_resource_variety = 0, 0, (pls.avg_resource_variety - oss.mean_of_avg_resource_variety) / oss.stddev_of_avg_resource_variety)) / 2, 2) AS pattern_complexity_score FROM pattern_level_stats AS pls, overall_stats_for_scoring AS oss) SELECT *, multiIf(pattern_complexity_score > 1., 'Problem Pattern', pattern_complexity_score < -1., 'Best Practice Pattern', 'Standard Pattern') AS `Business Interpretation` FROM patterns_with_scores ORDER BY pattern_rank ASC"
    },
    {
        "view_name": "sop_statistics_analyzer_logistics_event_log",
        "database": "default",
        "view_definition": "CREATE VIEW default.sop_statistics_analyzer_logistics_event_log (`pattern_rank` UInt64, `pattern_case_count` UInt64, `pattern_sequence` Array(String), `avg_total_events` Float64, `avg_activity_variety` Float64, `avg_resource_variety` Float64, `avg_duration_hours` Float64, `pattern_complexity_score` Float64, `Business Interpretation` String) AS WITH case_with_metrics AS (SELECT case_id, groupArray(activity) AS activity_sequence, count(activity) AS total_events, COUNTDistinct(activity) AS activity_variety, COUNTDistinct(resource) AS resource_variety, (max(parseDateTimeBestEffort(timestamp)) - min(parseDateTimeBestEffort(timestamp))) / 3600. AS duration_hours FROM default.logistics_event_log GROUP BY case_id), pattern_level_stats AS (SELECT activity_sequence, count() AS pattern_case_count, avg(total_events) AS avg_total_events, avg(activity_variety) AS avg_activity_variety, avg(resource_variety) AS avg_resource_variety, avg(duration_hours) AS avg_duration_hours FROM case_with_metrics GROUP BY activity_sequence), overall_stats_for_scoring AS (SELECT avg(avg_duration_hours) AS mean_of_avg_duration, stddevPop(avg_duration_hours) AS stddev_of_avg_duration, avg(avg_resource_variety) AS mean_of_avg_resource_variety, stddevPop(avg_resource_variety) AS stddev_of_avg_resource_variety FROM pattern_level_stats), patterns_with_scores AS (SELECT row_number() OVER (ORDER BY pls.pattern_case_count DESC) AS pattern_rank, pls.pattern_case_count, pls.activity_sequence AS pattern_sequence, round(pls.avg_total_events, 2) AS avg_total_events, round(pls.avg_activity_variety, 2) AS avg_activity_variety, round(pls.avg_resource_variety, 2) AS avg_resource_variety, round(pls.avg_duration_hours, 2) AS avg_duration_hours, round((if(oss.stddev_of_avg_duration = 0, 0, (pls.avg_duration_hours - oss.mean_of_avg_duration) / oss.stddev_of_avg_duration) + if(oss.stddev_of_avg_resource_variety = 0, 0, (pls.avg_resource_variety - oss.mean_of_avg_resource_variety) / oss.stddev_of_avg_resource_variety)) / 2, 2) AS pattern_complexity_score FROM pattern_level_stats AS pls, overall_stats_for_scoring AS oss) SELECT *, multiIf(pattern_complexity_score > 1., 'Problem Pattern', pattern_complexity_score < -1., 'Best Practice Pattern', 'Standard Pattern') AS `Business Interpretation` FROM patterns_with_scores ORDER BY pattern_rank ASC"
    },
    {
        "view_name": "sop_statistics_analyzer_mortgage_events",
        "database": "default",
        "view_definition": "CREATE VIEW default.sop_statistics_analyzer_mortgage_events (`pattern_rank` UInt64, `pattern_case_count` UInt64, `pattern_sequence` Array(String), `avg_total_events` Float64, `avg_activity_variety` Float64, `avg_resource_variety` Float64, `avg_duration_hours` Float64, `pattern_complexity_score` Float64, `Business Interpretation` String) AS WITH case_with_metrics AS (SELECT case_id, groupArray(activity) AS activity_sequence, count(activity) AS total_events, COUNTDistinct(activity) AS activity_variety, COUNTDistinct(resource) AS resource_variety, (max(parseDateTimeBestEffort(timestamp)) - min(parseDateTimeBestEffort(timestamp))) / 3600. AS duration_hours FROM default.mortgage_events GROUP BY case_id), pattern_level_stats AS (SELECT activity_sequence, count() AS pattern_case_count, avg(total_events) AS avg_total_events, avg(activity_variety) AS avg_activity_variety, avg(resource_variety) AS avg_resource_variety, avg(duration_hours) AS avg_duration_hours FROM case_with_metrics GROUP BY activity_sequence), overall_stats_for_scoring AS (SELECT avg(avg_duration_hours) AS mean_of_avg_duration, stddevPop(avg_duration_hours) AS stddev_of_avg_duration, avg(avg_resource_variety) AS mean_of_avg_resource_variety, stddevPop(avg_resource_variety) AS stddev_of_avg_resource_variety FROM pattern_level_stats), patterns_with_scores AS (SELECT row_number() OVER (ORDER BY pls.pattern_case_count DESC) AS pattern_rank, pls.pattern_case_count, pls.activity_sequence AS pattern_sequence, round(pls.avg_total_events, 2) AS avg_total_events, round(pls.avg_activity_variety, 2) AS avg_activity_variety, round(pls.avg_resource_variety, 2) AS avg_resource_variety, round(pls.avg_duration_hours, 2) AS avg_duration_hours, round((if(oss.stddev_of_avg_duration = 0, 0, (pls.avg_duration_hours - oss.mean_of_avg_duration) / oss.stddev_of_avg_duration) + if(oss.stddev_of_avg_resource_variety = 0, 0, (pls.avg_resource_variety - oss.mean_of_avg_resource_variety) / oss.stddev_of_avg_resource_variety)) / 2, 2) AS pattern_complexity_score FROM pattern_level_stats AS pls, overall_stats_for_scoring AS oss) SELECT *, multiIf(pattern_complexity_score > 1., 'Problem Pattern', pattern_complexity_score < -1., 'Best Practice Pattern', 'Standard Pattern') AS `Business Interpretation` FROM patterns_with_scores ORDER BY pattern_rank ASC"
    },
    {
        "view_name": "sop_statistics_analyzer_o2c_event_log",
        "database": "default",
        "view_definition": "CREATE VIEW default.sop_statistics_analyzer_o2c_event_log (`pattern_rank` UInt64, `pattern_case_count` UInt64, `pattern_sequence` Array(String), `avg_total_events` Float64, `avg_activity_variety` Float64, `avg_resource_variety` Float64, `avg_duration_hours` Float64, `pattern_complexity_score` Float64, `Business Interpretation` String) AS WITH case_with_metrics AS (SELECT case_id, groupArray(activity) AS activity_sequence, count(activity) AS total_events, COUNTDistinct(activity) AS activity_variety, COUNTDistinct(resource) AS resource_variety, (max(parseDateTimeBestEffort(timestamp)) - min(parseDateTimeBestEffort(timestamp))) / 3600. AS duration_hours FROM default.o2c_event_log GROUP BY case_id), pattern_level_stats AS (SELECT activity_sequence, count() AS pattern_case_count, avg(total_events) AS avg_total_events, avg(activity_variety) AS avg_activity_variety, avg(resource_variety) AS avg_resource_variety, avg(duration_hours) AS avg_duration_hours FROM case_with_metrics GROUP BY activity_sequence), overall_stats_for_scoring AS (SELECT avg(avg_duration_hours) AS mean_of_avg_duration, stddevPop(avg_duration_hours) AS stddev_of_avg_duration, avg(avg_resource_variety) AS mean_of_avg_resource_variety, stddevPop(avg_resource_variety) AS stddev_of_avg_resource_variety FROM pattern_level_stats), patterns_with_scores AS (SELECT row_number() OVER (ORDER BY pls.pattern_case_count DESC) AS pattern_rank, pls.pattern_case_count, pls.activity_sequence AS pattern_sequence, round(pls.avg_total_events, 2) AS avg_total_events, round(pls.avg_activity_variety, 2) AS avg_activity_variety, round(pls.avg_resource_variety, 2) AS avg_resource_variety, round(pls.avg_duration_hours, 2) AS avg_duration_hours, round((if(oss.stddev_of_avg_duration = 0, 0, (pls.avg_duration_hours - oss.mean_of_avg_duration) / oss.stddev_of_avg_duration) + if(oss.stddev_of_avg_resource_variety = 0, 0, (pls.avg_resource_variety - oss.mean_of_avg_resource_variety) / oss.stddev_of_avg_resource_variety)) / 2, 2) AS pattern_complexity_score FROM pattern_level_stats AS pls, overall_stats_for_scoring AS oss) SELECT *, multiIf(pattern_complexity_score > 1., 'Problem Pattern', pattern_complexity_score < -1., 'Best Practice Pattern', 'Standard Pattern') AS `Business Interpretation` FROM patterns_with_scores ORDER BY pattern_rank ASC"
    },
    {
        "view_name": "sop_statistics_analyzer_p2p_event_log",
        "database": "default",
        "view_definition": "CREATE VIEW default.sop_statistics_analyzer_p2p_event_log (`pattern_rank` UInt64, `pattern_case_count` UInt64, `pattern_sequence` Array(String), `avg_total_events` Float64, `avg_activity_variety` Float64, `avg_resource_variety` Float64, `avg_duration_hours` Float64, `pattern_complexity_score` Float64, `Business Interpretation` String) AS WITH case_with_metrics AS (SELECT case_id, groupArray(activity) AS activity_sequence, count(activity) AS total_events, COUNTDistinct(activity) AS activity_variety, COUNTDistinct(resource) AS resource_variety, (max(parseDateTimeBestEffort(timestamp)) - min(parseDateTimeBestEffort(timestamp))) / 3600. AS duration_hours FROM default.p2p_event_log GROUP BY case_id), pattern_level_stats AS (SELECT activity_sequence, count() AS pattern_case_count, avg(total_events) AS avg_total_events, avg(activity_variety) AS avg_activity_variety, avg(resource_variety) AS avg_resource_variety, avg(duration_hours) AS avg_duration_hours FROM case_with_metrics GROUP BY activity_sequence), overall_stats_for_scoring AS (SELECT avg(avg_duration_hours) AS mean_of_avg_duration, stddevPop(avg_duration_hours) AS stddev_of_avg_duration, avg(avg_resource_variety) AS mean_of_avg_resource_variety, stddevPop(avg_resource_variety) AS stddev_of_avg_resource_variety FROM pattern_level_stats), patterns_with_scores AS (SELECT row_number() OVER (ORDER BY pls.pattern_case_count DESC) AS pattern_rank, pls.pattern_case_count, pls.activity_sequence AS pattern_sequence, round(pls.avg_total_events, 2) AS avg_total_events, round(pls.avg_activity_variety, 2) AS avg_activity_variety, round(pls.avg_resource_variety, 2) AS avg_resource_variety, round(pls.avg_duration_hours, 2) AS avg_duration_hours, round((if(oss.stddev_of_avg_duration = 0, 0, (pls.avg_duration_hours - oss.mean_of_avg_duration) / oss.stddev_of_avg_duration) + if(oss.stddev_of_avg_resource_variety = 0, 0, (pls.avg_resource_variety - oss.mean_of_avg_resource_variety) / oss.stddev_of_avg_resource_variety)) / 2, 2) AS pattern_complexity_score FROM pattern_level_stats AS pls, overall_stats_for_scoring AS oss) SELECT *, multiIf(pattern_complexity_score > 1., 'Problem Pattern', pattern_complexity_score < -1., 'Best Practice Pattern', 'Standard Pattern') AS `Business Interpretation` FROM patterns_with_scores ORDER BY pattern_rank ASC"
    },
    {
        "view_name": "timing_analysis_analyzer_IncidentManagement",
        "database": "default",
        "view_definition": "CREATE VIEW default.timing_analysis_analyzer_IncidentManagement (`Activity` String, `Score` Nullable(Float64), `Outlier` String, `Violation Rate (%)` Float64, `Total Events` UInt64, `Violations After` UInt64) AS WITH ordered_events AS (SELECT case_id, activity, parseDateTimeBestEffort(timestamp) AS parsed_time, row_number() OVER (PARTITION BY case_id ORDER BY parseDateTimeBestEffort(timestamp) ASC) AS rn FROM default.IncidentManagement WHERE parsed_time IS NOT NULL), event_pairs AS (SELECT a.case_id, a.activity AS activity, round((toUnixTimestamp(a.parsed_time) - toUnixTimestamp(b.parsed_time)) / 3600., 2) AS duration_hours FROM ordered_events AS a INNER JOIN ordered_events AS b ON (a.case_id = b.case_id) AND (a.rn = (b.rn + 1)) WHERE (duration_hours > 0) AND (duration_hours < 8760)), activity_thresholds AS (SELECT activity, quantile(0.99)(duration_hours) AS p99_threshold_hours FROM event_pairs GROUP BY activity), activity_stats AS (SELECT ep.activity, count(*) AS total_events, avg(ep.duration_hours) AS avg_duration, stddevPop(ep.duration_hours) AS std_duration, sum(multiIf(ep.duration_hours > ath.p99_threshold_hours, 1, 0)) AS violations_after FROM event_pairs AS ep INNER JOIN activity_thresholds AS ath ON ep.activity = ath.activity GROUP BY ep.activity HAVING total_events >= 10), global_stats AS (SELECT avg(avg_duration) AS global_avg, stddevPop(avg_duration) AS global_std FROM activity_stats) SELECT activity AS Activity, round((avg_duration - global_stats.global_avg) / nullIf(global_stats.global_std, 0), 2) AS Score, 'Yes' AS Outlier, round((violations_after * 100.) / total_events, 2) AS `Violation Rate (%)`, total_events AS `Total Events`, violations_after AS `Violations After` FROM activity_stats, global_stats WHERE abs((avg_duration - global_stats.global_avg) / nullIf(global_stats.global_std, 0)) > 1.5 ORDER BY Score DESC LIMIT 50"
    },
    {
        "view_name": "timing_analysis_analyzer_ap_event_log",
        "database": "default",
        "view_definition": "CREATE VIEW default.timing_analysis_analyzer_ap_event_log (`Activity` String, `Score` Nullable(Float64), `Outlier` String, `Violation Rate (%)` Float64, `Total Events` UInt64, `Violations After` UInt64) AS WITH ordered_events AS (SELECT case_id, activity, parseDateTimeBestEffort(timestamp) AS parsed_time, row_number() OVER (PARTITION BY case_id ORDER BY parseDateTimeBestEffort(timestamp) ASC) AS rn FROM default.ap_event_log WHERE parsed_time IS NOT NULL), event_pairs AS (SELECT a.case_id, a.activity AS activity, round((toUnixTimestamp(a.parsed_time) - toUnixTimestamp(b.parsed_time)) / 3600., 2) AS duration_hours FROM ordered_events AS a INNER JOIN ordered_events AS b ON (a.case_id = b.case_id) AND (a.rn = (b.rn + 1)) WHERE (duration_hours > 0) AND (duration_hours < 8760)), activity_thresholds AS (SELECT activity, quantile(0.99)(duration_hours) AS p99_threshold_hours FROM event_pairs GROUP BY activity), activity_stats AS (SELECT ep.activity, count(*) AS total_events, avg(ep.duration_hours) AS avg_duration, stddevPop(ep.duration_hours) AS std_duration, sum(multiIf(ep.duration_hours > ath.p99_threshold_hours, 1, 0)) AS violations_after FROM event_pairs AS ep INNER JOIN activity_thresholds AS ath ON ep.activity = ath.activity GROUP BY ep.activity HAVING total_events >= 10), global_stats AS (SELECT avg(avg_duration) AS global_avg, stddevPop(avg_duration) AS global_std FROM activity_stats) SELECT activity AS Activity, round((avg_duration - global_stats.global_avg) / nullIf(global_stats.global_std, 0), 2) AS Score, 'Yes' AS Outlier, round((violations_after * 100.) / total_events, 2) AS `Violation Rate (%)`, total_events AS `Total Events`, violations_after AS `Violations After` FROM activity_stats, global_stats WHERE abs((avg_duration - global_stats.global_avg) / nullIf(global_stats.global_std, 0)) > 1.5 ORDER BY Score DESC LIMIT 50"
    },
    {
        "view_name": "timing_analysis_analyzer_ar_event_log",
        "database": "default",
        "view_definition": "CREATE VIEW default.timing_analysis_analyzer_ar_event_log (`Activity` String, `Score` Nullable(Float64), `Outlier` String, `Violation Rate (%)` Float64, `Total Events` UInt64, `Violations After` UInt64) AS WITH ordered_events AS (SELECT case_id, activity, parseDateTimeBestEffort(timestamp) AS parsed_time, row_number() OVER (PARTITION BY case_id ORDER BY parseDateTimeBestEffort(timestamp) ASC) AS rn FROM default.ar_event_log WHERE parsed_time IS NOT NULL), event_pairs AS (SELECT a.case_id, a.activity AS activity, round((toUnixTimestamp(a.parsed_time) - toUnixTimestamp(b.parsed_time)) / 3600., 2) AS duration_hours FROM ordered_events AS a INNER JOIN ordered_events AS b ON (a.case_id = b.case_id) AND (a.rn = (b.rn + 1)) WHERE (duration_hours > 0) AND (duration_hours < 8760)), activity_thresholds AS (SELECT activity, quantile(0.99)(duration_hours) AS p99_threshold_hours FROM event_pairs GROUP BY activity), activity_stats AS (SELECT ep.activity, count(*) AS total_events, avg(ep.duration_hours) AS avg_duration, stddevPop(ep.duration_hours) AS std_duration, sum(multiIf(ep.duration_hours > ath.p99_threshold_hours, 1, 0)) AS violations_after FROM event_pairs AS ep INNER JOIN activity_thresholds AS ath ON ep.activity = ath.activity GROUP BY ep.activity HAVING total_events >= 10), global_stats AS (SELECT avg(avg_duration) AS global_avg, stddevPop(avg_duration) AS global_std FROM activity_stats) SELECT activity AS Activity, round((avg_duration - global_stats.global_avg) / nullIf(global_stats.global_std, 0), 2) AS Score, 'Yes' AS Outlier, round((violations_after * 100.) / total_events, 2) AS `Violation Rate (%)`, total_events AS `Total Events`, violations_after AS `Violations After` FROM activity_stats, global_stats WHERE abs((avg_duration - global_stats.global_avg) / nullIf(global_stats.global_std, 0)) > 1.5 ORDER BY Score DESC LIMIT 50"
    },
    {
        "view_name": "timing_analysis_analyzer_car_insurance_claims",
        "database": "default",
        "view_definition": "CREATE VIEW default.timing_analysis_analyzer_car_insurance_claims (`Activity` String, `Score` Nullable(Float64), `Outlier` String, `Violation Rate (%)` Float64, `Total Events` UInt64, `Violations After` UInt64) AS WITH ordered_events AS (SELECT case_id, activity, parseDateTimeBestEffort(timestamp) AS parsed_time, row_number() OVER (PARTITION BY case_id ORDER BY parseDateTimeBestEffort(timestamp) ASC) AS rn FROM default.car_insurance_claims WHERE parsed_time IS NOT NULL), event_pairs AS (SELECT a.case_id, a.activity AS activity, round((toUnixTimestamp(a.parsed_time) - toUnixTimestamp(b.parsed_time)) / 3600., 2) AS duration_hours FROM ordered_events AS a INNER JOIN ordered_events AS b ON (a.case_id = b.case_id) AND (a.rn = (b.rn + 1)) WHERE (duration_hours > 0) AND (duration_hours < 8760)), activity_thresholds AS (SELECT activity, quantile(0.99)(duration_hours) AS p99_threshold_hours FROM event_pairs GROUP BY activity), activity_stats AS (SELECT ep.activity, count(*) AS total_events, avg(ep.duration_hours) AS avg_duration, stddevPop(ep.duration_hours) AS std_duration, sum(multiIf(ep.duration_hours > ath.p99_threshold_hours, 1, 0)) AS violations_after FROM event_pairs AS ep INNER JOIN activity_thresholds AS ath ON ep.activity = ath.activity GROUP BY ep.activity HAVING total_events >= 10), global_stats AS (SELECT avg(avg_duration) AS global_avg, stddevPop(avg_duration) AS global_std FROM activity_stats) SELECT activity AS Activity, round((avg_duration - global_stats.global_avg) / nullIf(global_stats.global_std, 0), 2) AS Score, 'Yes' AS Outlier, round((violations_after * 100.) / total_events, 2) AS `Violation Rate (%)`, total_events AS `Total Events`, violations_after AS `Violations After` FROM activity_stats, global_stats WHERE abs((avg_duration - global_stats.global_avg) / nullIf(global_stats.global_std, 0)) > 1.5 ORDER BY Score DESC LIMIT 50"
    },
    {
        "view_name": "timing_analysis_analyzer_hire_to_retire_event_log",
        "database": "default",
        "view_definition": "CREATE VIEW default.timing_analysis_analyzer_hire_to_retire_event_log (`Activity` String, `Score` Nullable(Float64), `Outlier` String, `Violation Rate (%)` Float64, `Total Events` UInt64, `Violations After` UInt64) AS WITH ordered_events AS (SELECT case_id, activity, parseDateTimeBestEffort(timestamp) AS parsed_time, row_number() OVER (PARTITION BY case_id ORDER BY parseDateTimeBestEffort(timestamp) ASC) AS rn FROM default.hire_to_retire_event_log WHERE parsed_time IS NOT NULL), event_pairs AS (SELECT a.case_id, a.activity AS activity, round((toUnixTimestamp(a.parsed_time) - toUnixTimestamp(b.parsed_time)) / 3600., 2) AS duration_hours FROM ordered_events AS a INNER JOIN ordered_events AS b ON (a.case_id = b.case_id) AND (a.rn = (b.rn + 1)) WHERE (duration_hours > 0) AND (duration_hours < 8760)), activity_thresholds AS (SELECT activity, quantile(0.99)(duration_hours) AS p99_threshold_hours FROM event_pairs GROUP BY activity), activity_stats AS (SELECT ep.activity, count(*) AS total_events, avg(ep.duration_hours) AS avg_duration, stddevPop(ep.duration_hours) AS std_duration, sum(multiIf(ep.duration_hours > ath.p99_threshold_hours, 1, 0)) AS violations_after FROM event_pairs AS ep INNER JOIN activity_thresholds AS ath ON ep.activity = ath.activity GROUP BY ep.activity HAVING total_events >= 10), global_stats AS (SELECT avg(avg_duration) AS global_avg, stddevPop(avg_duration) AS global_std FROM activity_stats) SELECT activity AS Activity, round((avg_duration - global_stats.global_avg) / nullIf(global_stats.global_std, 0), 2) AS Score, 'Yes' AS Outlier, round((violations_after * 100.) / total_events, 2) AS `Violation Rate (%)`, total_events AS `Total Events`, violations_after AS `Violations After` FROM activity_stats, global_stats WHERE abs((avg_duration - global_stats.global_avg) / nullIf(global_stats.global_std, 0)) > 1.5 ORDER BY Score DESC LIMIT 50"
    },
    {
        "view_name": "timing_analysis_analyzer_logistics_event_log",
        "database": "default",
        "view_definition": "CREATE VIEW default.timing_analysis_analyzer_logistics_event_log (`Activity` String, `Score` Nullable(Float64), `Outlier` String, `Violation Rate (%)` Float64, `Total Events` UInt64, `Violations After` UInt64) AS WITH ordered_events AS (SELECT case_id, activity, parseDateTimeBestEffort(timestamp) AS parsed_time, row_number() OVER (PARTITION BY case_id ORDER BY parseDateTimeBestEffort(timestamp) ASC) AS rn FROM default.logistics_event_log WHERE parsed_time IS NOT NULL), event_pairs AS (SELECT a.case_id, a.activity AS activity, round((toUnixTimestamp(a.parsed_time) - toUnixTimestamp(b.parsed_time)) / 3600., 2) AS duration_hours FROM ordered_events AS a INNER JOIN ordered_events AS b ON (a.case_id = b.case_id) AND (a.rn = (b.rn + 1)) WHERE (duration_hours > 0) AND (duration_hours < 8760)), activity_thresholds AS (SELECT activity, quantile(0.99)(duration_hours) AS p99_threshold_hours FROM event_pairs GROUP BY activity), activity_stats AS (SELECT ep.activity, count(*) AS total_events, avg(ep.duration_hours) AS avg_duration, stddevPop(ep.duration_hours) AS std_duration, sum(multiIf(ep.duration_hours > ath.p99_threshold_hours, 1, 0)) AS violations_after FROM event_pairs AS ep INNER JOIN activity_thresholds AS ath ON ep.activity = ath.activity GROUP BY ep.activity HAVING total_events >= 10), global_stats AS (SELECT avg(avg_duration) AS global_avg, stddevPop(avg_duration) AS global_std FROM activity_stats) SELECT activity AS Activity, round((avg_duration - global_stats.global_avg) / nullIf(global_stats.global_std, 0), 2) AS Score, 'Yes' AS Outlier, round((violations_after * 100.) / total_events, 2) AS `Violation Rate (%)`, total_events AS `Total Events`, violations_after AS `Violations After` FROM activity_stats, global_stats WHERE abs((avg_duration - global_stats.global_avg) / nullIf(global_stats.global_std, 0)) > 1.5 ORDER BY Score DESC LIMIT 50"
    },
    {
        "view_name": "timing_analysis_analyzer_mortgage_events",
        "database": "default",
        "view_definition": "CREATE VIEW default.timing_analysis_analyzer_mortgage_events (`Activity` String, `Score` Nullable(Float64), `Outlier` String, `Violation Rate (%)` Float64, `Total Events` UInt64, `Violations After` UInt64) AS WITH ordered_events AS (SELECT case_id, activity, parseDateTimeBestEffort(timestamp) AS parsed_time, row_number() OVER (PARTITION BY case_id ORDER BY parseDateTimeBestEffort(timestamp) ASC) AS rn FROM default.mortgage_events WHERE parsed_time IS NOT NULL), event_pairs AS (SELECT a.case_id, a.activity AS activity, round((toUnixTimestamp(a.parsed_time) - toUnixTimestamp(b.parsed_time)) / 3600., 2) AS duration_hours FROM ordered_events AS a INNER JOIN ordered_events AS b ON (a.case_id = b.case_id) AND (a.rn = (b.rn + 1)) WHERE (duration_hours > 0) AND (duration_hours < 8760)), activity_thresholds AS (SELECT activity, quantile(0.99)(duration_hours) AS p99_threshold_hours FROM event_pairs GROUP BY activity), activity_stats AS (SELECT ep.activity, count(*) AS total_events, avg(ep.duration_hours) AS avg_duration, stddevPop(ep.duration_hours) AS std_duration, sum(multiIf(ep.duration_hours > ath.p99_threshold_hours, 1, 0)) AS violations_after FROM event_pairs AS ep INNER JOIN activity_thresholds AS ath ON ep.activity = ath.activity GROUP BY ep.activity HAVING total_events >= 10), global_stats AS (SELECT avg(avg_duration) AS global_avg, stddevPop(avg_duration) AS global_std FROM activity_stats) SELECT activity AS Activity, round((avg_duration - global_stats.global_avg) / nullIf(global_stats.global_std, 0), 2) AS Score, 'Yes' AS Outlier, round((violations_after * 100.) / total_events, 2) AS `Violation Rate (%)`, total_events AS `Total Events`, violations_after AS `Violations After` FROM activity_stats, global_stats WHERE abs((avg_duration - global_stats.global_avg) / nullIf(global_stats.global_std, 0)) > 1.5 ORDER BY Score DESC LIMIT 50"
    },
    {
        "view_name": "timing_analysis_analyzer_o2c_event_log",
        "database": "default",
        "view_definition": "CREATE VIEW default.timing_analysis_analyzer_o2c_event_log (`Activity` String, `Score` Nullable(Float64), `Outlier` String, `Violation Rate (%)` Float64, `Total Events` UInt64, `Violations After` UInt64) AS WITH ordered_events AS (SELECT case_id, activity, parseDateTimeBestEffort(timestamp) AS parsed_time, row_number() OVER (PARTITION BY case_id ORDER BY parseDateTimeBestEffort(timestamp) ASC) AS rn FROM default.o2c_event_log WHERE parsed_time IS NOT NULL), event_pairs AS (SELECT a.case_id, a.activity AS activity, round((toUnixTimestamp(a.parsed_time) - toUnixTimestamp(b.parsed_time)) / 3600., 2) AS duration_hours FROM ordered_events AS a INNER JOIN ordered_events AS b ON (a.case_id = b.case_id) AND (a.rn = (b.rn + 1)) WHERE (duration_hours > 0) AND (duration_hours < 8760)), activity_thresholds AS (SELECT activity, quantile(0.99)(duration_hours) AS p99_threshold_hours FROM event_pairs GROUP BY activity), activity_stats AS (SELECT ep.activity, count(*) AS total_events, avg(ep.duration_hours) AS avg_duration, stddevPop(ep.duration_hours) AS std_duration, sum(multiIf(ep.duration_hours > ath.p99_threshold_hours, 1, 0)) AS violations_after FROM event_pairs AS ep INNER JOIN activity_thresholds AS ath ON ep.activity = ath.activity GROUP BY ep.activity HAVING total_events >= 10), global_stats AS (SELECT avg(avg_duration) AS global_avg, stddevPop(avg_duration) AS global_std FROM activity_stats) SELECT activity AS Activity, round((avg_duration - global_stats.global_avg) / nullIf(global_stats.global_std, 0), 2) AS Score, 'Yes' AS Outlier, round((violations_after * 100.) / total_events, 2) AS `Violation Rate (%)`, total_events AS `Total Events`, violations_after AS `Violations After` FROM activity_stats, global_stats WHERE abs((avg_duration - global_stats.global_avg) / nullIf(global_stats.global_std, 0)) > 1.5 ORDER BY Score DESC LIMIT 50"
    },
    {
        "view_name": "timing_analysis_analyzer_p2p_event_log",
        "database": "default",
        "view_definition": "CREATE VIEW default.timing_analysis_analyzer_p2p_event_log (`Activity` String, `Score` Nullable(Float64), `Outlier` String, `Violation Rate (%)` Float64, `Total Events` UInt64, `Violations After` UInt64) AS WITH ordered_events AS (SELECT case_id, activity, parseDateTimeBestEffort(timestamp) AS parsed_time, row_number() OVER (PARTITION BY case_id ORDER BY parseDateTimeBestEffort(timestamp) ASC) AS rn FROM default.p2p_event_log WHERE parsed_time IS NOT NULL), event_pairs AS (SELECT a.case_id, a.activity AS activity, round((toUnixTimestamp(a.parsed_time) - toUnixTimestamp(b.parsed_time)) / 3600., 2) AS duration_hours FROM ordered_events AS a INNER JOIN ordered_events AS b ON (a.case_id = b.case_id) AND (a.rn = (b.rn + 1)) WHERE (duration_hours > 0) AND (duration_hours < 8760)), activity_thresholds AS (SELECT activity, quantile(0.99)(duration_hours) AS p99_threshold_hours FROM event_pairs GROUP BY activity), activity_stats AS (SELECT ep.activity, count(*) AS total_events, avg(ep.duration_hours) AS avg_duration, stddevPop(ep.duration_hours) AS std_duration, sum(multiIf(ep.duration_hours > ath.p99_threshold_hours, 1, 0)) AS violations_after FROM event_pairs AS ep INNER JOIN activity_thresholds AS ath ON ep.activity = ath.activity GROUP BY ep.activity HAVING total_events >= 10), global_stats AS (SELECT avg(avg_duration) AS global_avg, stddevPop(avg_duration) AS global_std FROM activity_stats) SELECT activity AS Activity, round((avg_duration - global_stats.global_avg) / nullIf(global_stats.global_std, 0), 2) AS Score, 'Yes' AS Outlier, round((violations_after * 100.) / total_events, 2) AS `Violation Rate (%)`, total_events AS `Total Events`, violations_after AS `Violations After` FROM activity_stats, global_stats WHERE abs((avg_duration - global_stats.global_avg) / nullIf(global_stats.global_std, 0)) > 1.5 ORDER BY Score DESC LIMIT 50"
    },
    {
        "view_name": "timing_violations_analyzer_IncidentManagement",
        "database": "default",
        "view_definition": "CREATE VIEW default.timing_violations_analyzer_IncidentManagement (`Case ID` String, `From Activity` String, `To Activity` String, `Gap (h)` Float64, `Threshold (h)` Float64, `Exceeded By (h)` Float64, `Violation Time` String) AS WITH gaps_with_duration AS (SELECT case_id, activities[idx] AS from_activity, activities[idx + 1] AS to_activity, round((toUnixTimestamp(parseDateTimeBestEffort(timestamps[idx + 1])) - toUnixTimestamp(parseDateTimeBestEffort(timestamps[idx]))) / 3600., 2) AS gap_hours FROM (SELECT case_id, groupArray(activity) AS activities, groupArray(timestamp) AS timestamps FROM (SELECT case_id, activity, timestamp FROM default.IncidentManagement ORDER BY case_id ASC, parseDateTimeBestEffort(timestamp) ASC) GROUP BY case_id) ARRAY JOIN arrayEnumerate(activities) AS idx WHERE (idx < length(activities)) AND (gap_hours >= 0)), gap_thresholds AS (SELECT from_activity, to_activity, avg(gap_hours) AS threshold_hours FROM gaps_with_duration GROUP BY from_activity, to_activity), all_violations AS (SELECT g.case_id, g.from_activity, g.to_activity, round(g.gap_hours, 2) AS `Gap (h)`, round(t.threshold_hours, 2) AS `Threshold (h)`, round(g.gap_hours - t.threshold_hours, 2) AS `Exceeded By (h)` FROM gaps_with_duration AS g INNER JOIN gap_thresholds AS t ON (g.from_activity = t.from_activity) AND (g.to_activity = t.to_activity) WHERE g.gap_hours > t.threshold_hours), top_tier_cutoff AS (SELECT quantile(0.9)(`Exceeded By (h)`) AS cutoff_value FROM all_violations) SELECT v.case_id AS `Case ID`, v.from_activity AS `From Activity`, v.to_activity AS `To Activity`, v.`Gap (h)`, v.`Threshold (h)`, v.`Exceeded By (h)`, multiIf(v.`Gap (h)` > (v.`Threshold (h)` * 2), 'Critical Violation', v.`Gap (h)` > (v.`Threshold (h)` * 1.5), 'High Violation', 'Medium Violation') AS `Violation Time` FROM all_violations AS v WHERE v.`Exceeded By (h)` >= (SELECT cutoff_value FROM top_tier_cutoff) ORDER BY `Exceeded By (h)` DESC, `Case ID` ASC"
    },
    {
        "view_name": "timing_violations_analyzer_ap_event_log",
        "database": "default",
        "view_definition": "CREATE VIEW default.timing_violations_analyzer_ap_event_log (`Case ID` String, `From Activity` String, `To Activity` String, `Gap (h)` Float64, `Threshold (h)` Float64, `Exceeded By (h)` Float64, `Violation Time` String) AS WITH gaps_with_duration AS (SELECT case_id, activities[idx] AS from_activity, activities[idx + 1] AS to_activity, round((toUnixTimestamp(parseDateTimeBestEffort(timestamps[idx + 1])) - toUnixTimestamp(parseDateTimeBestEffort(timestamps[idx]))) / 3600., 2) AS gap_hours FROM (SELECT case_id, groupArray(activity) AS activities, groupArray(timestamp) AS timestamps FROM (SELECT case_id, activity, timestamp FROM default.ap_event_log ORDER BY case_id ASC, parseDateTimeBestEffort(timestamp) ASC) GROUP BY case_id) ARRAY JOIN arrayEnumerate(activities) AS idx WHERE (idx < length(activities)) AND (gap_hours >= 0)), gap_thresholds AS (SELECT from_activity, to_activity, avg(gap_hours) AS threshold_hours FROM gaps_with_duration GROUP BY from_activity, to_activity), all_violations AS (SELECT g.case_id, g.from_activity, g.to_activity, round(g.gap_hours, 2) AS `Gap (h)`, round(t.threshold_hours, 2) AS `Threshold (h)`, round(g.gap_hours - t.threshold_hours, 2) AS `Exceeded By (h)` FROM gaps_with_duration AS g INNER JOIN gap_thresholds AS t ON (g.from_activity = t.from_activity) AND (g.to_activity = t.to_activity) WHERE g.gap_hours > t.threshold_hours), top_tier_cutoff AS (SELECT quantile(0.9)(`Exceeded By (h)`) AS cutoff_value FROM all_violations) SELECT v.case_id AS `Case ID`, v.from_activity AS `From Activity`, v.to_activity AS `To Activity`, v.`Gap (h)`, v.`Threshold (h)`, v.`Exceeded By (h)`, multiIf(v.`Gap (h)` > (v.`Threshold (h)` * 2), 'Critical Violation', v.`Gap (h)` > (v.`Threshold (h)` * 1.5), 'High Violation', 'Medium Violation') AS `Violation Time` FROM all_violations AS v WHERE v.`Exceeded By (h)` >= (SELECT cutoff_value FROM top_tier_cutoff) ORDER BY `Exceeded By (h)` DESC, `Case ID` ASC"
    },
    {
        "view_name": "timing_violations_analyzer_ar_event_log",
        "database": "default",
        "view_definition": "CREATE VIEW default.timing_violations_analyzer_ar_event_log (`Case ID` String, `From Activity` String, `To Activity` String, `Gap (h)` Float64, `Threshold (h)` Float64, `Exceeded By (h)` Float64, `Violation Time` String) AS WITH gaps_with_duration AS (SELECT case_id, activities[idx] AS from_activity, activities[idx + 1] AS to_activity, round((toUnixTimestamp(parseDateTimeBestEffort(timestamps[idx + 1])) - toUnixTimestamp(parseDateTimeBestEffort(timestamps[idx]))) / 3600., 2) AS gap_hours FROM (SELECT case_id, groupArray(activity) AS activities, groupArray(timestamp) AS timestamps FROM (SELECT case_id, activity, timestamp FROM default.ar_event_log ORDER BY case_id ASC, parseDateTimeBestEffort(timestamp) ASC) GROUP BY case_id) ARRAY JOIN arrayEnumerate(activities) AS idx WHERE (idx < length(activities)) AND (gap_hours >= 0)), gap_thresholds AS (SELECT from_activity, to_activity, avg(gap_hours) AS threshold_hours FROM gaps_with_duration GROUP BY from_activity, to_activity), all_violations AS (SELECT g.case_id, g.from_activity, g.to_activity, round(g.gap_hours, 2) AS `Gap (h)`, round(t.threshold_hours, 2) AS `Threshold (h)`, round(g.gap_hours - t.threshold_hours, 2) AS `Exceeded By (h)` FROM gaps_with_duration AS g INNER JOIN gap_thresholds AS t ON (g.from_activity = t.from_activity) AND (g.to_activity = t.to_activity) WHERE g.gap_hours > t.threshold_hours), top_tier_cutoff AS (SELECT quantile(0.9)(`Exceeded By (h)`) AS cutoff_value FROM all_violations) SELECT v.case_id AS `Case ID`, v.from_activity AS `From Activity`, v.to_activity AS `To Activity`, v.`Gap (h)`, v.`Threshold (h)`, v.`Exceeded By (h)`, multiIf(v.`Gap (h)` > (v.`Threshold (h)` * 2), 'Critical Violation', v.`Gap (h)` > (v.`Threshold (h)` * 1.5), 'High Violation', 'Medium Violation') AS `Violation Time` FROM all_violations AS v WHERE v.`Exceeded By (h)` >= (SELECT cutoff_value FROM top_tier_cutoff) ORDER BY `Exceeded By (h)` DESC, `Case ID` ASC"
    },
    {
        "view_name": "timing_violations_analyzer_car_insurance_claims",
        "database": "default",
        "view_definition": "CREATE VIEW default.timing_violations_analyzer_car_insurance_claims (`Case ID` String, `From Activity` String, `To Activity` String, `Gap (h)` Float64, `Threshold (h)` Float64, `Exceeded By (h)` Float64, `Violation Time` String) AS WITH gaps_with_duration AS (SELECT case_id, activities[idx] AS from_activity, activities[idx + 1] AS to_activity, round((toUnixTimestamp(parseDateTimeBestEffort(timestamps[idx + 1])) - toUnixTimestamp(parseDateTimeBestEffort(timestamps[idx]))) / 3600., 2) AS gap_hours FROM (SELECT case_id, groupArray(activity) AS activities, groupArray(timestamp) AS timestamps FROM (SELECT case_id, activity, timestamp FROM default.car_insurance_claims ORDER BY case_id ASC, parseDateTimeBestEffort(timestamp) ASC) GROUP BY case_id) ARRAY JOIN arrayEnumerate(activities) AS idx WHERE (idx < length(activities)) AND (gap_hours >= 0)), gap_thresholds AS (SELECT from_activity, to_activity, avg(gap_hours) AS threshold_hours FROM gaps_with_duration GROUP BY from_activity, to_activity), all_violations AS (SELECT g.case_id, g.from_activity, g.to_activity, round(g.gap_hours, 2) AS `Gap (h)`, round(t.threshold_hours, 2) AS `Threshold (h)`, round(g.gap_hours - t.threshold_hours, 2) AS `Exceeded By (h)` FROM gaps_with_duration AS g INNER JOIN gap_thresholds AS t ON (g.from_activity = t.from_activity) AND (g.to_activity = t.to_activity) WHERE g.gap_hours > t.threshold_hours), top_tier_cutoff AS (SELECT quantile(0.9)(`Exceeded By (h)`) AS cutoff_value FROM all_violations) SELECT v.case_id AS `Case ID`, v.from_activity AS `From Activity`, v.to_activity AS `To Activity`, v.`Gap (h)`, v.`Threshold (h)`, v.`Exceeded By (h)`, multiIf(v.`Gap (h)` > (v.`Threshold (h)` * 2), 'Critical Violation', v.`Gap (h)` > (v.`Threshold (h)` * 1.5), 'High Violation', 'Medium Violation') AS `Violation Time` FROM all_violations AS v WHERE v.`Exceeded By (h)` >= (SELECT cutoff_value FROM top_tier_cutoff) ORDER BY `Exceeded By (h)` DESC, `Case ID` ASC"
    },
    {
        "view_name": "timing_violations_analyzer_hire_to_retire_event_log",
        "database": "default",
        "view_definition": "CREATE VIEW default.timing_violations_analyzer_hire_to_retire_event_log (`Case ID` String, `From Activity` String, `To Activity` String, `Gap (h)` Float64, `Threshold (h)` Float64, `Exceeded By (h)` Float64, `Violation Time` String) AS WITH gaps_with_duration AS (SELECT case_id, activities[idx] AS from_activity, activities[idx + 1] AS to_activity, round((toUnixTimestamp(parseDateTimeBestEffort(timestamps[idx + 1])) - toUnixTimestamp(parseDateTimeBestEffort(timestamps[idx]))) / 3600., 2) AS gap_hours FROM (SELECT case_id, groupArray(activity) AS activities, groupArray(timestamp) AS timestamps FROM (SELECT case_id, activity, timestamp FROM default.hire_to_retire_event_log ORDER BY case_id ASC, parseDateTimeBestEffort(timestamp) ASC) GROUP BY case_id) ARRAY JOIN arrayEnumerate(activities) AS idx WHERE (idx < length(activities)) AND (gap_hours >= 0)), gap_thresholds AS (SELECT from_activity, to_activity, avg(gap_hours) AS threshold_hours FROM gaps_with_duration GROUP BY from_activity, to_activity), all_violations AS (SELECT g.case_id, g.from_activity, g.to_activity, round(g.gap_hours, 2) AS `Gap (h)`, round(t.threshold_hours, 2) AS `Threshold (h)`, round(g.gap_hours - t.threshold_hours, 2) AS `Exceeded By (h)` FROM gaps_with_duration AS g INNER JOIN gap_thresholds AS t ON (g.from_activity = t.from_activity) AND (g.to_activity = t.to_activity) WHERE g.gap_hours > t.threshold_hours), top_tier_cutoff AS (SELECT quantile(0.9)(`Exceeded By (h)`) AS cutoff_value FROM all_violations) SELECT v.case_id AS `Case ID`, v.from_activity AS `From Activity`, v.to_activity AS `To Activity`, v.`Gap (h)`, v.`Threshold (h)`, v.`Exceeded By (h)`, multiIf(v.`Gap (h)` > (v.`Threshold (h)` * 2), 'Critical Violation', v.`Gap (h)` > (v.`Threshold (h)` * 1.5), 'High Violation', 'Medium Violation') AS `Violation Time` FROM all_violations AS v WHERE v.`Exceeded By (h)` >= (SELECT cutoff_value FROM top_tier_cutoff) ORDER BY `Exceeded By (h)` DESC, `Case ID` ASC"
    },
    {
        "view_name": "timing_violations_analyzer_logistics_event_log",
        "database": "default",
        "view_definition": "CREATE VIEW default.timing_violations_analyzer_logistics_event_log (`Case ID` String, `From Activity` String, `To Activity` String, `Gap (h)` Float64, `Threshold (h)` Float64, `Exceeded By (h)` Float64, `Violation Time` String) AS WITH gaps_with_duration AS (SELECT case_id, activities[idx] AS from_activity, activities[idx + 1] AS to_activity, round((toUnixTimestamp(parseDateTimeBestEffort(timestamps[idx + 1])) - toUnixTimestamp(parseDateTimeBestEffort(timestamps[idx]))) / 3600., 2) AS gap_hours FROM (SELECT case_id, groupArray(activity) AS activities, groupArray(timestamp) AS timestamps FROM (SELECT case_id, activity, timestamp FROM default.logistics_event_log ORDER BY case_id ASC, parseDateTimeBestEffort(timestamp) ASC) GROUP BY case_id) ARRAY JOIN arrayEnumerate(activities) AS idx WHERE (idx < length(activities)) AND (gap_hours >= 0)), gap_thresholds AS (SELECT from_activity, to_activity, avg(gap_hours) AS threshold_hours FROM gaps_with_duration GROUP BY from_activity, to_activity), all_violations AS (SELECT g.case_id, g.from_activity, g.to_activity, round(g.gap_hours, 2) AS `Gap (h)`, round(t.threshold_hours, 2) AS `Threshold (h)`, round(g.gap_hours - t.threshold_hours, 2) AS `Exceeded By (h)` FROM gaps_with_duration AS g INNER JOIN gap_thresholds AS t ON (g.from_activity = t.from_activity) AND (g.to_activity = t.to_activity) WHERE g.gap_hours > t.threshold_hours), top_tier_cutoff AS (SELECT quantile(0.9)(`Exceeded By (h)`) AS cutoff_value FROM all_violations) SELECT v.case_id AS `Case ID`, v.from_activity AS `From Activity`, v.to_activity AS `To Activity`, v.`Gap (h)`, v.`Threshold (h)`, v.`Exceeded By (h)`, multiIf(v.`Gap (h)` > (v.`Threshold (h)` * 2), 'Critical Violation', v.`Gap (h)` > (v.`Threshold (h)` * 1.5), 'High Violation', 'Medium Violation') AS `Violation Time` FROM all_violations AS v WHERE v.`Exceeded By (h)` >= (SELECT cutoff_value FROM top_tier_cutoff) ORDER BY `Exceeded By (h)` DESC, `Case ID` ASC"
    },
    {
        "view_name": "timing_violations_analyzer_mortgage_events",
        "database": "default",
        "view_definition": "CREATE VIEW default.timing_violations_analyzer_mortgage_events (`Case ID` String, `From Activity` String, `To Activity` String, `Gap (h)` Float64, `Threshold (h)` Float64, `Exceeded By (h)` Float64, `Violation Time` String) AS WITH gaps_with_duration AS (SELECT case_id, activities[idx] AS from_activity, activities[idx + 1] AS to_activity, round((toUnixTimestamp(parseDateTimeBestEffort(timestamps[idx + 1])) - toUnixTimestamp(parseDateTimeBestEffort(timestamps[idx]))) / 3600., 2) AS gap_hours FROM (SELECT case_id, groupArray(activity) AS activities, groupArray(timestamp) AS timestamps FROM (SELECT case_id, activity, timestamp FROM default.mortgage_events ORDER BY case_id ASC, parseDateTimeBestEffort(timestamp) ASC) GROUP BY case_id) ARRAY JOIN arrayEnumerate(activities) AS idx WHERE (idx < length(activities)) AND (gap_hours >= 0)), gap_thresholds AS (SELECT from_activity, to_activity, avg(gap_hours) AS threshold_hours FROM gaps_with_duration GROUP BY from_activity, to_activity), all_violations AS (SELECT g.case_id, g.from_activity, g.to_activity, round(g.gap_hours, 2) AS `Gap (h)`, round(t.threshold_hours, 2) AS `Threshold (h)`, round(g.gap_hours - t.threshold_hours, 2) AS `Exceeded By (h)` FROM gaps_with_duration AS g INNER JOIN gap_thresholds AS t ON (g.from_activity = t.from_activity) AND (g.to_activity = t.to_activity) WHERE g.gap_hours > t.threshold_hours), top_tier_cutoff AS (SELECT quantile(0.9)(`Exceeded By (h)`) AS cutoff_value FROM all_violations) SELECT v.case_id AS `Case ID`, v.from_activity AS `From Activity`, v.to_activity AS `To Activity`, v.`Gap (h)`, v.`Threshold (h)`, v.`Exceeded By (h)`, multiIf(v.`Gap (h)` > (v.`Threshold (h)` * 2), 'Critical Violation', v.`Gap (h)` > (v.`Threshold (h)` * 1.5), 'High Violation', 'Medium Violation') AS `Violation Time` FROM all_violations AS v WHERE v.`Exceeded By (h)` >= (SELECT cutoff_value FROM top_tier_cutoff) ORDER BY `Exceeded By (h)` DESC, `Case ID` ASC"
    },
    {
        "view_name": "timing_violations_analyzer_o2c_event_log",
        "database": "default",
        "view_definition": "CREATE VIEW default.timing_violations_analyzer_o2c_event_log (`Case ID` String, `From Activity` String, `To Activity` String, `Gap (h)` Float64, `Threshold (h)` Float64, `Exceeded By (h)` Float64, `Violation Time` String) AS WITH gaps_with_duration AS (SELECT case_id, activities[idx] AS from_activity, activities[idx + 1] AS to_activity, round((toUnixTimestamp(parseDateTimeBestEffort(timestamps[idx + 1])) - toUnixTimestamp(parseDateTimeBestEffort(timestamps[idx]))) / 3600., 2) AS gap_hours FROM (SELECT case_id, groupArray(activity) AS activities, groupArray(timestamp) AS timestamps FROM (SELECT case_id, activity, timestamp FROM default.o2c_event_log ORDER BY case_id ASC, parseDateTimeBestEffort(timestamp) ASC) GROUP BY case_id) ARRAY JOIN arrayEnumerate(activities) AS idx WHERE (idx < length(activities)) AND (gap_hours >= 0)), gap_thresholds AS (SELECT from_activity, to_activity, avg(gap_hours) AS threshold_hours FROM gaps_with_duration GROUP BY from_activity, to_activity), all_violations AS (SELECT g.case_id, g.from_activity, g.to_activity, round(g.gap_hours, 2) AS `Gap (h)`, round(t.threshold_hours, 2) AS `Threshold (h)`, round(g.gap_hours - t.threshold_hours, 2) AS `Exceeded By (h)` FROM gaps_with_duration AS g INNER JOIN gap_thresholds AS t ON (g.from_activity = t.from_activity) AND (g.to_activity = t.to_activity) WHERE g.gap_hours > t.threshold_hours), top_tier_cutoff AS (SELECT quantile(0.9)(`Exceeded By (h)`) AS cutoff_value FROM all_violations) SELECT v.case_id AS `Case ID`, v.from_activity AS `From Activity`, v.to_activity AS `To Activity`, v.`Gap (h)`, v.`Threshold (h)`, v.`Exceeded By (h)`, multiIf(v.`Gap (h)` > (v.`Threshold (h)` * 2), 'Critical Violation', v.`Gap (h)` > (v.`Threshold (h)` * 1.5), 'High Violation', 'Medium Violation') AS `Violation Time` FROM all_violations AS v WHERE v.`Exceeded By (h)` >= (SELECT cutoff_value FROM top_tier_cutoff) ORDER BY `Exceeded By (h)` DESC, `Case ID` ASC"
    },
    {
        "view_name": "timing_violations_analyzer_p2p_event_log",
        "database": "default",
        "view_definition": "CREATE VIEW default.timing_violations_analyzer_p2p_event_log (`Case ID` String, `From Activity` String, `To Activity` String, `Gap (h)` Float64, `Threshold (h)` Float64, `Exceeded By (h)` Float64, `Violation Time` String) AS WITH gaps_with_duration AS (SELECT case_id, activities[idx] AS from_activity, activities[idx + 1] AS to_activity, round((toUnixTimestamp(parseDateTimeBestEffort(timestamps[idx + 1])) - toUnixTimestamp(parseDateTimeBestEffort(timestamps[idx]))) / 3600., 2) AS gap_hours FROM (SELECT case_id, groupArray(activity) AS activities, groupArray(timestamp) AS timestamps FROM (SELECT case_id, activity, timestamp FROM default.p2p_event_log ORDER BY case_id ASC, parseDateTimeBestEffort(timestamp) ASC) GROUP BY case_id) ARRAY JOIN arrayEnumerate(activities) AS idx WHERE (idx < length(activities)) AND (gap_hours >= 0)), gap_thresholds AS (SELECT from_activity, to_activity, avg(gap_hours) AS threshold_hours FROM gaps_with_duration GROUP BY from_activity, to_activity), all_violations AS (SELECT g.case_id, g.from_activity, g.to_activity, round(g.gap_hours, 2) AS `Gap (h)`, round(t.threshold_hours, 2) AS `Threshold (h)`, round(g.gap_hours - t.threshold_hours, 2) AS `Exceeded By (h)` FROM gaps_with_duration AS g INNER JOIN gap_thresholds AS t ON (g.from_activity = t.from_activity) AND (g.to_activity = t.to_activity) WHERE g.gap_hours > t.threshold_hours), top_tier_cutoff AS (SELECT quantile(0.9)(`Exceeded By (h)`) AS cutoff_value FROM all_violations) SELECT v.case_id AS `Case ID`, v.from_activity AS `From Activity`, v.to_activity AS `To Activity`, v.`Gap (h)`, v.`Threshold (h)`, v.`Exceeded By (h)`, multiIf(v.`Gap (h)` > (v.`Threshold (h)` * 2), 'Critical Violation', v.`Gap (h)` > (v.`Threshold (h)` * 1.5), 'High Violation', 'Medium Violation') AS `Violation Time` FROM all_violations AS v WHERE v.`Exceeded By (h)` >= (SELECT cutoff_value FROM top_tier_cutoff) ORDER BY `Exceeded By (h)` DESC, `Case ID` ASC"
    },
    {
        "view_name": "CHARACTER_SETS",
        "database": "information_schema",
        "view_definition": "CREATE VIEW information_schema.CHARACTER_SETS (`character_set_name` String, `CHARACTER_SET_NAME` String) SQL SECURITY INVOKER AS SELECT arrayJoin(['utf8', 'utf8mb4', 'ascii', 'binary']) AS character_set_name, character_set_name AS CHARACTER_SET_NAME"
    },
    {
        "view_name": "COLLATIONS",
        "database": "information_schema",
        "view_definition": "CREATE VIEW information_schema.COLLATIONS (`collation_name` String, `COLLATION_NAME` String) SQL SECURITY INVOKER AS SELECT name AS collation_name, collation_name AS COLLATION_NAME FROM system.collations"
    },
    {
        "view_name": "COLUMNS",
        "database": "information_schema",
        "view_definition": "CREATE VIEW information_schema.COLUMNS (`table_catalog` String, `table_schema` String, `table_name` String, `column_name` String, `ordinal_position` UInt64, `column_default` String, `is_nullable` String, `data_type` String, `character_maximum_length` Nullable(UInt64), `character_octet_length` Nullable(UInt64), `numeric_precision` Nullable(UInt64), `numeric_precision_radix` Nullable(UInt64), `numeric_scale` Nullable(UInt64), `datetime_precision` Nullable(UInt64), `character_set_catalog` Nullable(String), `character_set_schema` Nullable(String), `character_set_name` Nullable(String), `collation_catalog` Nullable(String), `collation_schema` Nullable(String), `collation_name` Nullable(String), `domain_catalog` Nullable(String), `domain_schema` Nullable(String), `domain_name` Nullable(String), `extra` Nullable(String), `column_comment` String, `column_type` String, `TABLE_CATALOG` String, `TABLE_SCHEMA` String, `TABLE_NAME` String, `COLUMN_NAME` String, `ORDINAL_POSITION` UInt64, `COLUMN_DEFAULT` String, `IS_NULLABLE` String, `DATA_TYPE` String, `CHARACTER_MAXIMUM_LENGTH` Nullable(UInt64), `CHARACTER_OCTET_LENGTH` Nullable(UInt64), `NUMERIC_PRECISION` Nullable(UInt64), `NUMERIC_PRECISION_RADIX` Nullable(UInt64), `NUMERIC_SCALE` Nullable(UInt64), `DATETIME_PRECISION` Nullable(UInt64), `CHARACTER_SET_CATALOG` Nullable(String), `CHARACTER_SET_SCHEMA` Nullable(String), `CHARACTER_SET_NAME` Nullable(String), `COLLATION_CATALOG` Nullable(String), `COLLATION_SCHEMA` Nullable(String), `COLLATION_NAME` Nullable(String), `DOMAIN_CATALOG` Nullable(String), `DOMAIN_SCHEMA` Nullable(String), `DOMAIN_NAME` Nullable(String), `EXTRA` Nullable(String), `COLUMN_COMMENT` String, `COLUMN_TYPE` String) SQL SECURITY INVOKER AS SELECT database AS table_catalog, database AS table_schema, `table` AS table_name, name AS column_name, position AS ordinal_position, default_expression AS column_default, type LIKE 'Nullable(%)' AS is_nullable, type AS data_type, character_octet_length AS character_maximum_length, character_octet_length, numeric_precision, numeric_precision_radix, numeric_scale, datetime_precision, NULL AS character_set_catalog, NULL AS character_set_schema, NULL AS character_set_name, NULL AS collation_catalog, NULL AS collation_schema, NULL AS collation_name, NULL AS domain_catalog, NULL AS domain_schema, NULL AS domain_name, multiIf(default_kind = 'DEFAULT', 'DEFAULT_GENERATED', default_kind = 'MATERIALIZED', 'STORED GENERATED', default_kind = 'ALIAS', 'VIRTUAL GENERATED', '') AS extra, comment AS column_comment, type AS column_type, table_catalog AS TABLE_CATALOG, table_schema AS TABLE_SCHEMA, table_name AS TABLE_NAME, column_name AS COLUMN_NAME, ordinal_position AS ORDINAL_POSITION, column_default AS COLUMN_DEFAULT, is_nullable AS IS_NULLABLE, data_type AS DATA_TYPE, character_maximum_length AS CHARACTER_MAXIMUM_LENGTH, character_octet_length AS CHARACTER_OCTET_LENGTH, numeric_precision AS NUMERIC_PRECISION, numeric_precision_radix AS NUMERIC_PRECISION_RADIX, numeric_scale AS NUMERIC_SCALE, datetime_precision AS DATETIME_PRECISION, character_set_catalog AS CHARACTER_SET_CATALOG, character_set_schema AS CHARACTER_SET_SCHEMA, character_set_name AS CHARACTER_SET_NAME, collation_catalog AS COLLATION_CATALOG, collation_schema AS COLLATION_SCHEMA, collation_name AS COLLATION_NAME, domain_catalog AS DOMAIN_CATALOG, domain_schema AS DOMAIN_SCHEMA, domain_name AS DOMAIN_NAME, extra AS EXTRA, column_comment AS COLUMN_COMMENT, column_type AS COLUMN_TYPE FROM system.columns"
    },
    {
        "view_name": "ENGINES",
        "database": "information_schema",
        "view_definition": "CREATE VIEW information_schema.ENGINES (`engine` String, `support` String, `ENGINE` String, `SUPPORT` String) SQL SECURITY INVOKER AS SELECT name AS engine, if(engine = getSetting('default_table_engine'), 'DEFAULT', 'YES') AS support, engine AS ENGINE, support AS SUPPORT FROM system.table_engines"
    },
    {
        "view_name": "KEY_COLUMN_USAGE",
        "database": "information_schema",
        "view_definition": "CREATE VIEW information_schema.KEY_COLUMN_USAGE (`constraint_catalog` String, `constraint_schema` String, `constraint_name` Nullable(String), `table_catalog` String, `table_schema` String, `table_name` String, `column_name` Nullable(String), `ordinal_position` UInt32, `position_in_unique_constraint` Nullable(UInt32), `referenced_table_schema` Nullable(String), `referenced_table_name` Nullable(String), `referenced_column_name` Nullable(String), `CONSTRAINT_CATALOG` Nullable(String), `CONSTRAINT_SCHEMA` Nullable(String), `CONSTRAINT_NAME` Nullable(String), `TABLE_CATALOG` String, `TABLE_SCHEMA` String, `TABLE_NAME` String, `COLUMN_NAME` Nullable(String), `ORDINAL_POSITION` UInt32, `POSITION_IN_UNIQUE_CONSTRAINT` Nullable(UInt32), `REFERENCED_TABLE_SCHEMA` Nullable(String), `REFERENCED_TABLE_NAME` Nullable(String), `REFERENCED_COLUMN_NAME` Nullable(String)) SQL SECURITY INVOKER AS SELECT 'def' AS constraint_catalog, database AS constraint_schema, 'PRIMARY' AS constraint_name, 'def' AS table_catalog, database AS table_schema, `table` AS table_name, name AS column_name, 1 AS ordinal_position, NULL AS position_in_unique_constraint, NULL AS referenced_table_schema, NULL AS referenced_table_name, NULL AS referenced_column_name, constraint_catalog AS CONSTRAINT_CATALOG, constraint_schema AS CONSTRAINT_SCHEMA, constraint_name AS CONSTRAINT_NAME, table_catalog AS TABLE_CATALOG, table_schema AS TABLE_SCHEMA, table_name AS TABLE_NAME, column_name AS COLUMN_NAME, ordinal_position AS ORDINAL_POSITION, position_in_unique_constraint AS POSITION_IN_UNIQUE_CONSTRAINT, referenced_table_schema AS REFERENCED_TABLE_SCHEMA, referenced_table_name AS REFERENCED_TABLE_NAME, referenced_column_name AS REFERENCED_COLUMN_NAME FROM system.columns WHERE is_in_primary_key"
    },
    {
        "view_name": "REFERENTIAL_CONSTRAINTS",
        "database": "information_schema",
        "view_definition": "CREATE VIEW information_schema.REFERENTIAL_CONSTRAINTS (`constraint_catalog` String, `constraint_schema` String, `constraint_name` Nullable(String), `unique_constraint_catalog` String, `unique_constraint_schema` String, `unique_constraint_name` Nullable(String), `match_option` String, `update_rule` String, `delete_rule` String, `table_name` String, `referenced_table_name` String, `CONSTRAINT_CATALOG` String, `CONSTRAINT_SCHEMA` String, `CONSTRAINT_NAME` Nullable(String), `UNIQUE_CONSTRAINT_CATALOG` String, `UNIQUE_CONSTRAINT_SCHEMA` String, `UNIQUE_CONSTRAINT_NAME` Nullable(String), `MATCH_OPTION` String, `UPDATE_RULE` String, `DELETE_RULE` String, `TABLE_NAME` String, `REFERENCED_TABLE_NAME` String) SQL SECURITY INVOKER AS SELECT '' AS constraint_catalog, NULL AS constraint_name, '' AS constraint_schema, '' AS unique_constraint_catalog, NULL AS unique_constraint_name, '' AS unique_constraint_schema, '' AS match_option, '' AS update_rule, '' AS delete_rule, '' AS table_name, '' AS referenced_table_name, constraint_catalog AS CONSTRAINT_CATALOG, constraint_name AS CONSTRAINT_NAME, constraint_schema AS CONSTRAINT_SCHEMA, unique_constraint_catalog AS UNIQUE_CONSTRAINT_CATALOG, unique_constraint_name AS UNIQUE_CONSTRAINT_NAME, unique_constraint_schema AS UNIQUE_CONSTRAINT_SCHEMA, match_option AS MATCH_OPTION, update_rule AS UPDATE_RULE, delete_rule AS DELETE_RULE, table_name AS TABLE_NAME, referenced_table_name AS REFERENCED_TABLE_NAME WHERE false"
    },
    {
        "view_name": "SCHEMATA",
        "database": "information_schema",
        "view_definition": "CREATE VIEW information_schema.SCHEMATA (`catalog_name` String, `schema_name` String, `schema_owner` String, `default_character_set_catalog` Nullable(String), `default_character_set_schema` Nullable(String), `default_character_set_name` Nullable(String), `sql_path` Nullable(String), `CATALOG_NAME` String, `SCHEMA_NAME` String, `SCHEMA_OWNER` String, `DEFAULT_CHARACTER_SET_CATALOG` Nullable(String), `DEFAULT_CHARACTER_SET_SCHEMA` Nullable(String), `DEFAULT_CHARACTER_SET_NAME` Nullable(String), `SQL_PATH` Nullable(String)) SQL SECURITY INVOKER AS SELECT name AS catalog_name, name AS schema_name, 'default' AS schema_owner, NULL AS default_character_set_catalog, NULL AS default_character_set_schema, NULL AS default_character_set_name, NULL AS sql_path, catalog_name AS CATALOG_NAME, schema_name AS SCHEMA_NAME, schema_owner AS SCHEMA_OWNER, default_character_set_catalog AS DEFAULT_CHARACTER_SET_CATALOG, default_character_set_schema AS DEFAULT_CHARACTER_SET_SCHEMA, default_character_set_name AS DEFAULT_CHARACTER_SET_NAME, sql_path AS SQL_PATH FROM system.databases"
    },
    {
        "view_name": "STATISTICS",
        "database": "information_schema",
        "view_definition": "CREATE VIEW information_schema.STATISTICS (`table_catalog` String, `table_schema` String, `table_name` String, `non_unique` Int32, `index_schema` String, `index_name` Nullable(String), `seq_in_index` UInt32, `column_name` Nullable(String), `collation` Nullable(String), `cardinality` Nullable(Int64), `sub_part` Nullable(Int64), `packed` Nullable(String), `nullable` String, `index_type` String, `comment` String, `index_comment` String, `is_visible` String, `expression` Nullable(String), `TABLE_CATALOG` String, `TABLE_SCHEMA` String, `TABLE_NAME` String, `NON_UNIQUE` Int32, `INDEX_SCHEMA` String, `INDEX_NAME` Nullable(String), `SEQ_IN_INDEX` UInt32, `COLUMN_NAME` Nullable(String), `COLLATION` Nullable(String), `CARDINALITY` Nullable(Int64), `SUB_PART` Nullable(Int64), `PACKED` Nullable(String), `NULLABLE` String, `INDEX_TYPE` String, `COMMENT` String, `INDEX_COMMENT` String, `IS_VISIBLE` String, `EXPRESSION` Nullable(String)) SQL SECURITY INVOKER AS SELECT '' AS table_catalog, '' AS table_schema, '' AS table_name, 0 AS non_unique, '' AS index_schema, NULL AS index_name, 0 AS seq_in_index, NULL AS column_name, NULL AS collation, NULL AS cardinality, NULL AS sub_part, NULL AS packed, '' AS nullable, '' AS index_type, '' AS comment, '' AS index_comment, '' AS is_visible, NULL AS expression, table_catalog AS TABLE_CATALOG, table_schema AS TABLE_SCHEMA, table_name AS TABLE_NAME, non_unique AS NON_UNIQUE, index_schema AS INDEX_SCHEMA, index_name AS INDEX_NAME, seq_in_index AS SEQ_IN_INDEX, column_name AS COLUMN_NAME, collation AS COLLATION, cardinality AS CARDINALITY, sub_part AS SUB_PART, packed AS PACKED, nullable AS NULLABLE, index_type AS INDEX_TYPE, comment AS COMMENT, index_comment AS INDEX_COMMENT, is_visible AS IS_VISIBLE, expression AS EXPRESSION WHERE false"
    },
    {
        "view_name": "TABLES",
        "database": "information_schema",
        "view_definition": "CREATE VIEW information_schema.TABLES (`table_catalog` String, `table_schema` String, `table_name` String, `table_type` String, `table_rows` Nullable(UInt64), `data_length` Nullable(UInt64), `index_length` Nullable(UInt64), `table_collation` Nullable(String), `table_comment` Nullable(String), `TABLE_CATALOG` String, `TABLE_SCHEMA` String, `TABLE_NAME` String, `TABLE_TYPE` String, `TABLE_ROWS` Nullable(UInt64), `DATA_LENGTH` Nullable(UInt64), `TABLE_COLLATION` Nullable(String), `TABLE_COMMENT` Nullable(String)) SQL SECURITY INVOKER AS SELECT database AS table_catalog, database AS table_schema, name AS table_name, multiIf(is_temporary, 'LOCAL TEMPORARY', engine LIKE '%View', 'VIEW', engine LIKE 'System%', 'SYSTEM VIEW', has_own_data = 0, 'FOREIGN TABLE', 'BASE TABLE') AS table_type, total_rows AS table_rows, total_bytes AS data_length, sum(((p.primary_key_size + p.marks_bytes) + p.secondary_indices_compressed_bytes) + p.secondary_indices_marks_bytes) AS index_length, 'utf8mb4_0900_ai_ci' AS table_collation, comment AS table_comment, table_catalog AS TABLE_CATALOG, table_schema AS TABLE_SCHEMA, table_name AS TABLE_NAME, table_type AS TABLE_TYPE, table_rows AS TABLE_ROWS, data_length AS DATA_LENGTH, table_collation AS TABLE_COLLATION, table_comment AS TABLE_COMMENT FROM system.tables AS t LEFT JOIN system.parts AS p ON (t.database = p.database) AND (t.name = p.`table`) GROUP BY t.database, t.name, t.is_temporary, t.engine, t.has_own_data, t.total_rows, t.total_bytes, t.comment"
    },
    {
        "view_name": "VIEWS",
        "database": "information_schema",
        "view_definition": "CREATE VIEW information_schema.VIEWS (`table_catalog` String, `table_schema` String, `table_name` String, `view_definition` String, `check_option` String, `is_updatable` Enum8('NO' = 0, 'YES' = 1), `is_insertable_into` Enum8('NO' = 0, 'YES' = 1), `is_trigger_updatable` Enum8('NO' = 0, 'YES' = 1), `is_trigger_deletable` Enum8('NO' = 0, 'YES' = 1), `is_trigger_insertable_into` Enum8('NO' = 0, 'YES' = 1), `TABLE_CATALOG` String, `TABLE_SCHEMA` String, `TABLE_NAME` String, `VIEW_DEFINITION` String, `CHECK_OPTION` String, `IS_UPDATABLE` Enum8('NO' = 0, 'YES' = 1), `IS_INSERTABLE_INTO` Enum8('NO' = 0, 'YES' = 1), `IS_TRIGGER_UPDATABLE` Enum8('NO' = 0, 'YES' = 1), `IS_TRIGGER_DELETABLE` Enum8('NO' = 0, 'YES' = 1), `IS_TRIGGER_INSERTABLE_INTO` Enum8('NO' = 0, 'YES' = 1)) SQL SECURITY INVOKER AS SELECT database AS table_catalog, database AS table_schema, name AS table_name, as_select AS view_definition, 'NONE' AS check_option, 0 AS is_updatable, engine = 'MaterializedView' AS is_insertable_into, 0 AS is_trigger_updatable, 0 AS is_trigger_deletable, 0 AS is_trigger_insertable_into, table_catalog AS TABLE_CATALOG, table_schema AS TABLE_SCHEMA, table_name AS TABLE_NAME, view_definition AS VIEW_DEFINITION, check_option AS CHECK_OPTION, is_updatable AS IS_UPDATABLE, is_insertable_into AS IS_INSERTABLE_INTO, is_trigger_updatable AS IS_TRIGGER_UPDATABLE, is_trigger_deletable AS IS_TRIGGER_DELETABLE, is_trigger_insertable_into AS IS_TRIGGER_INSERTABLE_INTO FROM system.tables WHERE engine LIKE '%View'"
    },
    {
        "view_name": "character_sets",
        "database": "information_schema",
        "view_definition": "CREATE VIEW information_schema.character_sets (`character_set_name` String, `CHARACTER_SET_NAME` String) SQL SECURITY INVOKER AS SELECT arrayJoin(['utf8', 'utf8mb4', 'ascii', 'binary']) AS character_set_name, character_set_name AS CHARACTER_SET_NAME"
    },
    {
        "view_name": "collations",
        "database": "information_schema",
        "view_definition": "CREATE VIEW information_schema.collations (`collation_name` String, `COLLATION_NAME` String) SQL SECURITY INVOKER AS SELECT name AS collation_name, collation_name AS COLLATION_NAME FROM system.collations"
    },
    {
        "view_name": "columns",
        "database": "information_schema",
        "view_definition": "CREATE VIEW information_schema.columns (`table_catalog` String, `table_schema` String, `table_name` String, `column_name` String, `ordinal_position` UInt64, `column_default` String, `is_nullable` String, `data_type` String, `character_maximum_length` Nullable(UInt64), `character_octet_length` Nullable(UInt64), `numeric_precision` Nullable(UInt64), `numeric_precision_radix` Nullable(UInt64), `numeric_scale` Nullable(UInt64), `datetime_precision` Nullable(UInt64), `character_set_catalog` Nullable(String), `character_set_schema` Nullable(String), `character_set_name` Nullable(String), `collation_catalog` Nullable(String), `collation_schema` Nullable(String), `collation_name` Nullable(String), `domain_catalog` Nullable(String), `domain_schema` Nullable(String), `domain_name` Nullable(String), `extra` Nullable(String), `column_comment` String, `column_type` String, `TABLE_CATALOG` String, `TABLE_SCHEMA` String, `TABLE_NAME` String, `COLUMN_NAME` String, `ORDINAL_POSITION` UInt64, `COLUMN_DEFAULT` String, `IS_NULLABLE` String, `DATA_TYPE` String, `CHARACTER_MAXIMUM_LENGTH` Nullable(UInt64), `CHARACTER_OCTET_LENGTH` Nullable(UInt64), `NUMERIC_PRECISION` Nullable(UInt64), `NUMERIC_PRECISION_RADIX` Nullable(UInt64), `NUMERIC_SCALE` Nullable(UInt64), `DATETIME_PRECISION` Nullable(UInt64), `CHARACTER_SET_CATALOG` Nullable(String), `CHARACTER_SET_SCHEMA` Nullable(String), `CHARACTER_SET_NAME` Nullable(String), `COLLATION_CATALOG` Nullable(String), `COLLATION_SCHEMA` Nullable(String), `COLLATION_NAME` Nullable(String), `DOMAIN_CATALOG` Nullable(String), `DOMAIN_SCHEMA` Nullable(String), `DOMAIN_NAME` Nullable(String), `EXTRA` Nullable(String), `COLUMN_COMMENT` String, `COLUMN_TYPE` String) SQL SECURITY INVOKER AS SELECT database AS table_catalog, database AS table_schema, `table` AS table_name, name AS column_name, position AS ordinal_position, default_expression AS column_default, type LIKE 'Nullable(%)' AS is_nullable, type AS data_type, character_octet_length AS character_maximum_length, character_octet_length, numeric_precision, numeric_precision_radix, numeric_scale, datetime_precision, NULL AS character_set_catalog, NULL AS character_set_schema, NULL AS character_set_name, NULL AS collation_catalog, NULL AS collation_schema, NULL AS collation_name, NULL AS domain_catalog, NULL AS domain_schema, NULL AS domain_name, multiIf(default_kind = 'DEFAULT', 'DEFAULT_GENERATED', default_kind = 'MATERIALIZED', 'STORED GENERATED', default_kind = 'ALIAS', 'VIRTUAL GENERATED', '') AS extra, comment AS column_comment, type AS column_type, table_catalog AS TABLE_CATALOG, table_schema AS TABLE_SCHEMA, table_name AS TABLE_NAME, column_name AS COLUMN_NAME, ordinal_position AS ORDINAL_POSITION, column_default AS COLUMN_DEFAULT, is_nullable AS IS_NULLABLE, data_type AS DATA_TYPE, character_maximum_length AS CHARACTER_MAXIMUM_LENGTH, character_octet_length AS CHARACTER_OCTET_LENGTH, numeric_precision AS NUMERIC_PRECISION, numeric_precision_radix AS NUMERIC_PRECISION_RADIX, numeric_scale AS NUMERIC_SCALE, datetime_precision AS DATETIME_PRECISION, character_set_catalog AS CHARACTER_SET_CATALOG, character_set_schema AS CHARACTER_SET_SCHEMA, character_set_name AS CHARACTER_SET_NAME, collation_catalog AS COLLATION_CATALOG, collation_schema AS COLLATION_SCHEMA, collation_name AS COLLATION_NAME, domain_catalog AS DOMAIN_CATALOG, domain_schema AS DOMAIN_SCHEMA, domain_name AS DOMAIN_NAME, extra AS EXTRA, column_comment AS COLUMN_COMMENT, column_type AS COLUMN_TYPE FROM system.columns"
    },
    {
        "view_name": "engines",
        "database": "information_schema",
        "view_definition": "CREATE VIEW information_schema.engines (`engine` String, `support` String, `ENGINE` String, `SUPPORT` String) SQL SECURITY INVOKER AS SELECT name AS engine, if(engine = getSetting('default_table_engine'), 'DEFAULT', 'YES') AS support, engine AS ENGINE, support AS SUPPORT FROM system.table_engines"
    },
    {
        "view_name": "key_column_usage",
        "database": "information_schema",
        "view_definition": "CREATE VIEW information_schema.key_column_usage (`constraint_catalog` String, `constraint_schema` String, `constraint_name` Nullable(String), `table_catalog` String, `table_schema` String, `table_name` String, `column_name` Nullable(String), `ordinal_position` UInt32, `position_in_unique_constraint` Nullable(UInt32), `referenced_table_schema` Nullable(String), `referenced_table_name` Nullable(String), `referenced_column_name` Nullable(String), `CONSTRAINT_CATALOG` Nullable(String), `CONSTRAINT_SCHEMA` Nullable(String), `CONSTRAINT_NAME` Nullable(String), `TABLE_CATALOG` String, `TABLE_SCHEMA` String, `TABLE_NAME` String, `COLUMN_NAME` Nullable(String), `ORDINAL_POSITION` UInt32, `POSITION_IN_UNIQUE_CONSTRAINT` Nullable(UInt32), `REFERENCED_TABLE_SCHEMA` Nullable(String), `REFERENCED_TABLE_NAME` Nullable(String), `REFERENCED_COLUMN_NAME` Nullable(String)) SQL SECURITY INVOKER AS SELECT 'def' AS constraint_catalog, database AS constraint_schema, 'PRIMARY' AS constraint_name, 'def' AS table_catalog, database AS table_schema, `table` AS table_name, name AS column_name, 1 AS ordinal_position, NULL AS position_in_unique_constraint, NULL AS referenced_table_schema, NULL AS referenced_table_name, NULL AS referenced_column_name, constraint_catalog AS CONSTRAINT_CATALOG, constraint_schema AS CONSTRAINT_SCHEMA, constraint_name AS CONSTRAINT_NAME, table_catalog AS TABLE_CATALOG, table_schema AS TABLE_SCHEMA, table_name AS TABLE_NAME, column_name AS COLUMN_NAME, ordinal_position AS ORDINAL_POSITION, position_in_unique_constraint AS POSITION_IN_UNIQUE_CONSTRAINT, referenced_table_schema AS REFERENCED_TABLE_SCHEMA, referenced_table_name AS REFERENCED_TABLE_NAME, referenced_column_name AS REFERENCED_COLUMN_NAME FROM system.columns WHERE is_in_primary_key"
    },
    {
        "view_name": "referential_constraints",
        "database": "information_schema",
        "view_definition": "CREATE VIEW information_schema.referential_constraints (`constraint_catalog` String, `constraint_schema` String, `constraint_name` Nullable(String), `unique_constraint_catalog` String, `unique_constraint_schema` String, `unique_constraint_name` Nullable(String), `match_option` String, `update_rule` String, `delete_rule` String, `table_name` String, `referenced_table_name` String, `CONSTRAINT_CATALOG` String, `CONSTRAINT_SCHEMA` String, `CONSTRAINT_NAME` Nullable(String), `UNIQUE_CONSTRAINT_CATALOG` String, `UNIQUE_CONSTRAINT_SCHEMA` String, `UNIQUE_CONSTRAINT_NAME` Nullable(String), `MATCH_OPTION` String, `UPDATE_RULE` String, `DELETE_RULE` String, `TABLE_NAME` String, `REFERENCED_TABLE_NAME` String) SQL SECURITY INVOKER AS SELECT '' AS constraint_catalog, NULL AS constraint_name, '' AS constraint_schema, '' AS unique_constraint_catalog, NULL AS unique_constraint_name, '' AS unique_constraint_schema, '' AS match_option, '' AS update_rule, '' AS delete_rule, '' AS table_name, '' AS referenced_table_name, constraint_catalog AS CONSTRAINT_CATALOG, constraint_name AS CONSTRAINT_NAME, constraint_schema AS CONSTRAINT_SCHEMA, unique_constraint_catalog AS UNIQUE_CONSTRAINT_CATALOG, unique_constraint_name AS UNIQUE_CONSTRAINT_NAME, unique_constraint_schema AS UNIQUE_CONSTRAINT_SCHEMA, match_option AS MATCH_OPTION, update_rule AS UPDATE_RULE, delete_rule AS DELETE_RULE, table_name AS TABLE_NAME, referenced_table_name AS REFERENCED_TABLE_NAME WHERE false"
    },
    {
        "view_name": "schemata",
        "database": "information_schema",
        "view_definition": "CREATE VIEW information_schema.schemata (`catalog_name` String, `schema_name` String, `schema_owner` String, `default_character_set_catalog` Nullable(String), `default_character_set_schema` Nullable(String), `default_character_set_name` Nullable(String), `sql_path` Nullable(String), `CATALOG_NAME` String, `SCHEMA_NAME` String, `SCHEMA_OWNER` String, `DEFAULT_CHARACTER_SET_CATALOG` Nullable(String), `DEFAULT_CHARACTER_SET_SCHEMA` Nullable(String), `DEFAULT_CHARACTER_SET_NAME` Nullable(String), `SQL_PATH` Nullable(String)) SQL SECURITY INVOKER AS SELECT name AS catalog_name, name AS schema_name, 'default' AS schema_owner, NULL AS default_character_set_catalog, NULL AS default_character_set_schema, NULL AS default_character_set_name, NULL AS sql_path, catalog_name AS CATALOG_NAME, schema_name AS SCHEMA_NAME, schema_owner AS SCHEMA_OWNER, default_character_set_catalog AS DEFAULT_CHARACTER_SET_CATALOG, default_character_set_schema AS DEFAULT_CHARACTER_SET_SCHEMA, default_character_set_name AS DEFAULT_CHARACTER_SET_NAME, sql_path AS SQL_PATH FROM system.databases"
    },
    {
        "view_name": "statistics",
        "database": "information_schema",
        "view_definition": "CREATE VIEW information_schema.statistics (`table_catalog` String, `table_schema` String, `table_name` String, `non_unique` Int32, `index_schema` String, `index_name` Nullable(String), `seq_in_index` UInt32, `column_name` Nullable(String), `collation` Nullable(String), `cardinality` Nullable(Int64), `sub_part` Nullable(Int64), `packed` Nullable(String), `nullable` String, `index_type` String, `comment` String, `index_comment` String, `is_visible` String, `expression` Nullable(String), `TABLE_CATALOG` String, `TABLE_SCHEMA` String, `TABLE_NAME` String, `NON_UNIQUE` Int32, `INDEX_SCHEMA` String, `INDEX_NAME` Nullable(String), `SEQ_IN_INDEX` UInt32, `COLUMN_NAME` Nullable(String), `COLLATION` Nullable(String), `CARDINALITY` Nullable(Int64), `SUB_PART` Nullable(Int64), `PACKED` Nullable(String), `NULLABLE` String, `INDEX_TYPE` String, `COMMENT` String, `INDEX_COMMENT` String, `IS_VISIBLE` String, `EXPRESSION` Nullable(String)) SQL SECURITY INVOKER AS SELECT '' AS table_catalog, '' AS table_schema, '' AS table_name, 0 AS non_unique, '' AS index_schema, NULL AS index_name, 0 AS seq_in_index, NULL AS column_name, NULL AS collation, NULL AS cardinality, NULL AS sub_part, NULL AS packed, '' AS nullable, '' AS index_type, '' AS comment, '' AS index_comment, '' AS is_visible, NULL AS expression, table_catalog AS TABLE_CATALOG, table_schema AS TABLE_SCHEMA, table_name AS TABLE_NAME, non_unique AS NON_UNIQUE, index_schema AS INDEX_SCHEMA, index_name AS INDEX_NAME, seq_in_index AS SEQ_IN_INDEX, column_name AS COLUMN_NAME, collation AS COLLATION, cardinality AS CARDINALITY, sub_part AS SUB_PART, packed AS PACKED, nullable AS NULLABLE, index_type AS INDEX_TYPE, comment AS COMMENT, index_comment AS INDEX_COMMENT, is_visible AS IS_VISIBLE, expression AS EXPRESSION WHERE false"
    },
    {
        "view_name": "tables",
        "database": "information_schema",
        "view_definition": "CREATE VIEW information_schema.tables (`table_catalog` String, `table_schema` String, `table_name` String, `table_type` String, `table_rows` Nullable(UInt64), `data_length` Nullable(UInt64), `index_length` Nullable(UInt64), `table_collation` Nullable(String), `table_comment` Nullable(String), `TABLE_CATALOG` String, `TABLE_SCHEMA` String, `TABLE_NAME` String, `TABLE_TYPE` String, `TABLE_ROWS` Nullable(UInt64), `DATA_LENGTH` Nullable(UInt64), `TABLE_COLLATION` Nullable(String), `TABLE_COMMENT` Nullable(String)) SQL SECURITY INVOKER AS SELECT database AS table_catalog, database AS table_schema, name AS table_name, multiIf(is_temporary, 'LOCAL TEMPORARY', engine LIKE '%View', 'VIEW', engine LIKE 'System%', 'SYSTEM VIEW', has_own_data = 0, 'FOREIGN TABLE', 'BASE TABLE') AS table_type, total_rows AS table_rows, total_bytes AS data_length, sum(((p.primary_key_size + p.marks_bytes) + p.secondary_indices_compressed_bytes) + p.secondary_indices_marks_bytes) AS index_length, 'utf8mb4_0900_ai_ci' AS table_collation, comment AS table_comment, table_catalog AS TABLE_CATALOG, table_schema AS TABLE_SCHEMA, table_name AS TABLE_NAME, table_type AS TABLE_TYPE, table_rows AS TABLE_ROWS, data_length AS DATA_LENGTH, table_collation AS TABLE_COLLATION, table_comment AS TABLE_COMMENT FROM system.tables AS t LEFT JOIN system.parts AS p ON (t.database = p.database) AND (t.name = p.`table`) GROUP BY t.database, t.name, t.is_temporary, t.engine, t.has_own_data, t.total_rows, t.total_bytes, t.comment"
    },
    {
        "view_name": "views",
        "database": "information_schema",
        "view_definition": "CREATE VIEW information_schema.views (`table_catalog` String, `table_schema` String, `table_name` String, `view_definition` String, `check_option` String, `is_updatable` Enum8('NO' = 0, 'YES' = 1), `is_insertable_into` Enum8('NO' = 0, 'YES' = 1), `is_trigger_updatable` Enum8('NO' = 0, 'YES' = 1), `is_trigger_deletable` Enum8('NO' = 0, 'YES' = 1), `is_trigger_insertable_into` Enum8('NO' = 0, 'YES' = 1), `TABLE_CATALOG` String, `TABLE_SCHEMA` String, `TABLE_NAME` String, `VIEW_DEFINITION` String, `CHECK_OPTION` String, `IS_UPDATABLE` Enum8('NO' = 0, 'YES' = 1), `IS_INSERTABLE_INTO` Enum8('NO' = 0, 'YES' = 1), `IS_TRIGGER_UPDATABLE` Enum8('NO' = 0, 'YES' = 1), `IS_TRIGGER_DELETABLE` Enum8('NO' = 0, 'YES' = 1), `IS_TRIGGER_INSERTABLE_INTO` Enum8('NO' = 0, 'YES' = 1)) SQL SECURITY INVOKER AS SELECT database AS table_catalog, database AS table_schema, name AS table_name, as_select AS view_definition, 'NONE' AS check_option, 0 AS is_updatable, engine = 'MaterializedView' AS is_insertable_into, 0 AS is_trigger_updatable, 0 AS is_trigger_deletable, 0 AS is_trigger_insertable_into, table_catalog AS TABLE_CATALOG, table_schema AS TABLE_SCHEMA, table_name AS TABLE_NAME, view_definition AS VIEW_DEFINITION, check_option AS CHECK_OPTION, is_updatable AS IS_UPDATABLE, is_insertable_into AS IS_INSERTABLE_INTO, is_trigger_updatable AS IS_TRIGGER_UPDATABLE, is_trigger_deletable AS IS_TRIGGER_DELETABLE, is_trigger_insertable_into AS IS_TRIGGER_INSERTABLE_INTO FROM system.tables WHERE engine LIKE '%View'"
    }
]